<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.2/css/all.min.css" integrity="sha256-xejo6yLi6vGtAjcMIsY8BHdKsLg7QynVlFMzdQgUuy8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"kyrie2to11.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.12.3","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="github repo: https:&#x2F;&#x2F;github.com&#x2F;zjhellofss&#x2F;kuiperdatawhale.git  目录 目录 Tensor Compute Graph KuiperInfer对计算图的封装 构建计算图关系和执行顺序 拓扑排序 基于深度优先的拓扑排序计算步骤   Operator &amp; Register Factory Layer 类型的定义   Convolu">
<meta property="og:type" content="article">
<meta property="og:title" content="Kuiper Infer">
<meta property="og:url" content="https://kyrie2to11.github.io/2024/12/24/Kuiper-Infer/index.html">
<meta property="og:site_name" content="Jarvis&#39;s Blog">
<meta property="og:description" content="github repo: https:&#x2F;&#x2F;github.com&#x2F;zjhellofss&#x2F;kuiperdatawhale.git  目录 目录 Tensor Compute Graph KuiperInfer对计算图的封装 构建计算图关系和执行顺序 拓扑排序 基于深度优先的拓扑排序计算步骤   Operator &amp; Register Factory Layer 类型的定义   Convolu">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://kyrie2to11.github.io/2024/12/24/Kuiper-Infer/runtime_ir.png">
<meta property="og:image" content="https://kyrie2to11.github.io/2024/12/24/Kuiper-Infer/pooling.png">
<meta property="og:image" content="https://kyrie2to11.github.io/2024/12/24/Kuiper-Infer/single_channel_conv.png">
<meta property="og:image" content="https://kyrie2to11.github.io/2024/12/24/Kuiper-Infer/multi_channel_channel_conv.png">
<meta property="og:image" content="https://kyrie2to11.github.io/2024/12/24/Kuiper-Infer/multi_kernel_conv.png">
<meta property="og:image" content="https://kyrie2to11.github.io/2024/12/24/Kuiper-Infer/group_conv.png">
<meta property="article:published_time" content="2024-12-24T13:06:56.000Z">
<meta property="article:modified_time" content="2025-01-03T09:41:34.493Z">
<meta property="article:author" content="jarvis">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://kyrie2to11.github.io/2024/12/24/Kuiper-Infer/runtime_ir.png">


<link rel="canonical" href="https://kyrie2to11.github.io/2024/12/24/Kuiper-Infer/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://kyrie2to11.github.io/2024/12/24/Kuiper-Infer/","path":"2024/12/24/Kuiper-Infer/","title":"Kuiper Infer"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Kuiper Infer | Jarvis's Blog</title>
  






  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Jarvis's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">记录生活，沉淀自己</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>







</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%AE%E5%BD%95"><span class="nav-number">1.</span> <span class="nav-text">目录</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Tensor"><span class="nav-number">2.</span> <span class="nav-text">Tensor</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Compute-Graph"><span class="nav-number">3.</span> <span class="nav-text">Compute Graph</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#KuiperInfer%E5%AF%B9%E8%AE%A1%E7%AE%97%E5%9B%BE%E7%9A%84%E5%B0%81%E8%A3%85"><span class="nav-number">4.</span> <span class="nav-text">KuiperInfer对计算图的封装</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9E%84%E5%BB%BA%E8%AE%A1%E7%AE%97%E5%9B%BE%E5%85%B3%E7%B3%BB%E5%92%8C%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F"><span class="nav-number">5.</span> <span class="nav-text">构建计算图关系和执行顺序</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F"><span class="nav-number">5.1.</span> <span class="nav-text">拓扑排序</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E7%9A%84%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%E8%AE%A1%E7%AE%97%E6%AD%A5%E9%AA%A4"><span class="nav-number">5.2.</span> <span class="nav-text">基于深度优先的拓扑排序计算步骤</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Operator-amp-Register-Factory"><span class="nav-number">6.</span> <span class="nav-text">Operator &amp; Register Factory</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Layer-%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="nav-number">6.1.</span> <span class="nav-text">Layer 类型的定义</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Convolution-amp-Pooling-Operator"><span class="nav-number">7.</span> <span class="nav-text">Convolution &amp; Pooling Operator</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B1%A0%E5%8C%96%E7%AE%97%E5%AD%90%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="nav-number">7.1.</span> <span class="nav-text">池化算子的定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%AE%97%E5%AD%90%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="nav-number">7.2.</span> <span class="nav-text">卷积算子的定义</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Expression-Layer"><span class="nav-number">8.</span> <span class="nav-text">Expression Layer</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="nav-number">8.1.</span> <span class="nav-text">表达式的定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%8D%E6%B3%95%E8%A7%A3%E6%9E%90"><span class="nav-number">8.2.</span> <span class="nav-text">词法解析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%8D%E6%B3%95%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="nav-number">8.2.1.</span> <span class="nav-text">词法的定义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%8D%E6%B3%95%E7%9A%84%E8%A7%A3%E6%9E%90"><span class="nav-number">8.2.2.</span> <span class="nav-text">词法的解析</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%A4%E6%96%AD%E5%8F%A5%E5%AD%90%E6%98%AF%E5%90%A6%E4%B8%BA%E7%A9%BA"><span class="nav-number">8.2.2.1.</span> <span class="nav-text">判断句子是否为空</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%A7%BB%E9%99%A4%E5%8F%A5%E5%AD%90%E4%B8%AD%E7%9A%84%E7%A9%BA%E6%A0%BC"><span class="nav-number">8.2.2.2.</span> <span class="nav-text">移除句子中的空格</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%80%90%E4%B8%AA%E8%A7%A3%E6%9E%90%E5%8F%A5%E5%AD%90%E7%9A%84%E5%AD%97%E7%AC%A6"><span class="nav-number">8.2.2.3.</span> <span class="nav-text">逐个解析句子的字符</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%AD%E6%B3%95%E8%A7%A3%E6%9E%90"><span class="nav-number">8.3.</span> <span class="nav-text">语法解析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%AD%E6%B3%95%E6%A0%91%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="nav-number">8.3.1.</span> <span class="nav-text">语法树的定义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%92%E5%BD%92%E5%90%91%E4%B8%8B%E7%9A%84%E8%A7%A3%E6%9E%90"><span class="nav-number">8.3.2.</span> <span class="nav-text">递归向下的解析</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E8%AF%AD%E6%B3%95%E6%A0%91%E7%9A%84%E8%BD%AC%E6%8D%A2"><span class="nav-number">8.4.</span> <span class="nav-text">对语法树的转换</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%86%E6%B3%A2%E5%85%B0%E5%BC%8F"><span class="nav-number">8.4.1.</span> <span class="nav-text">逆波兰式</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%87%E7%A8%8B%E6%80%BB%E8%BF%B0"><span class="nav-number">8.5.</span> <span class="nav-text">过程总述</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ResNet-amp-YOLOv5-Infer"><span class="nav-number">9.</span> <span class="nav-text">ResNet &amp; YOLOv5 Infer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#homework"><span class="nav-number">10.</span> <span class="nav-text">homework</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#course1"><span class="nav-number">10.1.</span> <span class="nav-text">course1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#course2"><span class="nav-number">10.2.</span> <span class="nav-text">course2</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#course3"><span class="nav-number">10.3.</span> <span class="nav-text">course3</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#course4"><span class="nav-number">10.4.</span> <span class="nav-text">course4</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#course5"><span class="nav-number">10.5.</span> <span class="nav-text">course5</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#course6"><span class="nav-number">10.6.</span> <span class="nav-text">course6</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#course7"><span class="nav-number">10.7.</span> <span class="nav-text">course7</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">jarvis</p>
  <div class="site-description" itemprop="description">记录学习和生活，留下时光的痕迹</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">27</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://kyrie2to11.github.io/2024/12/24/Kuiper-Infer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="jarvis">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jarvis's Blog">
      <meta itemprop="description" content="记录学习和生活，留下时光的痕迹">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Kuiper Infer | Jarvis's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Kuiper Infer
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-12-24 21:06:56" itemprop="dateCreated datePublished" datetime="2024-12-24T21:06:56+08:00">2024-12-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-01-03 17:41:34" itemprop="dateModified" datetime="2025-01-03T17:41:34+08:00">2025-01-03</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <blockquote>
<p>github repo: <a target="_blank" rel="noopener" href="https://github.com/zjhellofss/kuiperdatawhale.git">https://github.com/zjhellofss/kuiperdatawhale.git</a></p>
</blockquote>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul>
<li><a href="#%E7%9B%AE%E5%BD%95">目录</a></li>
<li><a href="#tensor">Tensor</a></li>
<li><a href="#compute-graph">Compute Graph</a></li>
<li><a href="#kuiperinfer%E5%AF%B9%E8%AE%A1%E7%AE%97%E5%9B%BE%E7%9A%84%E5%B0%81%E8%A3%85">KuiperInfer对计算图的封装</a></li>
<li><a href="#%E6%9E%84%E5%BB%BA%E8%AE%A1%E7%AE%97%E5%9B%BE%E5%85%B3%E7%B3%BB%E5%92%8C%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F">构建计算图关系和执行顺序</a><ul>
<li><a href="#%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F">拓扑排序</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E7%9A%84%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%E8%AE%A1%E7%AE%97%E6%AD%A5%E9%AA%A4">基于深度优先的拓扑排序计算步骤</a></li>
</ul>
</li>
<li><a href="#operator--register-factory">Operator &amp; Register Factory</a><ul>
<li><a href="#layer-%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%AE%9A%E4%B9%89">Layer 类型的定义</a></li>
</ul>
</li>
<li><a href="#convolution--pooling-operator">Convolution &amp; Pooling Operator</a><ul>
<li><a href="#%E6%B1%A0%E5%8C%96%E7%AE%97%E5%AD%90%E7%9A%84%E5%AE%9A%E4%B9%89">池化算子的定义</a></li>
<li><a href="#%E5%8D%B7%E7%A7%AF%E7%AE%97%E5%AD%90%E7%9A%84%E5%AE%9A%E4%B9%89">卷积算子的定义</a></li>
</ul>
</li>
<li><a href="#expression-layer">Expression Layer</a><ul>
<li><a href="#%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84%E5%AE%9A%E4%B9%89">表达式的定义</a></li>
<li><a href="#%E8%AF%8D%E6%B3%95%E8%A7%A3%E6%9E%90">词法解析</a><ul>
<li><a href="#%E8%AF%8D%E6%B3%95%E7%9A%84%E5%AE%9A%E4%B9%89">词法的定义</a></li>
<li><a href="#%E8%AF%8D%E6%B3%95%E7%9A%84%E8%A7%A3%E6%9E%90">词法的解析</a><ul>
<li><a href="#%E5%88%A4%E6%96%AD%E5%8F%A5%E5%AD%90%E6%98%AF%E5%90%A6%E4%B8%BA%E7%A9%BA">判断句子是否为空</a></li>
<li><a href="#%E7%A7%BB%E9%99%A4%E5%8F%A5%E5%AD%90%E4%B8%AD%E7%9A%84%E7%A9%BA%E6%A0%BC">移除句子中的空格</a></li>
<li><a href="#%E9%80%90%E4%B8%AA%E8%A7%A3%E6%9E%90%E5%8F%A5%E5%AD%90%E7%9A%84%E5%AD%97%E7%AC%A6">逐个解析句子的字符</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E8%AF%AD%E6%B3%95%E8%A7%A3%E6%9E%90">语法解析</a><ul>
<li><a href="#%E8%AF%AD%E6%B3%95%E6%A0%91%E7%9A%84%E5%AE%9A%E4%B9%89">语法树的定义</a></li>
<li><a href="#%E9%80%92%E5%BD%92%E5%90%91%E4%B8%8B%E7%9A%84%E8%A7%A3%E6%9E%90">递归向下的解析</a></li>
</ul>
</li>
<li><a href="#%E5%AF%B9%E8%AF%AD%E6%B3%95%E6%A0%91%E7%9A%84%E8%BD%AC%E6%8D%A2">对语法树的转换</a><ul>
<li><a href="#%E9%80%86%E6%B3%A2%E5%85%B0%E5%BC%8F">逆波兰式</a></li>
</ul>
</li>
<li><a href="#%E8%BF%87%E7%A8%8B%E6%80%BB%E8%BF%B0">过程总述</a></li>
</ul>
</li>
<li><a href="#resnet--yolov5-infer">ResNet &amp; YOLOv5 Infer</a></li>
<li><a href="#homework">homework</a><ul>
<li><a href="#course1">course1</a></li>
<li><a href="#course2">course2</a></li>
<li><a href="#course3">course3</a></li>
<li><a href="#course4">course4</a></li>
<li><a href="#course5">course5</a></li>
<li><a href="#course6">course6</a></li>
<li><a href="#course7">course7</a></li>
</ul>
</li>
</ul>
<h2 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h2><ol>
<li><p>类设计</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Tensor</span>&lt;<span class="type">float</span>&gt;&#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">     <span class="built_in">Tensor</span>(<span class="type">const</span> std::vector&lt;<span class="type">uint32_t</span>&gt;&amp; shapes); <span class="comment">// 三维张量构造函数</span></span><br><span class="line">     <span class="function"><span class="type">uint32_t</span> <span class="title">rows</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">     <span class="function"><span class="type">uint32_t</span> <span class="title">cols</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">     <span class="function"><span class="type">uint32_t</span> <span class="title">channels</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">     <span class="function"><span class="type">uint32_t</span> <span class="title">size</span><span class="params">()</span> <span class="type">const</span></span>; <span class="comment">// 返回元素个数</span></span><br><span class="line">     <span class="function"><span class="type">const</span> std::vector&lt;<span class="type">uint32_t</span>&gt;&amp; <span class="title">raw_shapes</span><span class="params">()</span> <span class="type">const</span></span>; <span class="comment">// 张量实际大小</span></span><br><span class="line">     <span class="function"><span class="type">void</span> <span class="title">Fill</span><span class="params">(<span class="type">const</span> std::vector&lt;<span class="type">float</span>&gt;&amp; values, <span class="type">bool</span> row_major)</span></span>; <span class="comment">// 填充指定值</span></span><br><span class="line">     ···</span><br><span class="line">     ···</span><br><span class="line">     ···</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">     std::vector&lt;<span class="type">uint32_t</span>&gt; raw_shapes_;  <span class="comment">// 张量数据的实际尺寸大小</span></span><br><span class="line">     arma::fcube data_;                  <span class="comment">// 张量数据</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="Compute-Graph"><a href="#Compute-Graph" class="headerlink" title="Compute Graph"></a>Compute Graph</h2><ol>
<li><p>计算图相关概念</p>
<ul>
<li><code>Operator</code>: 深度学习计算图中的计算节点。</li>
<li><code>Layer</code>: <strong>计算节点中</strong>运算的具体执行者，<code>Layer</code>类先读取输入张量中的数据，然后对输入张量进行计算，得到的结果存放到计算节点的输出张量中，<strong>当然，不同的算子中<code>Layer</code>的计算过程会不一致</strong>。</li>
<li><code>Tensor</code>: 用于存放<strong>多维数据</strong>的数据结构，方便数据在计算节点之间传递，同时该结构也封装矩阵乘、点积等与矩阵相关的基本操作。</li>
<li><code>Graph</code>: 有多个<code>Operator</code>串联得到的有向无环图，规定了各个计算节点（<code>Operator</code>）执行的流程和顺序。</li>
</ul>
</li>
<li><p>PNNX 计算图优势</p>
<ul>
<li>使用模板匹配（<code>pattern matching</code>）的方法将匹配到的子图用对应等价的大算子替换掉，不会像模型导出 ONNX 算子一样细碎。</li>
<li>在<code>PyTorch</code>中编写的简单算术表达式在转换为<code>PNNX</code>后，会保留表达式的整体结构，而不会被拆分成许多小的加减乘除算子。</li>
<li><code>PNNX</code>项目中有大量图优化的技术，包括了算子融合，常量折叠和消除，公共表达式消除等技术。</li>
</ul>
</li>
<li><p>PNNX 计算图格式</p>
<ul>
<li><code>PNNX</code>由图结构(<code>Graph</code>), 运算符(<code>Operator</code>)和操作数(<code>Operand</code>)这三种结构组成的，设计非常简洁。</li>
<li><code>Graph</code>的核心作用是<strong>管理计算图中的运算符和操作数</strong>。下面将对这两个概念进行说明：<ol>
<li><code>Operator</code>类用来<strong>表示计算图中的运算符（算子）</strong>，比如一个模型中的<code>Convolution</code>, <code>Pooling</code>等算子；</li>
<li><code>Operand</code>类用来<strong>表示计算图中的操作数</strong>，即<strong>与一个运算符有关的输入和输出张量</strong>；</li>
<li><code>Graph</code>类的成员函数提供了方便的接口用来<strong>创建和访问操作符和操作数</strong>，以构建和遍历计算图。同时，它也是模型中<strong>运算符（算子）和操作数的集合</strong>。</li>
</ol>
</li>
</ul>
</li>
<li><p>PNNX 运算符结构</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Operator</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">   std::vector&lt;Operand*&gt; inputs; <span class="comment">// 输入</span></span><br><span class="line">   std::vector&lt;Operand*&gt; outputs; <span class="comment">// 输出</span></span><br><span class="line"></span><br><span class="line">   std::string type; <span class="comment">// 类型：conv/linear/pooling</span></span><br><span class="line">   std::string name; <span class="comment">// 名称</span></span><br><span class="line"></span><br><span class="line">   std::vector&lt;std::string&gt; inputnames; </span><br><span class="line">   std::map&lt;std::string, Parameter&gt; params; <span class="comment">// 参数：如 `stride`, `padding`, `kernel size` 等</span></span><br><span class="line">   std::map&lt;std::string, Attribute&gt; attrs; <span class="comment">// 权重属性</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>PNNX 操作数结构</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Operand</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">   <span class="function"><span class="type">void</span> <span class="title">remove_consumer</span><span class="params">(<span class="type">const</span> Operator* c)</span></span>;</span><br><span class="line">   Operator* producer;</span><br><span class="line">   std::vector&lt;Operator*&gt; consumers;</span><br><span class="line">   </span><br><span class="line">   <span class="type">int</span> type;</span><br><span class="line">   std::vector&lt;<span class="type">int</span>&gt; shape;</span><br><span class="line"></span><br><span class="line">   std::string name;</span><br><span class="line">   std::map&lt;std::string, Parameter&gt; params;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>操作数结构中的<code>producer</code>和<code>customers</code>, 分别表示<strong>产生这个操作数的算子</strong>和<strong>使用这个操作数的算子</strong>。<br>值得注意的是产生这个操作数的算子只能有一个，而使用这个操作数的算子可以有很多个。</p>
</li>
</ol>
<h2 id="KuiperInfer对计算图的封装"><a href="#KuiperInfer对计算图的封装" class="headerlink" title="KuiperInfer对计算图的封装"></a>KuiperInfer对计算图的封装</h2><ol>
<li>PNNX Operator -&gt; RuntimeOperator<img src="/2024/12/24/Kuiper-Infer/runtime_ir.png" class="" title="runtime_ir"></li>
</ol>
<h2 id="构建计算图关系和执行顺序"><a href="#构建计算图关系和执行顺序" class="headerlink" title="构建计算图关系和执行顺序"></a>构建计算图关系和执行顺序</h2><h3 id="拓扑排序"><a href="#拓扑排序" class="headerlink" title="拓扑排序"></a>拓扑排序</h3><p>对于一个有向无环图，拓扑排序总能够找到一个<strong>节点序列</strong>，在这个序列中，<strong>每个节点的前驱节点都能排在这个节点的前面</strong>。什么是前驱节点呢，也就是对于<strong>有向图中任意一条边的起点，可以认为它是终点节点的前驱节点。</strong></p>
<h3 id="基于深度优先的拓扑排序计算步骤"><a href="#基于深度优先的拓扑排序计算步骤" class="headerlink" title="基于深度优先的拓扑排序计算步骤"></a>基于深度优先的拓扑排序计算步骤</h3><p>有计算排序的函数为<code>ReverseTopo</code>. <code>ReverseTopo</code>有参数<code>current_op</code>.</p>
<ol>
<li>选定一个入度为零的节点(<code>current_op</code>)，入度为零指的是<strong>该节点没有前驱节点或所有前驱节点已经都被执行过</strong>，在选定的同时将该节点的已执行标记置为<code>True</code>，并将该节点传入到<code>ReverseTopo</code>函数中；</li>
<li>遍历1步骤中节点的后继节点(<code>current_op-&gt;output_operators</code>)；</li>
<li>如果1的某个后继节点没有被执行过(已执行标记为<code>False</code>)，则递归将<strong>该后继节点</strong>传入到<code>ReverseTopo</code>函数中；</li>
<li>第2步中的遍历结束后，将当前节点放入到执行队列(<code>topo_operators_</code>)中。</li>
</ol>
<p>当该函数结束后，对<strong>执行队列中的排序结果做逆序就得到了最终拓扑排序的结果</strong>，来看看具体的代码：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">RuntimeGraph::ReverseTopo</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::shared_ptr&lt;RuntimeOperator&gt;&amp; current_op)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">CHECK</span>(current_op != <span class="literal">nullptr</span>) &lt;&lt; <span class="string">&quot;current operator is nullptr&quot;</span>;</span><br><span class="line">  current_op-&gt;has_forward = <span class="literal">true</span>;</span><br><span class="line">  <span class="type">const</span> <span class="keyword">auto</span>&amp; next_ops = current_op-&gt;output_operators;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; [_, op] : next_ops) &#123;</span><br><span class="line">    <span class="keyword">if</span> (op != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!op-&gt;has_forward) &#123;</span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">ReverseTopo</span>(op);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; [_, op] : next_ops) &#123;</span><br><span class="line">    <span class="built_in">CHECK_EQ</span>(op-&gt;has_forward, <span class="literal">true</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">this</span>-&gt;topo_operators_.<span class="built_in">push_back</span>(current_op);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Operator-amp-Register-Factory"><a href="#Operator-amp-Register-Factory" class="headerlink" title="Operator &amp; Register Factory"></a>Operator &amp; Register Factory</h2><h3 id="Layer-类型的定义"><a href="#Layer-类型的定义" class="headerlink" title="Layer 类型的定义"></a>Layer 类型的定义</h3><ol>
<li><p>计算节点被称之为<code>RuntimeOperator</code>, 具体的结构定义如下的代码所示：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">RuntimeOperator</span> &#123;</span><br><span class="line"><span class="keyword">virtual</span> ~<span class="built_in">RuntimeOperator</span>();</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> has_forward = <span class="literal">false</span>;</span><br><span class="line">std::string name;      <span class="comment">/// 计算节点的名称</span></span><br><span class="line">std::string type;      <span class="comment">/// 计算节点的类型</span></span><br><span class="line">std::shared_ptr&lt;Layer&gt; layer;  <span class="comment">/// 节点对应的计算Layer</span></span><br><span class="line">   </span><br><span class="line">std::map&lt;std::string, std::shared_ptr&lt;RuntimeOperand&gt;&gt;</span><br><span class="line">      input_operands;  <span class="comment">/// 节点的输入操作数</span></span><br><span class="line">std::shared_ptr&lt;RuntimeOperand&gt; output_operands;  <span class="comment">/// 节点的输出操作数</span></span><br><span class="line">std::vector&lt;std::shared_ptr&lt;RuntimeOperand&gt;&gt;</span><br><span class="line">      input_operands_seq;  <span class="comment">/// 节点的输入操作数，顺序排列</span></span><br><span class="line">std::map&lt;std::string, std::shared_ptr&lt;RuntimeOperator&gt;&gt;</span><br><span class="line">      output_operators;  <span class="comment">/// 输出节点的名字和节点对应</span></span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在一个计算节点(<code>RuntimeOperator</code>)中，记录了与该节点相关的类型、名称，以及输入输出数等信息。其中最重要的是<code>layer</code>变量，它是具体计算的实施者。</p>
<p>通过访问<code>RuntimeOperator</code>的输入数(<code>input_operand</code>)，<code>layer</code>可以获取计算所需的输入张量数据，<strong>并根据<code>layer</code>各派生类别中定义的计算函数(<code>forward</code>)对输入张量数据进行计算</strong>。计算完成后，计算结果将存储在该节点的输出数(<code>output_operand</code>)中。</p>
</li>
<li><p>以下的代码位于<code>include/abstract/layer.hpp</code>中，<strong>它是所有算子的父类</strong>，如果要实现项目中其他的算子，都需要继承于该类作为派生类并重写其中的计算函数(<code>forward</code>)。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Layer</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="function"><span class="keyword">explicit</span> <span class="title">Layer</span><span class="params">(std::string layer_name)</span> : layer_name_(std::move(layer_name)) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">virtual</span> ~<span class="built_in">Layer</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Layer的执行函数</span></span><br><span class="line"><span class="comment">   * @param inputs 层的输入</span></span><br><span class="line"><span class="comment">   * @param outputs 层的输出</span></span><br><span class="line"><span class="comment">   * @return 执行的状态</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> InferStatus <span class="title">Forward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">const</span> std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt;&amp; inputs,</span></span></span><br><span class="line"><span class="params"><span class="function">      std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt;&amp; outputs)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Layer的执行函数</span></span><br><span class="line"><span class="comment">   * @param current_operator 当前的operator</span></span><br><span class="line"><span class="comment">   * @return 执行的状态</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> InferStatus <span class="title">Forward</span><span class="params">()</span></span>;</span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>以上的代码定义了<code>Layer</code>类的构造函数，它只需要一个<code>layer_name</code>变量来指定该算子的名称。重点关注带有参数的<code>Forward</code>方法，它是算子中定义的计算函数。</p>
<p>这个函数有两个参数，分别是<code>inputs</code>和<code>outputs</code>。它们是在计算过程中所需的输入和输出张量数组。<strong>每个算子的派生类都需要重写这个带参数的<code>Forward</code>方法，并在其中定义计算的具体逻辑。</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Layer</span> &#123;</span><br><span class="line">   ...</span><br><span class="line">   ...</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">std::weak_ptr&lt;RuntimeOperator&gt; runtime_operator_;</span><br><span class="line">std::string layer_name_;  <span class="comment">/// Layer的名称  </span></span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>在<code>Layer</code>类中有两个成员变量。一个是在构造函数中指定的算子名称 <code>layer_name</code>，另一个是与该算子关联的计算节点变量 <code>RuntimeOperator</code>。在之前回顾了 <code>RuntimeOperator</code> 的定义：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">RuntimeOperator</span> &#123;</span><br><span class="line">...</span><br><span class="line">std::shared_ptr&lt;Layer&gt; layer;  <span class="comment">/// 节点对应的计算Layer</span></span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">classDiagram</span><br><span class="line">      RuntimeOperator &lt;-- Layer</span><br><span class="line">      Layer &lt;-- RuntimeOperator </span><br><span class="line">      class RuntimeOperator&#123;</span><br><span class="line">         - Tensor Array inputs</span><br><span class="line">         - Tensor Array outputs</span><br><span class="line">         - Layer Reference layer</span><br><span class="line">      &#125;</span><br><span class="line">      class Layer&#123;</span><br><span class="line">      - RuntimeOperator Reference runtime_operator</span><br><span class="line">         + Forward(void) InferStatus</span><br><span class="line">      + Forward(inputs,outputs) InferStatus</span><br><span class="line">      &#125;</span><br><span class="line">      Layer &lt;|-- ReLULayer</span><br><span class="line">      Layer &lt;|-- ConvLayer</span><br><span class="line">      Layer &lt;|-- MaxPoolingLayer</span><br><span class="line">      class ReLULayer&#123;</span><br><span class="line">      + Forward(inputs,outputs) InferStatus</span><br><span class="line">      &#125;</span><br><span class="line">      class ConvLayer&#123;</span><br><span class="line">      + Forward(inputs,outputs) InferStatus</span><br><span class="line">      &#125;</span><br><span class="line">         class MaxPoolingLayer&#123;</span><br><span class="line">      + Forward(inputs,outputs) InferStatus</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure>

<p><code>RuntimeOperator</code>与该节点对应的 <code>Layer</code> 相关联，而 <code>Layer</code> 也关联了它所属的 <code>RuntimeOperator</code>，因此它们之间是双向关联的关系。</p>
<p><code>Layer</code> 类中不带参数的 <code>Forward</code> 方法。这个方法是所有算子的父类方法，<strong>它的作用是准备输入和输出数据，并使用这些数据调用每个派生类算子中各自实现的计算过程</strong>（上文提到的带参数的 <code>Forward</code> 函数）。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">InferStatus <span class="title">Layer::Forward</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="built_in">LOG_IF</span>(FATAL, <span class="keyword">this</span>-&gt;runtime_operator_.<span class="built_in">expired</span>())</span><br><span class="line">      &lt;&lt; <span class="string">&quot;Runtime operator is expired or nullptr&quot;</span>;</span><br><span class="line"><span class="comment">// 获取算子相关的计算节点</span></span><br><span class="line"><span class="type">const</span> <span class="keyword">auto</span>&amp; runtime_operator = <span class="keyword">this</span>-&gt;runtime_operator_.<span class="built_in">lock</span>();</span><br><span class="line"><span class="comment">// 准备节点layer计算所需要的输入</span></span><br><span class="line"><span class="type">const</span> std::vector&lt;std::shared_ptr&lt;RuntimeOperand&gt;&gt;&amp; input_operand_datas = runtime_operator-&gt;input_operands_seq;</span><br><span class="line"><span class="comment">// layer的输入</span></span><br><span class="line">std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt; layer_input_datas;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; input_operand_data : input_operand_datas) &#123;</span><br><span class="line">   <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; input_data : input_operand_data-&gt;datas) &#123;</span><br><span class="line">      layer_input_datas.<span class="built_in">push_back</span>(input_data);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在<code>Layer</code>类的不带参数的<code>Forward</code>方法中，首先获取与该<code>Layer</code>相对应的计算节点<code>RuntimeOperator</code>。它们之间是双向关联的关系，一个算子对应一个计算节点（<code>RuntimeOperator</code>），一个计算节点对应一个算子(<code>Layer</code>)。</p>
<p>从计算节点中得到<strong>该节点对应的输入数</strong><code>input_operand_datas</code>以及<strong>该输入数存储的张量数据</strong><code>layer_input_datas</code>. 随后，再从计算节点中取出对应的输出数<code>output_operand_datas</code>.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> std::shared_ptr&lt;RuntimeOperand&gt;&amp; output_operand_datas =</span><br><span class="line">      runtime_operator-&gt;output_operands;</span><br><span class="line">InferStatus status = runtime_operator-&gt;layer-&gt;<span class="built_in">Forward</span>(</span><br><span class="line">      layer_input_datas, output_operand_datas-&gt;datas);</span><br></pre></td></tr></table></figure>

<p>在以上的步骤中，从计算节点<code>RuntimeOperator</code>中获取了相关的输入数和输出数，随后再使用对应的输入和输出张量<strong>去调用子类算子各自实现的，带参数的<code>Forward</code>函数</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line"></span><br><span class="line">父类Layer中Foward不带参数的版本--准备输入输出--&gt; 各子类Layer中Foward带参数的版本;</span><br><span class="line">各子类Layer中Foward带参数的版本--&gt;Relu::Foward带参数版本</span><br><span class="line">各子类Layer中Foward带参数的版本--&gt;Conv::Foward带参数版本</span><br><span class="line">各子类Layer中Foward带参数的版本--&gt;MaxPool::Forward带参数版本</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="Convolution-amp-Pooling-Operator"><a href="#Convolution-amp-Pooling-Operator" class="headerlink" title="Convolution &amp; Pooling Operator"></a>Convolution &amp; Pooling Operator</h2><h3 id="池化算子的定义"><a href="#池化算子的定义" class="headerlink" title="池化算子的定义"></a>池化算子的定义</h3><p>池化算子常用于缓解深度神经网络对位置的过度敏感性。</p>
<p>池化算子会在固定形状的窗口（即池化窗口）内对输入数据的元素进行计算，计算结果可以是池化窗口内元素的最大值或平均值，这种运算被称为最大池化或平均池化。</p>
<img src="/2024/12/24/Kuiper-Infer/pooling.png" class="" title="pooling">

<p>对于带填充的池化算子，输出特征图的大小和输入特征图的大小之间有以下等式关系：<br>$$<br>output ,size&#x3D; floor(\frac{input,size+2\times padding-pooling,size}{stride}+1)<br>$$</p>
<h3 id="卷积算子的定义"><a href="#卷积算子的定义" class="headerlink" title="卷积算子的定义"></a>卷积算子的定义</h3><p>卷积是信号处理和图像处理中常用的运算操作之一。它通过将输入信号（如图像、音频等）与一个卷积核（也称为滤波器或权重）进行相乘和累加的过程，用于在深度神经网络中提取特定的特征。因此，可以说卷积是最常用的算子之一。</p>
<ul>
<li><p>卷积定义二维表示：</p>
<p>$$Y[i, j] &#x3D; \sum_{m} \sum_{n} H[m, n] \cdot X[i+m, j+n]$$</p>
</li>
</ul>
<p>其中，$X$表示输入矩阵，$H$表示卷积核，$Y$表示输出矩阵，$i$和$j$表示输出矩阵中的输出像素坐标，$m$和$n$表示卷积核中的坐标，$i+m$和$j+n$用于将卷积核和输入矩阵进行对齐，分别表示输入图像中的某个元素坐标。<strong>通过这两个偏移量，可以确定卷积核在输入矩阵中的位置，并将其与对应位置的像素值相乘，然后求和得到输出矩阵的每个元素 $Y[i,j]$。</strong></p>
<ul>
<li><p>二维卷积计算过程直观展示如下图，卷积核以滑动窗口的形式，从输入中划过，计算点积并求和，得到卷积后的输出存于<code>output</code>中。</p>
 <img src="/2024/12/24/Kuiper-Infer/single_channel_conv.png" class="" title="single channel conv">
</li>
<li><p>单通道可以直观地被拓展成多通道，只需对多个单通道的卷积结果求和即可（请注意，下图中的kernel属于同一个卷积核中的不同通道），此时需要注意的是输入的通道数与卷积核的通道数需要保持一致。</p>
<p>如下图所示，可以看到一个多通道的输入和一个多通道的卷积核进行卷积计算，最后得到了<strong>一个单通道的输出</strong><code>output</code>. <strong>输入张量的通道数需要和卷积核的通道数个数相同</strong>,这里都是2个通道</p>
<p>input第一个通道和kernel第一个通道 对应位置内求卷积</p>
<p>input第二个通道和kernel第二个通道对应位置内求卷积</p>
<p>两者相加，得到对应位置的输出</p>
 <img src="/2024/12/24/Kuiper-Infer/multi_channel_channel_conv.png" class="" title="multi channel conv">
</li>
<li><p>对于单通道输出，只需要一个卷积核就可以完成，<strong>如果想要使得输出为多通道，则需使用多个不同的卷积核，即卷积核个数对应输出通道个数</strong>。</p>
<p>如下图所示，可以看到，如果使用两个卷积核，最后会产生一个<strong>多通道的输出</strong><code>output</code>，它有两个通道，分别为<code>c1</code>和<code>c2</code>.</p>
<p>有一个输入，输入的通道数为2</p>
<p>取出input_channel &#x3D; 1的输入通道，它需要分别和卷积核1的通道1做卷积，和卷积核2的通道1做卷积，再把二者相加。</p>
<p>取出输入的第一个通道input c1</p>
<p>取出input_channel&#x3D;2，输入第二个通道，它需要和卷积核1的通道2做卷积，和卷积核2的通道2做卷积，再把二者相加。</p>
 <img src="/2024/12/24/Kuiper-Infer/multi_kernel_conv.png" class="" title="multi kernel conv">
</li>
<li><p>组卷积（<code>group conv</code>），顾名思义就是将卷积分组，即在深度上进行分组，假设group&#x3D;2，则表示将原有的输入数据分成2组，如上图图所示，原本一个卷积核管全部通道，当分组之后，一个卷积核只需要管$\frac{input,channel}{group} &#x3D; 2 &#x2F; 2  &#x3D; 1$个通道，即如下图所示。</p>
</li>
<li><p>分组卷积早在<code>AlexNet</code>便得到了应用，Alex认为组卷积能够增加 卷积核之间的对角相关性，并减少训练参数，不容易过拟合，达到类似正则的效果。从下图可以看出，如果对一个多通道的输入运用组卷积，最后得到了一个多通道的输出<code>output</code>, 它有两个通道，分别为<code>c1</code>和<code>c2</code>.</p>
 <img src="/2024/12/24/Kuiper-Infer/group_conv.png" class="" title="group conv"></li>
</ul>
<p>总结：以上是二维卷积的基本定义，二维卷积的直观解释。<strong>普通卷积核的通道数需要与输入数据的通道数保持一致，而卷积核的数量则代表了输出数据的通道数。分组卷积核的通道数为输入数据通道数&#x2F;分组数</strong>在卷积计算中，输入输出大小的维度有以下的对应关系：<br>$$<br>output, size &#x3D; floor(\frac{input,size+ 2\times padding-kernel ,size}{stride }+1)<br>$$</p>
<p>上图例子中：output size &#x3D; ((4+2*0-3)&#x2F;1+1)  &#x3D; 2</p>
<h2 id="Expression-Layer"><a href="#Expression-Layer" class="headerlink" title="Expression Layer"></a>Expression Layer</h2><h3 id="表达式的定义"><a href="#表达式的定义" class="headerlink" title="表达式的定义"></a>表达式的定义</h3><p><code>PNNX</code>中的表达式就是一个二元的计算过程，类似如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">output_mid = input1 + input2;</span><br><span class="line">output = output_mid * input3;</span><br></pre></td></tr></table></figure>

<p>在<code>PNNX</code>的表达式层（Expression Layer）中，提供了一种计算表达式，该表达式能够在一定程度上折叠计算过程并消除中间变量。例如，在残差结构中的add操作在<code>PNNX</code>中就是一个表达式层。</p>
<p>下面是<code>PNNX</code>中对上述过程的计算表达式表示，其中的<code>@0</code>和<code>@1</code>代表之前提到的计算数<code>RuntimeOperand</code>，用于表示计算表达式中的输入节点。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mul(@2, add(@0, @1));</span><br></pre></td></tr></table></figure>

<p>尽管这个抽象表达式看起来比较简单，但实际上可能存在更为复杂的情况，例如以下的例子。因此，在这种情况下，需要一个强大而可靠的表达式解析和语法树构建功能。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add(add(mul(@0, @1), mul(@2, add(add(add(@0, @2), @3), @4))), @5);</span><br></pre></td></tr></table></figure>

<h3 id="词法解析"><a href="#词法解析" class="headerlink" title="词法解析"></a>词法解析</h3><h4 id="词法的定义"><a href="#词法的定义" class="headerlink" title="词法的定义"></a>词法的定义</h4><p>词法解析的目的是将**add(@0, mul(@1, @2))**拆分为多个Token，拆分后的Token依次为：</p>
<ol>
<li>Identifier: <strong>add</strong></li>
<li>Left bracket: <strong>(</strong></li>
<li>Input number: <strong>@0</strong></li>
<li>Comma: <strong>,</strong></li>
<li>Identifier: <strong>mul</strong></li>
<li>Left bracket: <strong>(</strong></li>
<li>Input number: <strong>@1</strong></li>
<li>Comma: <strong>,</strong></li>
<li>Input number:  <strong>@2</strong></li>
<li>Right bracket: <strong>)</strong></li>
</ol>
<p><code>Token</code>的类型定义如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum class</span> <span class="title class_">TokenType</span> &#123;</span><br><span class="line">  TokenUnknown = <span class="number">-9</span>,</span><br><span class="line">  TokenInputNumber = <span class="number">-8</span>,</span><br><span class="line">  TokenComma = <span class="number">-7</span>,</span><br><span class="line">  TokenAdd = <span class="number">-6</span>,</span><br><span class="line">  TokenMul = <span class="number">-5</span>,</span><br><span class="line">  TokenLeftBracket = <span class="number">-4</span>,</span><br><span class="line">  TokenRightBracket = <span class="number">-3</span>,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>Token的定义如下，包括以下变量：</p>
<ol>
<li>Token类型，包括add（加法），mul（乘法），bracket（左右括号）等；</li>
<li>Token在原句子中的开始和结束位置，即<code>start_pos</code>和<code>end_pos</code>；</li>
</ol>
<p>对于表达式**add(@0, mul(@1, @2))**，可以将它切分为多个Token，其中Token(add)的<code>start_pos</code>为0，<code>end_pos</code>为3。Token(left bracket)的<code>start_pos</code>为3，<code>end_pos</code>为4。Token(@0)的<code>start_pos</code>为4，<code>end_pos</code>为5，以此类推。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 词语Token</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Token</span> &#123;</span><br><span class="line">    TokenType token_type = TokenType::TokenUnknown;</span><br><span class="line">    <span class="type">int32_t</span> start_pos = <span class="number">0</span>; <span class="comment">// 词语开始的位置</span></span><br><span class="line">    <span class="type">int32_t</span> end_pos = <span class="number">0</span>;   <span class="comment">// 词语结束的位置</span></span><br><span class="line">    <span class="built_in">Token</span>(TokenType token_type, <span class="type">int32_t</span> start_pos, <span class="type">int32_t</span> end_pos)</span><br><span class="line">        : <span class="built_in">token_type</span>(token_type), <span class="built_in">start_pos</span>(start_pos), <span class="built_in">end_pos</span>(end_pos) &#123;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>最后，在词法解析结束后，需要将这些 Token（词语）按照它们的出现顺序和层级关系组成一棵语法树。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 语法树的节点</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">TokenNode</span> &#123;</span><br><span class="line">    <span class="type">int32_t</span> num_index = <span class="number">-1</span>;</span><br><span class="line">    std::shared_ptr&lt;TokenNode&gt; left = <span class="literal">nullptr</span>;   <span class="comment">// 语法树的左节点</span></span><br><span class="line">    std::shared_ptr&lt;TokenNode&gt; right = <span class="literal">nullptr</span>;  <span class="comment">// 语法树的右节点</span></span><br><span class="line">    <span class="built_in">TokenNode</span>(<span class="type">int32_t</span> num_index, std::shared_ptr&lt;TokenNode&gt; left,</span><br><span class="line">              std::shared_ptr&lt;TokenNode&gt; right);</span><br><span class="line">    <span class="built_in">TokenNode</span>() = <span class="keyword">default</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="词法的解析"><a href="#词法的解析" class="headerlink" title="词法的解析"></a>词法的解析</h4><h5 id="判断句子是否为空"><a href="#判断句子是否为空" class="headerlink" title="判断句子是否为空"></a>判断句子是否为空</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">CHECK</span>(!statement_.<span class="built_in">empty</span>()) &lt;&lt; <span class="string">&quot;The input statement is empty!&quot;</span>;</span><br></pre></td></tr></table></figure>

<h5 id="移除句子中的空格"><a href="#移除句子中的空格" class="headerlink" title="移除句子中的空格"></a>移除句子中的空格</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">statement_.<span class="built_in">erase</span>(std::<span class="built_in">remove_if</span>(statement_.<span class="built_in">begin</span>(), statement_.<span class="built_in">end</span>(),</span><br><span class="line">                                [](<span class="type">char</span> c) &#123; <span class="keyword">return</span> std::<span class="built_in">isspace</span>(c); &#125;),</span><br><span class="line">                 statement_.<span class="built_in">end</span>());</span><br><span class="line"><span class="built_in">CHECK</span>(!statement_.<span class="built_in">empty</span>()) &lt;&lt; <span class="string">&quot;The input statement is empty!&quot;</span>;</span><br></pre></td></tr></table></figure>

<p>如果表达式层中有表达式为<code>add(@0,   @1)</code>，删除其中的空格后就会得到新的表达式<code>add(@0,@1)</code>。</p>
<h5 id="逐个解析句子的字符"><a href="#逐个解析句子的字符" class="headerlink" title="逐个解析句子的字符"></a>逐个解析句子的字符</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; statement_.<span class="built_in">size</span>();) &#123;</span><br><span class="line">    <span class="type">char</span> c = statement_.<span class="built_in">at</span>(i);</span><br><span class="line">    <span class="keyword">if</span> (c == <span class="string">&#x27;a&#x27;</span>) &#123;</span><br><span class="line">        <span class="built_in">CHECK</span>(i + <span class="number">1</span> &lt; statement_.<span class="built_in">size</span>() &amp;&amp; statement_.<span class="built_in">at</span>(i + <span class="number">1</span>) == <span class="string">&#x27;d&#x27;</span>)</span><br><span class="line">            &lt;&lt; <span class="string">&quot;Parse add token failed, illegal character: &quot;</span></span><br><span class="line">            &lt;&lt; statement_.<span class="built_in">at</span>(i + <span class="number">1</span>);</span><br><span class="line">        <span class="built_in">CHECK</span>(i + <span class="number">2</span> &lt; statement_.<span class="built_in">size</span>() &amp;&amp; statement_.<span class="built_in">at</span>(i + <span class="number">2</span>) == <span class="string">&#x27;d&#x27;</span>)</span><br><span class="line">            &lt;&lt; <span class="string">&quot;Parse add token failed, illegal character: &quot;</span></span><br><span class="line">            &lt;&lt; statement_.<span class="built_in">at</span>(i + <span class="number">2</span>);</span><br><span class="line">        <span class="function">Token <span class="title">token</span><span class="params">(TokenType::TokenAdd, i, i + <span class="number">3</span>)</span></span>;</span><br><span class="line">        tokens_.<span class="built_in">push_back</span>(token);</span><br><span class="line">        std::string token_operation =</span><br><span class="line">            std::<span class="built_in">string</span>(statement_.<span class="built_in">begin</span>() + i, statement_.<span class="built_in">begin</span>() + i + <span class="number">3</span>);</span><br><span class="line">        token_strs_.<span class="built_in">push_back</span>(token_operation);</span><br><span class="line">        i = i + <span class="number">3</span>;</span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假设字符 <code>c</code> 表示当前的字符。如果 <code>c</code> 等于字符 ‘a’，根据的词法规定，Token 中以 ‘a’ 开头的情况只有 add。因此，需要判断接下来的两个字符是否分别是 ‘d’ 和 ‘d’。如果不是，则报错。如果是的话，则初始化一个新的 Token，并保存其在表达式中的初始和结束位置。</p>
<p>举个例子，如果表达式中的单词以 ‘a’ 开头，那么它只能是 add，而不能是其他词汇表之外的单词，例如 <code>axc</code> 等情况。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">CHECK</span>(i + <span class="number">1</span> &lt; statement_.<span class="built_in">size</span>() &amp;&amp; statement_.<span class="built_in">at</span>(i + <span class="number">1</span>) == <span class="string">&#x27;d&#x27;</span>)</span><br><span class="line">    &lt;&lt; <span class="string">&quot;Parse add token failed, illegal character: &quot;</span></span><br><span class="line">    &lt;&lt; statement_.<span class="built_in">at</span>(i + <span class="number">1</span>);</span><br><span class="line"><span class="built_in">CHECK</span>(i + <span class="number">2</span> &lt; statement_.<span class="built_in">size</span>() &amp;&amp; statement_.<span class="built_in">at</span>(i + <span class="number">2</span>) == <span class="string">&#x27;d&#x27;</span>)</span><br><span class="line">    &lt;&lt; <span class="string">&quot;Parse add token failed, illegal character: &quot;</span></span><br><span class="line">    &lt;&lt; statement_.<span class="built_in">at</span>(i + <span class="number">2</span>);</span><br><span class="line"><span class="function">Token <span class="title">token</span><span class="params">(TokenType::TokenAdd, i, i + <span class="number">3</span>)</span></span>;</span><br><span class="line">tokens_.<span class="built_in">push_back</span>(token);</span><br><span class="line">std::string token_operation =</span><br><span class="line">    std::<span class="built_in">string</span>(statement_.<span class="built_in">begin</span>() + i, statement_.<span class="built_in">begin</span>() + i + <span class="number">3</span>);</span><br><span class="line">token_strs_.<span class="built_in">push_back</span>(token_operation);</span><br></pre></td></tr></table></figure>

<p>如果在第一行中，判断第二个字符是否为 ‘d’；若是，在第二行中，判断第三个字符是否也是 ‘d’。如果满足条件，将初始化一个 Token 实例，并保存该单词在句子中的起始位置和结束位置。</p>
<p>同样地，如果某个字符 <code>c</code> 是 ‘m’，需要判断接下来的字符是否是 ‘u’ 和 ‘l’。如果不满足条件，则说明的表达式中出现了词汇表之外的单词（因为词汇表只允许以 ‘m’ 开头的单词是 “mul”）。如果满足条件，同样会初始化一个 Token 实例，并保存该单词的起始和结束位置，以及 Token 的类型。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (c == <span class="string">&#x27;@&#x27;</span>) &#123;</span><br><span class="line">    <span class="built_in">CHECK</span>(i + <span class="number">1</span> &lt; statement_.<span class="built_in">size</span>() &amp;&amp; std::<span class="built_in">isdigit</span>(statement_.<span class="built_in">at</span>(i + <span class="number">1</span>)))</span><br><span class="line">        &lt;&lt; <span class="string">&quot;Parse number token failed, illegal character: &quot;</span> &lt;&lt; c;</span><br><span class="line">    <span class="type">int32_t</span> j = i + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (; j &lt; statement_.<span class="built_in">size</span>(); ++j) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!std::<span class="built_in">isdigit</span>(statement_.<span class="built_in">at</span>(j))) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">Token <span class="title">token</span><span class="params">(TokenType::TokenInputNumber, i, j)</span></span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(token.start_pos &lt; token.end_pos);</span><br><span class="line">    tokens_.<span class="built_in">push_back</span>(token);</span><br><span class="line">    std::string token_input_number = std::<span class="built_in">string</span>(statement_.<span class="built_in">begin</span>() + i, statement_.<span class="built_in">begin</span>() + j);</span><br><span class="line">    token_strs_.<span class="built_in">push_back</span>(token_input_number);</span><br><span class="line">    i = j;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果第一个字符是 ‘@’，需要读取 ‘@’ 后面的所有数字，例如对于@31231，需要读取@符号之后的所有数字。如果紧跟在 ‘@’ 后面的字符不是数字，则报错。如果是数字，则将这些数字全部读取并组成一个单词（Token）。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (c == <span class="string">&#x27;,&#x27;</span>) &#123;</span><br><span class="line">      Token <span class="built_in">token</span>(TokenType::TokenComma, i, i + <span class="number">1</span>);</span><br><span class="line">      tokens_.<span class="built_in">push_back</span>(token);</span><br><span class="line">      std::string token_comma =</span><br><span class="line">          std::<span class="built_in">string</span>(statement_.<span class="built_in">begin</span>() + i, statement_.<span class="built_in">begin</span>() + i + <span class="number">1</span>);</span><br><span class="line">      token_strs_.<span class="built_in">push_back</span>(token_comma);</span><br><span class="line">      i += <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果第一个字符是’,’逗号，那么直接读取这个字符作为一个新的Token。</p>
<p>最后，在正确解析和创建这些 Token 后，将它们放入名为 <code>tokens</code> 的数组中，以便进行后续处理。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokens_.<span class="built_in">push_back</span>(token);</span><br></pre></td></tr></table></figure>

<h3 id="语法解析"><a href="#语法解析" class="headerlink" title="语法解析"></a>语法解析</h3><h4 id="语法树的定义"><a href="#语法树的定义" class="headerlink" title="语法树的定义"></a>语法树的定义</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">TokenNode</span> &#123;</span><br><span class="line">    <span class="type">int32_t</span> num_index = <span class="number">-1</span>;</span><br><span class="line">    std::shared_ptr&lt;TokenNode&gt; left = <span class="literal">nullptr</span>;</span><br><span class="line">    std::shared_ptr&lt;TokenNode&gt; right = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="built_in">TokenNode</span>(<span class="type">int32_t</span> num_index, std::shared_ptr&lt;TokenNode&gt; left, std::shared_ptr&lt;TokenNode&gt; right);</span><br><span class="line">    <span class="built_in">TokenNode</span>() = <span class="keyword">default</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>在进行语法分析时，可以根据词法分析得到的 <code>token</code> 数组构建抽象语法树。抽象语法树是一个由二叉树组成的结构，每个节点都存储了操作符号或值，并通过左子节点和右子节点与其他节点连接。</p>
<p>对于表达式 “add (@0, @1)”，当 <code>num_index</code> 等于 1 时，表示计算数为 @0；当 <code>num_index</code> 等于 2 时，表示计算数为 @1。若 <code>num_index</code> 为负数，则说明当前节点是一个计算节点，如 “mul” 或 “add” 等。</p>
<p>以下是一个简单的示例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">   add</span><br><span class="line">  /   \</span><br><span class="line">@0     @1</span><br></pre></td></tr></table></figure>

<p>在这个示例中，根节点是 “add”，左子节点是 “@0”，右子节点是 “@1”。这个抽象语法树表示了一个将 “@0” 和 “@1” 进行相加的表达式。</p>
<p>通过将词法分析得到的 <code>token</code> 数组解析并构建抽象语法树，可以进一步对表达式进行语义分析和求值等操作。</p>
<h4 id="递归向下的解析"><a href="#递归向下的解析" class="headerlink" title="递归向下的解析"></a>递归向下的解析</h4><p>语法解析的过程是递归向下的,定义在<code>Generate_</code>函数中。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::shared_ptr&lt;TokenNode&gt; <span class="title">ExpressionParser::Generate_</span><span class="params">(<span class="type">int32_t</span> &amp;index)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>());</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> current_token = <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index);</span><br><span class="line">    <span class="built_in">CHECK</span>(current_token.token_type == TokenType::TokenInputNumber</span><br><span class="line">          || current_token.token_type == TokenType::TokenAdd || current_token.token_type == TokenType::TokenMul);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个函数处理的对象是词法解析的Token（单词）数组，因为<code>Generate_</code>是一个递归函数，所以<code>index</code>参数指向Token数组中的当前处理位置.</p>
<p><code>current_token</code>表示当前被处理的Token，它作为<strong>当前递归层</strong>的第一个Token，必须是以下类型之一。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">TokenInputNumber = <span class="number">0</span>,</span><br><span class="line">TokenAdd = <span class="number">2</span>,</span><br><span class="line">TokenMul = <span class="number">3</span>,</span><br></pre></td></tr></table></figure>

<p><strong>如果当前Token的类型是输入数字类型，那么会直接返回一个操作数Token作为叶子节点，不再进行下一层递归（如下）。</strong>例如，在表达式add(@0, @1)中的@0和@1被归类为输入数字类型的Token，在解析到这两个Token时会直接创建并返回语法树节点<code>TokenNode</code>。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (current_token.token_type == TokenType::TokenInputNumber) &#123;</span><br><span class="line">    <span class="type">uint32_t</span> start_pos = current_token.start_pos + <span class="number">1</span>;</span><br><span class="line">    <span class="type">uint32_t</span> end_pos = current_token.end_pos;</span><br><span class="line">    <span class="built_in">CHECK</span>(end_pos &gt; start_pos);</span><br><span class="line">    <span class="built_in">CHECK</span>(end_pos &lt;= <span class="keyword">this</span>-&gt;statement_.<span class="built_in">length</span>());</span><br><span class="line">    <span class="type">const</span> std::string &amp;str_number =</span><br><span class="line">        std::<span class="built_in">string</span>(<span class="keyword">this</span>-&gt;statement_.<span class="built_in">begin</span>() + start_pos, <span class="keyword">this</span>-&gt;statement_.<span class="built_in">begin</span>() + end_pos);</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">make_shared</span>&lt;TokenNode&gt;(std::<span class="built_in">stoi</span>(str_number), <span class="literal">nullptr</span>, <span class="literal">nullptr</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>如果当前Token的类型是mul或者add，需要进行下一层递归来构建对应的左子节点和右子节点。</strong></p>
<p>例如，在处理add(@1,@2)时，遇到add token之后，如下的第一行代码，需要做以下的两步：</p>
<ol>
<li>首先判断是否存在左括号（left bracket）</li>
<li>然后继续向下递归以获取@1，如下的第14行到17行代码，但由于@1代表的是数字类型，递归后立即返回，如以上代码块中第一行对数字类型Token的处理。</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (current_token.token_type == TokenType::TokenMul || current_token.token_type == TokenType::TokenAdd) &#123;</span><br><span class="line">    std::shared_ptr&lt;TokenNode&gt; current_node = std::<span class="built_in">make_shared</span>&lt;TokenNode&gt;();</span><br><span class="line">    current_node-&gt;num_index = -<span class="built_in">int</span>(current_token.token_type);</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>());</span><br><span class="line">    <span class="comment">// 判断add之后是否有( left bracket</span></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index).token_type == TokenType::TokenLeftBracket);</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>());</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> left_token = <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index);</span><br><span class="line">    <span class="comment">// 判断当前需要处理的left token是不是合法类型</span></span><br><span class="line">    <span class="keyword">if</span> (left_token.token_type == TokenType::TokenInputNumber</span><br><span class="line">        || left_token.token_type == TokenType::TokenAdd || left_token.token_type == TokenType::TokenMul) &#123;</span><br><span class="line">        <span class="comment">// (之后进行向下递归得到@0</span></span><br><span class="line">        current_node-&gt;left = <span class="built_in">Generate_</span>(index);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown token type: &quot;</span> &lt;&lt; <span class="built_in">int</span>(left_token.token_type);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在第17行当左子树递归构建完毕后，将它赋值到add节点的左子树上。对于表达式<code>add(@0, @1)</code>，将左子树连接到<code>current_node</code>的<code>left</code>指针中，随后开始构建右子树。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">graph TB;</span><br><span class="line">1((add))--&gt;2((ant 0))</span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">index += <span class="number">1</span>; </span><br><span class="line"><span class="comment">// 当前的index指向add(@1,@2)中的逗号</span></span><br><span class="line"><span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>());</span><br><span class="line"><span class="comment">// 判断是否是逗号</span></span><br><span class="line"><span class="built_in">CHECK</span>(<span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index).token_type == TokenType::TokenComma);</span><br><span class="line"></span><br><span class="line">index += <span class="number">1</span>;</span><br><span class="line"><span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>());</span><br><span class="line"><span class="comment">// current_node-&gt;right = Generate_(index);构建右子树</span></span><br><span class="line"><span class="type">const</span> <span class="keyword">auto</span> right_token = <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index);</span><br><span class="line"><span class="keyword">if</span> (right_token.token_type == TokenType::TokenInputNumber</span><br><span class="line">    || right_token.token_type == TokenType::TokenAdd || right_token.token_type == TokenType::TokenMul) &#123;</span><br><span class="line">  current_node-&gt;right = <span class="built_in">Generate_</span>(index);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown token type: &quot;</span> &lt;&lt; <span class="built_in">int</span>(left_token.token_type);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">index += <span class="number">1</span>;</span><br><span class="line"><span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>());</span><br><span class="line"><span class="built_in">CHECK</span>(<span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index).token_type == TokenType::TokenRightBracket);</span><br><span class="line"><span class="keyword">return</span> current_node;</span><br></pre></td></tr></table></figure>

<p>随后需要判断@0之后是否存在comma token，如上代码中的第五行。在构建右子树的过程中，对于表达式<code>add(@1,@2)</code>，当<code>index</code>指向逗号的位置时，首先需要判断是否存在逗号。接下来，开始构建右子树，在右子树的向下递归分析中，会得到<code>@2</code>作为一个叶子节点。</p>
<p>当右子树构建完成后，将该节点（即<code>Generate_</code>返回的<code>TokenNode</code>，此处为一个叶子节点，其数据为<code>@1</code>）放置于<code>current_node</code>的<code>right</code>指针中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">graph TB;</span><br><span class="line">1((add))--&gt;2((ant 0))</span><br><span class="line"></span><br><span class="line">1((add))--&gt;3((ant 1))</span><br></pre></td></tr></table></figure>

<h3 id="对语法树的转换"><a href="#对语法树的转换" class="headerlink" title="对语法树的转换"></a>对语法树的转换</h3><h4 id="逆波兰式"><a href="#逆波兰式" class="headerlink" title="逆波兰式"></a>逆波兰式</h4><p>来以一个简单的例子来说明，对于计算式<code>add(@0,@1)</code>，首先遇到的节点是<code>add</code>，但在遇到<code>add</code>时缺少进行计算所需的具体数据<code>@0</code>和<code>@1</code>。</p>
<p><strong>因此，需要进行逆波兰转换，将操作数放在前面，计算放在后面。</strong>该转换的实现非常简单，<strong>只需对原有的二叉树进行后续遍历即可：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">ReversePolish</span><span class="params">(<span class="type">const</span> std::shared_ptr&lt;TokenNode&gt; &amp;root_node,</span></span></span><br><span class="line"><span class="params"><span class="function">                   std::vector&lt;std::shared_ptr&lt;TokenNode&gt;&gt; &amp;reverse_polish)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (root_node != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="built_in">ReversePolish</span>(root_node-&gt;left, reverse_polish);</span><br><span class="line">        <span class="built_in">ReversePolish</span>(root_node-&gt;right, reverse_polish);</span><br><span class="line">        reverse_polish.<span class="built_in">push_back</span>(root_node);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>逆波兰式化后的表达如下：</p>
<p>对于 <code>add (@0,@1)</code>，逆波兰式为：<code>@0,@1,add</code></p>
<p>对于 <code>add(mul(@0,@1),@2)</code>，逆波兰式为：<code>@0,@1,mul,@2,add</code></p>
<p><strong>通过逆波兰转换，可以将原式转换为计算式的输入数放在前面，操作符号放在后面的形式。</strong>逆波兰式的特点是消除了括号的需求，使得计算顺序更加清晰和直观。</p>
<h3 id="过程总述"><a href="#过程总述" class="headerlink" title="过程总述"></a>过程总述</h3><p>经过这样的转换，可以确保在每次遇到计算节点时所需的操作数已经准备就绪。</p>
<ol>
<li>首先，传入一个表达式字符串，例如add(mul(@0,@1),@2)</li>
<li>接下来，对add(mul(@0,@1),@2)进行词法分析，将其拆分为多个tokens，在拆分过程中需要进行词法校验。</li>
<li>然后，根据已知的tokens数组，通过递归向下遍历进行语法分析，从而得到相应的计算二叉树。计算二叉树的各个节点可以是add、mul或者@0、@1等。</li>
<li>最后，对计算二叉树进行逆波兰变换，得到的逆波兰式如下：@0,@1,mul,@2,add。</li>
</ol>
<h2 id="ResNet-amp-YOLOv5-Infer"><a href="#ResNet-amp-YOLOv5-Infer" class="headerlink" title="ResNet &amp; YOLOv5 Infer"></a>ResNet &amp; YOLOv5 Infer</h2><p>TODO</p>
<h2 id="homework"><a href="#homework" class="headerlink" title="homework"></a>homework</h2><h3 id="course1"><a href="#course1" class="headerlink" title="course1"></a>course1</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// axby.cpp</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Axby</span><span class="params">(<span class="type">const</span> arma::fmat &amp;x, <span class="type">const</span> arma::fmat &amp;w, <span class="type">const</span> arma::fmat &amp;b,</span></span></span><br><span class="line"><span class="params"><span class="function">          arma::fmat &amp;y)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 把代码写这里 完成y = w * x + b的运算</span></span><br><span class="line">  y = w * x + b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">EPowerMinus</span><span class="params">(<span class="type">const</span> arma::fmat &amp;x, arma::fmat &amp;y)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 把代码写这里 完成y = e^&#123;-x&#125;的运算</span></span><br><span class="line">  <span class="function">arma::fmat <span class="title">eMat</span><span class="params">(x.n_rows, x.n_cols)</span></span>;</span><br><span class="line">  eMat.<span class="built_in">fill</span>(std::<span class="built_in">exp</span>(<span class="number">1.0</span>));</span><br><span class="line">  y = arma::<span class="built_in">pow</span>(eMat, -x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="course2"><a href="#course2" class="headerlink" title="course2"></a>course2</h3><ol>
<li>Tensor::Flatten</li>
<li>Tensor::Padding</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// tensor.cpp</span></span><br><span class="line"><span class="type">void</span> Tensor&lt;<span class="type">float</span>&gt;::<span class="built_in">Flatten</span>(<span class="type">bool</span> row_major) &#123;</span><br><span class="line">  <span class="type">const</span> std::vector&lt;<span class="type">uint32_t</span>&gt; flatten_size = &#123;<span class="keyword">this</span>-&gt;<span class="built_in">size</span>()&#125;;</span><br><span class="line">  <span class="keyword">this</span>-&gt;<span class="built_in">Reshape</span>(flatten_size, row_major);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> Tensor&lt;<span class="type">float</span>&gt;::<span class="built_in">Padding</span>(<span class="type">const</span> std::vector&lt;<span class="type">uint32_t</span>&gt;&amp; pads,</span><br><span class="line">                            <span class="type">float</span> padding_value) &#123;</span><br><span class="line">    <span class="built_in">CHECK</span>(!<span class="keyword">this</span>-&gt;data_.<span class="built_in">empty</span>());</span><br><span class="line">    <span class="built_in">CHECK_EQ</span>(pads.<span class="built_in">size</span>(), <span class="number">4</span>);</span><br><span class="line">    <span class="comment">// 四周填充的维度</span></span><br><span class="line">    <span class="type">uint32_t</span> pad_rows1 = pads.<span class="built_in">at</span>(<span class="number">0</span>);  <span class="comment">// up</span></span><br><span class="line">    <span class="type">uint32_t</span> pad_rows2 = pads.<span class="built_in">at</span>(<span class="number">1</span>);  <span class="comment">// bottom</span></span><br><span class="line">    <span class="type">uint32_t</span> pad_cols1 = pads.<span class="built_in">at</span>(<span class="number">2</span>);  <span class="comment">// left</span></span><br><span class="line">    <span class="type">uint32_t</span> pad_cols2 = pads.<span class="built_in">at</span>(<span class="number">3</span>);  <span class="comment">// right</span></span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> rows = <span class="keyword">this</span>-&gt;<span class="built_in">rows</span>();</span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> cols = <span class="keyword">this</span>-&gt;<span class="built_in">cols</span>();</span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> channels = <span class="keyword">this</span>-&gt;data_.n_slices;</span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> new_rows = rows + pad_rows1 + pad_rows2;</span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> new_cols = cols + pad_cols1 + pad_cols2;</span><br><span class="line"></span><br><span class="line">    arma::fcube new_data = arma::<span class="built_in">fcube</span>(new_rows, new_cols, channels);</span><br><span class="line">    new_data.<span class="built_in">fill</span>(padding_value);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 方式一：通过循环逐个赋值填充（记录开始时间，精确到纳秒）</span></span><br><span class="line">    <span class="keyword">auto</span> start_loop = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">uint32_t</span> c = <span class="number">0</span>; c &lt; channels; ++c) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; rows; ++i) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">uint32_t</span> j = <span class="number">0</span>; j &lt; cols; ++j) &#123;</span><br><span class="line">                new_data.<span class="built_in">at</span>(i + pad_rows1, j + pad_cols1, c) = <span class="keyword">this</span>-&gt;data_.<span class="built_in">at</span>(i, j, c);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">auto</span> end_loop = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">    <span class="keyword">auto</span> duration_loop = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::nanoseconds&gt;(end_loop - start_loop).<span class="built_in">count</span>();</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Time taken by loop-based padding (in nanoseconds): &quot;</span> &lt;&lt; duration_loop &lt;&lt; <span class="string">&quot; ns&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 重置new_data，重新填充初始值，为方式二做准备</span></span><br><span class="line">    new_data.<span class="built_in">fill</span>(padding_value);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 方式二：使用subcube赋值填充（记录开始时间，精确到纳秒）</span></span><br><span class="line">    <span class="keyword">auto</span> start_subcube = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">    new_data.<span class="built_in">subcube</span>(pad_rows1, pad_cols1, <span class="number">0</span>, new_rows - pad_rows2 - <span class="number">1</span>,</span><br><span class="line">                     new_cols - pad_cols2 - <span class="number">1</span>, channels - <span class="number">1</span>) = <span class="keyword">this</span>-&gt;data_;</span><br><span class="line">    <span class="keyword">auto</span> end_subcube = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">    <span class="keyword">auto</span> duration_subcube = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::nanoseconds&gt;(end_subcube - start_subcube).<span class="built_in">count</span>();</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Time taken by subcube-based padding (in nanoseconds): &quot;</span> &lt;&lt; duration_subcube &lt;&lt; <span class="string">&quot; ns&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">this</span>-&gt;data_ = std::<span class="built_in">move</span>(new_data);</span><br><span class="line">    <span class="keyword">this</span>-&gt;raw_shapes_ = std::vector&lt;<span class="type">uint32_t</span>&gt;&#123;channels, new_rows, new_cols&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="course3"><a href="#course3" class="headerlink" title="course3"></a>course3</h3><ol>
<li>RuntimeGraph::InitGraphParams</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// runtime_ir.cpp</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">RuntimeGraph::InitGraphParams</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">const</span> std::map&lt;std::string, pnnx::Parameter&gt; &amp;params,</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">const</span> std::shared_ptr&lt;RuntimeOperator&gt; &amp;runtime_operator)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span> &amp;[name, parameter]: params) &#123;</span><br><span class="line">      <span class="type">const</span> <span class="type">int</span> type = parameter.type;</span><br><span class="line">      <span class="keyword">switch</span> (type) &#123;</span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">int</span><span class="params">(RuntimeParameterType::kParameterUnknown)</span>: &#123;</span></span><br><span class="line">               RuntimeParameter *runtime_parameter = <span class="keyword">new</span> RuntimeParameter;</span><br><span class="line">               runtime_operator-&gt;params.<span class="built_in">insert</span>(&#123;name, runtime_parameter&#125;);</span><br><span class="line">               <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">int</span><span class="params">(RuntimeParameterType::kParameterBool)</span>: &#123;</span></span><br><span class="line">               RuntimeParameterBool *runtime_parameter = <span class="keyword">new</span> RuntimeParameterBool;</span><br><span class="line">               runtime_parameter-&gt;value = parameter.b;</span><br><span class="line">               runtime_operator-&gt;params.<span class="built_in">insert</span>(&#123;name, runtime_parameter&#125;);</span><br><span class="line">               <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">int</span><span class="params">(RuntimeParameterType::kParameterInt)</span>: &#123;</span></span><br><span class="line">               RuntimeParameterInt *runtime_parameter = <span class="keyword">new</span> RuntimeParameterInt;</span><br><span class="line">               runtime_parameter-&gt;value = parameter.i;</span><br><span class="line">               runtime_operator-&gt;params.<span class="built_in">insert</span>(&#123;name, runtime_parameter&#125;);</span><br><span class="line">               <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">int</span><span class="params">(RuntimeParameterType::kParameterFloat)</span>: &#123;</span></span><br><span class="line">               RuntimeParameterFloat *runtime_parameter = <span class="keyword">new</span> RuntimeParameterFloat;</span><br><span class="line">               runtime_parameter-&gt;value = parameter.f;</span><br><span class="line">               runtime_operator-&gt;params.<span class="built_in">insert</span>(&#123;name, runtime_parameter&#125;);</span><br><span class="line">               <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">int</span><span class="params">(RuntimeParameterType::kParameterString)</span>: &#123;</span></span><br><span class="line">               RuntimeParameterString *runtime_parameter = <span class="keyword">new</span> RuntimeParameterString;</span><br><span class="line">               runtime_parameter-&gt;value = parameter.s;</span><br><span class="line">               runtime_operator-&gt;params.<span class="built_in">insert</span>(&#123;name, runtime_parameter&#125;);</span><br><span class="line">               <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">int</span><span class="params">(RuntimeParameterType::kParameterIntArray)</span>: &#123;</span></span><br><span class="line">               RuntimeParameterIntArray *runtime_parameter =</span><br><span class="line">                        <span class="keyword">new</span> RuntimeParameterIntArray;</span><br><span class="line">               runtime_parameter-&gt;value = parameter.ai;</span><br><span class="line">               runtime_operator-&gt;params.<span class="built_in">insert</span>(&#123;name, runtime_parameter&#125;);</span><br><span class="line">               <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">int</span><span class="params">(RuntimeParameterType::kParameterFloatArray)</span>: &#123;</span></span><br><span class="line">               RuntimeParameterFloatArray *runtime_parameter =</span><br><span class="line">                        <span class="keyword">new</span> RuntimeParameterFloatArray;</span><br><span class="line">               runtime_parameter-&gt;value = parameter.af;</span><br><span class="line">               runtime_operator-&gt;params.<span class="built_in">insert</span>(&#123;name, runtime_parameter&#125;);</span><br><span class="line">               <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">int</span><span class="params">(RuntimeParameterType::kParameterStringArray)</span>: &#123;</span></span><br><span class="line">               RuntimeParameterStringArray *runtime_parameter =</span><br><span class="line">                        <span class="keyword">new</span> RuntimeParameterStringArray;</span><br><span class="line">               runtime_parameter-&gt;value = parameter.as;</span><br><span class="line">               runtime_operator-&gt;params.<span class="built_in">insert</span>(&#123;name, runtime_parameter&#125;);</span><br><span class="line">               <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">default</span>: &#123;</span><br><span class="line">               <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown parameter type: &quot;</span> &lt;&lt; type;</span><br><span class="line">            &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="course4"><a href="#course4" class="headerlink" title="course4"></a>course4</h3><ol>
<li>TopoSort</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// runtime_ir.hpp</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">KahnTopoSort</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// runtime_ir.cpp</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">RuntimeGraph::KahnTopoSort</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::unordered_map&lt;std::shared_ptr&lt;RuntimeOperator&gt;, <span class="type">int</span>&gt; in_degree;</span><br><span class="line">    std::queue&lt;std::shared_ptr&lt;RuntimeOperator&gt;&gt; zero_in_degree_queue;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算所有节点的入度</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; op : operators_) &#123;</span><br><span class="line">        in_degree[op] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; op : operators_) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; [_, next_op] : op-&gt;output_operators) &#123;</span><br><span class="line">            <span class="keyword">if</span> (next_op != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">                in_degree[next_op]++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 找到所有入度为0的节点</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; [op, degree] : in_degree) &#123;</span><br><span class="line">        <span class="keyword">if</span> (degree == <span class="number">0</span>) &#123;</span><br><span class="line">            zero_in_degree_queue.<span class="built_in">push</span>(op);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 处理队列中的节点</span></span><br><span class="line">    <span class="keyword">while</span> (!zero_in_degree_queue.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        <span class="keyword">auto</span> op = zero_in_degree_queue.<span class="built_in">front</span>();</span><br><span class="line">        zero_in_degree_queue.<span class="built_in">pop</span>();</span><br><span class="line">        topo_operators_.<span class="built_in">push_back</span>(op);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; [_, next_op] : op-&gt;output_operators) &#123;</span><br><span class="line">            <span class="keyword">if</span> (next_op != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">                in_degree[next_op]--;</span><br><span class="line">                <span class="keyword">if</span> (in_degree[next_op] == <span class="number">0</span>) &#123;</span><br><span class="line">                    zero_in_degree_queue.<span class="built_in">push</span>(next_op);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 检查是否存在环</span></span><br><span class="line">    <span class="keyword">if</span> (topo_operators_.<span class="built_in">size</span>() != operators_.<span class="built_in">size</span>()) &#123;</span><br><span class="line">        <span class="keyword">throw</span> std::<span class="built_in">runtime_error</span>(<span class="string">&quot;Graph has a cycle&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="course5"><a href="#course5" class="headerlink" title="course5"></a>course5</h3><ol>
<li>Sigmoid Layer</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// sigmoid.hpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> KUIPER_INFER_SOURCE_LAYER_BINOCULAR_SIGMOID_HPP_</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> KUIPER_INFER_SOURCE_LAYER_BINOCULAR_SIGMOID_HPP_</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;layer/abstract/non_param_layer.hpp&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> kuiper_infer &#123;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SigmoidLayer</span> : <span class="keyword">public</span> NonParamLayer &#123;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">SigmoidLayer</span>() : <span class="built_in">NonParamLayer</span>(<span class="string">&quot;Sigmoid&quot;</span>) &#123;&#125;</span><br><span class="line">        <span class="function">InferStatus <span class="title">Forward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">            <span class="type">const</span> std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt;&amp; inputs,</span></span></span><br><span class="line"><span class="params"><span class="function">            std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt;&amp; outputs)</span> <span class="keyword">override</span></span>;</span><br><span class="line">        <span class="function"><span class="type">static</span> ParseParameterAttrStatus <span class="title">GetInstance</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">            <span class="type">const</span> std::shared_ptr&lt;RuntimeOperator&gt;&amp; op,</span></span></span><br><span class="line"><span class="params"><span class="function">            std::shared_ptr&lt;Layer&gt;&amp; sigmoid_layer)</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line">&#125; <span class="comment">// namespace kuiper_infer</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span>  <span class="comment">// KUIPER_INFER_SOURCE_LAYER_BINOCULAR_SIGMOID_HPP_</span></span></span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// sigmoid.cpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;sigmoid.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;layer/abstract/layer_factory.hpp&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> kuiper_infer &#123;</span><br><span class="line"><span class="function">InferStatus <span class="title">SigmoidLayer::Forward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">   <span class="type">const</span> std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt; &amp;inputs,</span></span></span><br><span class="line"><span class="params"><span class="function">   std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt; &amp;outputs)</span> </span>&#123; </span><br><span class="line">  <span class="keyword">if</span> (inputs.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">    <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;The input tensor array in the relu layer is empty&quot;</span>;</span><br><span class="line">    <span class="keyword">return</span> InferStatus::kInferFailedInputEmpty;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (inputs.<span class="built_in">size</span>() != outputs.<span class="built_in">size</span>()) &#123;</span><br><span class="line">    <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;The input and output tensor array size of the relu layer do &quot;</span></span><br><span class="line">                  <span class="string">&quot;not match&quot;</span>;</span><br><span class="line">    <span class="keyword">return</span> InferStatus::kInferFailedInputOutSizeMatchError;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> batch_size = inputs.<span class="built_in">size</span>();</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; batch_size; ++i) &#123;</span><br><span class="line">    <span class="type">const</span> sftensor &amp;input_data = inputs.<span class="built_in">at</span>(i);</span><br><span class="line">    <span class="type">const</span> sftensor &amp;output_data = outputs.<span class="built_in">at</span>(i);</span><br><span class="line">    <span class="keyword">if</span> (input_data == <span class="literal">nullptr</span> || input_data-&gt;<span class="built_in">empty</span>()) &#123;</span><br><span class="line">      <span class="built_in">LOG</span>(ERROR)</span><br><span class="line">          &lt;&lt; <span class="string">&quot;The input tensor array in the relu layer has an empty tensor &quot;</span></span><br><span class="line">          &lt;&lt; i &lt;&lt; <span class="string">&quot; th&quot;</span>;</span><br><span class="line">      <span class="keyword">return</span> InferStatus::kInferFailedInputEmpty;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (output_data != <span class="literal">nullptr</span> &amp;&amp; !output_data-&gt;<span class="built_in">empty</span>()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (input_data-&gt;<span class="built_in">shapes</span>() != output_data-&gt;<span class="built_in">shapes</span>()) &#123;</span><br><span class="line">        <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;The input and output tensor shapes of the relu &quot;</span></span><br><span class="line">                      <span class="string">&quot;layer do not match &quot;</span></span><br><span class="line">                   &lt;&lt; i &lt;&lt; <span class="string">&quot; th&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> InferStatus::kInferFailedInputOutSizeMatchError;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; batch_size; ++i) &#123;</span><br><span class="line">    <span class="type">const</span> std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt; &amp;input = inputs.<span class="built_in">at</span>(i);</span><br><span class="line">    <span class="built_in">CHECK</span>(input == <span class="literal">nullptr</span> || !input-&gt;<span class="built_in">empty</span>())</span><br><span class="line">            &lt;&lt; <span class="string">&quot;The input tensor array in the relu layer has an empty tensor &quot;</span> &lt;&lt; i</span><br><span class="line">            &lt;&lt; <span class="string">&quot; th&quot;</span>;</span><br><span class="line"></span><br><span class="line">    std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt; output = outputs.<span class="built_in">at</span>(i);</span><br><span class="line">    <span class="keyword">if</span> (output == <span class="literal">nullptr</span> || output-&gt;<span class="built_in">empty</span>()) &#123;</span><br><span class="line">      <span class="built_in">DLOG</span>(ERROR)</span><br><span class="line">          &lt;&lt; <span class="string">&quot;The output tensor array in the relu layer has an empty tensor &quot;</span></span><br><span class="line">          &lt;&lt; i &lt;&lt; <span class="string">&quot; th&quot;</span>;</span><br><span class="line">      output = std::make_shared&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;(input-&gt;<span class="built_in">shapes</span>());</span><br><span class="line">      outputs.<span class="built_in">at</span>(i) = output;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">CHECK</span>(output-&gt;<span class="built_in">shapes</span>() == input-&gt;<span class="built_in">shapes</span>())</span><br><span class="line">            &lt;&lt; <span class="string">&quot;The input and output tensor shapes of the relu layer do not match &quot;</span></span><br><span class="line">            &lt;&lt; i &lt;&lt; <span class="string">&quot; th&quot;</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">uint32_t</span> j = <span class="number">0</span>; j &lt; input-&gt;<span class="built_in">size</span>(); ++j) &#123;</span><br><span class="line">      <span class="type">float</span> value = input-&gt;<span class="built_in">index</span>(j);</span><br><span class="line">      output-&gt;<span class="built_in">index</span>(j) = <span class="number">1.f</span> / (<span class="number">1.f</span> + <span class="built_in">expf</span>(-value));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> InferStatus::kInferSuccess;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">ParseParameterAttrStatus <span class="title">SigmoidLayer::GetInstance</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::shared_ptr&lt;RuntimeOperator&gt; &amp;op,</span></span></span><br><span class="line"><span class="params"><span class="function">    std::shared_ptr&lt;Layer&gt; &amp;sigmoid_layer)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">CHECK</span>(op != <span class="literal">nullptr</span>) &lt;&lt; <span class="string">&quot;Sigmod layer op is nullptr&quot;</span>;</span><br><span class="line">  sigmoid_layer = std::<span class="built_in">make_shared</span>&lt;SigmoidLayer&gt;();</span><br><span class="line">  <span class="keyword">return</span> ParseParameterAttrStatus::kParameterAttrParseSuccess;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">LayerRegistererWrapper <span class="title">kSigmoidGetInstance</span><span class="params">(<span class="string">&quot;nn.Sigmoid&quot;</span>, SigmoidLayer::GetInstance)</span></span>;</span><br><span class="line">&#125;  <span class="comment">// namespace kuiper_infer</span></span><br></pre></td></tr></table></figure>

<h3 id="course6"><a href="#course6" class="headerlink" title="course6"></a>course6</h3><ol>
<li>create_layer_group_convforward</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// test_conv.cpp</span></span><br><span class="line"><span class="built_in">TEST</span>(test_registry, create_layer_group_convforward) &#123;</span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> batch_size = <span class="number">1</span>;</span><br><span class="line">  <span class="function">std::vector&lt;sftensor&gt; <span class="title">inputs</span><span class="params">(batch_size)</span></span>;</span><br><span class="line">  <span class="function">std::vector&lt;sftensor&gt; <span class="title">outputs</span><span class="params">(batch_size)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> in_channel = <span class="number">2</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; batch_size; ++i) &#123;</span><br><span class="line">    sftensor input = std::<span class="built_in">make_shared</span>&lt;ftensor&gt;(in_channel, <span class="number">4</span>, <span class="number">4</span>);</span><br><span class="line">    input-&gt;<span class="built_in">data</span>().<span class="built_in">slice</span>(<span class="number">0</span>) = <span class="string">&quot;1,2,3,4;&quot;</span></span><br><span class="line">                             <span class="string">&quot;5,6,7,8;&quot;</span></span><br><span class="line">                             <span class="string">&quot;9,10,11,12;&quot;</span></span><br><span class="line">                             <span class="string">&quot;13,14,15,16;&quot;</span>;</span><br><span class="line"></span><br><span class="line">    input-&gt;<span class="built_in">data</span>().<span class="built_in">slice</span>(<span class="number">1</span>) = <span class="string">&quot;1,2,3,4;&quot;</span></span><br><span class="line">                             <span class="string">&quot;5,6,7,8;&quot;</span></span><br><span class="line">                             <span class="string">&quot;9,10,11,12;&quot;</span></span><br><span class="line">                             <span class="string">&quot;13,14,15,16;&quot;</span>;</span><br><span class="line">    inputs.<span class="built_in">at</span>(i) = input;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> kernel_h = <span class="number">3</span>;</span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> kernel_w = <span class="number">3</span>;</span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> stride_h = <span class="number">1</span>;</span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> stride_w = <span class="number">1</span>;</span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> kernel_count = <span class="number">2</span>;</span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> group = <span class="number">2</span>;</span><br><span class="line">  std::vector&lt;sftensor&gt; weights;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; kernel_count; ++i) &#123;</span><br><span class="line">    sftensor kernel = std::<span class="built_in">make_shared</span>&lt;ftensor&gt;(in_channel / group, kernel_h, kernel_w);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">uint32_t</span> j = <span class="number">0</span>; j &lt; (in_channel / group); ++j) &#123;</span><br><span class="line">      kernel-&gt;<span class="built_in">data</span>().<span class="built_in">slice</span>(j) = arma::<span class="built_in">fmat</span>(<span class="string">&quot;1,2,3;&quot;</span></span><br><span class="line">                                           <span class="string">&quot;3,2,1;&quot;</span></span><br><span class="line">                                           <span class="string">&quot;1,2,3;&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    weights.<span class="built_in">push_back</span>(kernel);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function">ConvolutionLayer <span class="title">conv_layer</span><span class="params">(kernel_count, in_channel, kernel_h, kernel_w, <span class="number">0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                              <span class="number">0</span>, stride_h, stride_w, group, <span class="literal">false</span>)</span></span>;</span><br><span class="line">  conv_layer.<span class="built_in">set_weights</span>(weights);</span><br><span class="line">  conv_layer.<span class="built_in">Forward</span>(inputs, outputs);</span><br><span class="line">  outputs.<span class="built_in">at</span>(<span class="number">0</span>)-&gt;<span class="built_in">Show</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="course7"><a href="#course7" class="headerlink" title="course7"></a>course7</h3><ol>
<li>词法和语法解析中支持sin(三角函数)操作</li>
<li>如果操作符是单输入数，例如问题1中的sin函数，的<code>Forward</code>函数应该做出什么改动能获得正确的计算结果。</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// tensor_utils.hpp</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * sin(@num)</span></span><br><span class="line"><span class="comment"> * @param tensor 输入张量</span></span><br><span class="line"><span class="comment"> * @return 张量 sin 的结果</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt; <span class="built_in">TensorElementSin</span>(</span><br><span class="line">    <span class="type">const</span> std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&amp; tensor);</span><br><span class="line"></span><br><span class="line"><span class="comment">// tensor_utils.cpp</span></span><br><span class="line">std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt; <span class="built_in">TensorElementSin</span>(</span><br><span class="line">            <span class="type">const</span> std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&amp; tensor) &#123;</span><br><span class="line">    <span class="built_in">CHECK</span>(tensor != <span class="literal">nullptr</span>);</span><br><span class="line"></span><br><span class="line">    sftensor output_tensor = <span class="built_in">TensorCreate</span>(tensor-&gt;<span class="built_in">shapes</span>());</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span>&amp; input_data = tensor-&gt;<span class="built_in">data</span>();</span><br><span class="line">    <span class="keyword">auto</span>&amp; output_data = output_tensor-&gt;<span class="built_in">data</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; input_data.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">        output_data[i] = std::<span class="built_in">sin</span>(input_data[i]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output_tensor;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// parse_expression.cpp</span></span><br><span class="line"><span class="function">std::shared_ptr&lt;TokenNode&gt; <span class="title">ExpressionParser::Generate_</span><span class="params">(<span class="type">int32_t</span> &amp;index)</span> </span>&#123; <span class="comment">// recursive generate</span></span><br><span class="line">  <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>());</span><br><span class="line">  <span class="type">const</span> <span class="keyword">auto</span> current_token = <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index);</span><br><span class="line">  <span class="built_in">CHECK</span>(current_token.token_type == TokenType::TokenInputNumber ||</span><br><span class="line">      current_token.token_type == TokenType::TokenAdd ||</span><br><span class="line">      current_token.token_type == TokenType::TokenMul ||</span><br><span class="line">      current_token.token_type == TokenType::TokenSin);</span><br><span class="line">  <span class="keyword">if</span> (current_token.token_type == TokenType::TokenInputNumber) &#123;</span><br><span class="line">    <span class="type">uint32_t</span> start_pos = current_token.start_pos + <span class="number">1</span>;</span><br><span class="line">    <span class="type">uint32_t</span> end_pos = current_token.end_pos;</span><br><span class="line">    <span class="built_in">CHECK</span>(end_pos &gt; start_pos || end_pos &lt;= <span class="keyword">this</span>-&gt;statement_.<span class="built_in">length</span>())</span><br><span class="line">            &lt;&lt; <span class="string">&quot;Current token has a wrong length&quot;</span>;</span><br><span class="line">    <span class="type">const</span> std::string &amp;str_number =</span><br><span class="line">        std::<span class="built_in">string</span>(<span class="keyword">this</span>-&gt;statement_.<span class="built_in">begin</span>() + start_pos,</span><br><span class="line">                    <span class="keyword">this</span>-&gt;statement_.<span class="built_in">begin</span>() + end_pos);</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">make_shared</span>&lt;TokenNode&gt;(std::<span class="built_in">stoi</span>(str_number), <span class="literal">nullptr</span>, <span class="literal">nullptr</span>);</span><br><span class="line"></span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (current_token.token_type == TokenType::TokenMul ||</span><br><span class="line">      current_token.token_type == TokenType::TokenAdd) &#123;</span><br><span class="line">    std::shared_ptr&lt;TokenNode&gt; current_node = std::<span class="built_in">make_shared</span>&lt;TokenNode&gt;();</span><br><span class="line">    current_node-&gt;num_index = <span class="built_in">int</span>(current_token.token_type);</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>()) &lt;&lt; <span class="string">&quot;Missing left bracket!&quot;</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index).token_type == TokenType::TokenLeftBracket);</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>()) &lt;&lt; <span class="string">&quot;Missing correspond left token!&quot;</span>;</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> left_token = <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (left_token.token_type == TokenType::TokenInputNumber ||</span><br><span class="line">        left_token.token_type == TokenType::TokenAdd ||</span><br><span class="line">        left_token.token_type == TokenType::TokenMul ||</span><br><span class="line">        left_token.token_type == TokenType::TokenSin) &#123;</span><br><span class="line">      current_node-&gt;left = <span class="built_in">Generate_</span>(index);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown token type: &quot;</span> &lt;&lt; <span class="built_in">int</span>(left_token.token_type);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>()) &lt;&lt; <span class="string">&quot;Missing comma!&quot;</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index).token_type == TokenType::TokenComma);</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>()) &lt;&lt; <span class="string">&quot;Missing correspond right token!&quot;</span>;</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> right_token = <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index);</span><br><span class="line">    <span class="keyword">if</span> (right_token.token_type == TokenType::TokenInputNumber ||</span><br><span class="line">        right_token.token_type == TokenType::TokenAdd ||</span><br><span class="line">        right_token.token_type == TokenType::TokenMul ||</span><br><span class="line">        right_token.token_type == TokenType::TokenSin) &#123;</span><br><span class="line">      current_node-&gt;right = <span class="built_in">Generate_</span>(index);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown token type: &quot;</span> &lt;&lt; <span class="built_in">int</span>(right_token.token_type);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>()) &lt;&lt; <span class="string">&quot;Missing right bracket!&quot;</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index).token_type == TokenType::TokenRightBracket);</span><br><span class="line">    <span class="keyword">return</span> current_node;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (current_token.token_type == TokenType::TokenSin)&#123;</span><br><span class="line">    std::shared_ptr&lt;TokenNode&gt; current_node = std::<span class="built_in">make_shared</span>&lt;TokenNode&gt;();</span><br><span class="line">    current_node-&gt;num_index = <span class="built_in">int</span>(current_token.token_type);</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>()) &lt;&lt; <span class="string">&quot;Missing left bracket!&quot;</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index).token_type == TokenType::TokenLeftBracket);</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> cur_token = <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index);</span><br><span class="line">    <span class="keyword">if</span> (cur_token.token_type == TokenType::TokenInputNumber ||</span><br><span class="line">        cur_token.token_type == TokenType::TokenAdd ||</span><br><span class="line">        cur_token.token_type == TokenType::TokenMul ||</span><br><span class="line">        cur_token.token_type == TokenType::TokenSin) &#123;</span><br><span class="line">      current_node-&gt;left = <span class="built_in">Generate_</span>(index);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown token type: &quot;</span> &lt;&lt; <span class="built_in">int</span>(cur_token.token_type);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>()) &lt;&lt; <span class="string">&quot;Missing right bracket!&quot;</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index).token_type == TokenType::TokenRightBracket);</span><br><span class="line">    <span class="keyword">return</span> current_node;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown token type: &quot;</span> &lt;&lt; <span class="built_in">int</span>(current_token.token_type);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// expression.cpp</span></span><br><span class="line"><span class="function">InferStatus <span class="title">ExpressionLayer::Forward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt;&amp; inputs,</span></span></span><br><span class="line"><span class="params"><span class="function">    std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt;&amp; outputs)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (inputs.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">    <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;The input tensor array in the expression layer is empty&quot;</span>;</span><br><span class="line">    <span class="keyword">return</span> InferStatus::kInferFailedInputEmpty;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (outputs.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">    <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;The output tensor array in the expression layer is empty&quot;</span>;</span><br><span class="line">    <span class="keyword">return</span> InferStatus::kInferFailedOutputEmpty;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="keyword">this</span>-&gt;parser_ != <span class="literal">nullptr</span>)</span><br><span class="line">      &lt;&lt; <span class="string">&quot;The parser in the expression layer is null!&quot;</span>;</span><br><span class="line">  <span class="keyword">this</span>-&gt;parser_-&gt;<span class="built_in">Tokenizer</span>(<span class="literal">false</span>);</span><br><span class="line">  <span class="type">const</span> <span class="keyword">auto</span>&amp; expressions = <span class="keyword">this</span>-&gt;parser_-&gt;<span class="built_in">tokens</span>();</span><br><span class="line">  <span class="built_in">CHECK</span>(!expressions.<span class="built_in">empty</span>())</span><br><span class="line">      &lt;&lt; <span class="string">&quot;The expression parser failed to parse &quot;</span> &lt;&lt; statement_;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; inputs.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">    <span class="type">const</span> sftensor&amp; input_data = inputs.<span class="built_in">at</span>(i);</span><br><span class="line">    <span class="keyword">if</span> (input_data == <span class="literal">nullptr</span> || input_data-&gt;<span class="built_in">empty</span>()) &#123;</span><br><span class="line">      <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;The input tensor array in the expression layer has an &quot;</span></span><br><span class="line">                    <span class="string">&quot;empty tensor &quot;</span></span><br><span class="line">                 &lt;&lt; i &lt;&lt; <span class="string">&quot;th&quot;</span>;</span><br><span class="line">      <span class="keyword">return</span> InferStatus::kInferFailedInputEmpty;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> batch_size = outputs.<span class="built_in">size</span>();</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; batch_size; ++i) &#123;</span><br><span class="line">    <span class="keyword">if</span> (outputs.<span class="built_in">at</span>(i) == <span class="literal">nullptr</span> || outputs.<span class="built_in">at</span>(i)-&gt;<span class="built_in">empty</span>()) &#123;</span><br><span class="line">      <span class="built_in">DLOG</span>(ERROR) &lt;&lt; <span class="string">&quot;The output tensor array in the expression layer has an &quot;</span></span><br><span class="line">                     <span class="string">&quot;empty tensor &quot;</span></span><br><span class="line">                  &lt;&lt; i &lt;&lt; <span class="string">&quot;th&quot;</span>;</span><br><span class="line">      <span class="keyword">return</span> InferStatus::kInferFailedOutputEmpty;</span><br><span class="line">    &#125;</span><br><span class="line">    outputs.<span class="built_in">at</span>(i)-&gt;<span class="built_in">Fill</span>(<span class="number">0.f</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  std::stack&lt;std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt;&gt; op_stack;</span><br><span class="line">  <span class="type">const</span> std::vector&lt;std::shared_ptr&lt;TokenNode&gt;&gt;&amp; token_nodes =</span><br><span class="line">      <span class="keyword">this</span>-&gt;parser_-&gt;<span class="built_in">Generate</span>();</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; token_node : token_nodes) &#123;</span><br><span class="line">    <span class="keyword">if</span> (token_node-&gt;num_index &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// process operator</span></span><br><span class="line">      <span class="type">uint32_t</span> start_pos = token_node-&gt;num_index * batch_size;</span><br><span class="line">      std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt; input_token_nodes;</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; batch_size; ++i) &#123;</span><br><span class="line">        <span class="built_in">CHECK</span>(i + start_pos &lt; inputs.<span class="built_in">size</span>())</span><br><span class="line">            &lt;&lt; <span class="string">&quot;The &quot;</span> &lt;&lt; i</span><br><span class="line">            &lt;&lt; <span class="string">&quot;th operand doesn&#x27;t have appropriate number of tensors&quot;</span>;</span><br><span class="line">        <span class="comment">// fixme 这里的张量拷贝是否有必要</span></span><br><span class="line">        input_token_nodes.<span class="built_in">push_back</span>(inputs.<span class="built_in">at</span>(i + start_pos));</span><br><span class="line">      &#125;</span><br><span class="line">      op_stack.<span class="built_in">push</span>(input_token_nodes);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// process operation</span></span><br><span class="line">      <span class="type">const</span> <span class="type">int32_t</span> op = token_node-&gt;num_index;</span><br><span class="line">      <span class="keyword">if</span> (op != <span class="built_in">int</span>(TokenType::TokenAdd) &amp;&amp; op != <span class="built_in">int</span>(TokenType::TokenMul) &amp;&amp; op != <span class="built_in">int</span>(TokenType::TokenSin)) &#123;</span><br><span class="line">        <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown operator type: &quot;</span> &lt;&lt; op;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (op == <span class="built_in">int</span>(TokenType::TokenSin)) &#123;</span><br><span class="line">          <span class="built_in">CHECK</span>(op_stack.<span class="built_in">size</span>() &gt;= <span class="number">1</span>) &lt;&lt; <span class="string">&quot;The number of operand is less than one for sin operation&quot;</span>;</span><br><span class="line">          std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt; input_node = op_stack.<span class="built_in">top</span>();</span><br><span class="line">          <span class="built_in">CHECK</span>(input_node.<span class="built_in">size</span>() == batch_size)</span><br><span class="line">                          &lt;&lt; <span class="string">&quot;The operand doesn&#x27;t have appropriate number of tensors, &quot;</span></span><br><span class="line">                             <span class="string">&quot;which need &quot;</span></span><br><span class="line">                          &lt;&lt; batch_size;</span><br><span class="line">          op_stack.<span class="built_in">pop</span>();</span><br><span class="line">          std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt; <span class="built_in">output_token_nodes</span>(batch_size);</span><br><span class="line">          <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; batch_size; ++i) &#123;</span><br><span class="line">              <span class="comment">// do execution</span></span><br><span class="line">              output_token_nodes.<span class="built_in">at</span>(i) = <span class="built_in">TensorElementSin</span>(input_node.<span class="built_in">at</span>(i)); <span class="comment">// Modified</span></span><br><span class="line">          &#125;</span><br><span class="line">          op_stack.<span class="built_in">push</span>(output_token_nodes);</span><br><span class="line">          <span class="keyword">continue</span>; <span class="comment">/// 跳过循环的其余部分进行sin操作</span></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">CHECK</span>(op_stack.<span class="built_in">size</span>() &gt;= <span class="number">2</span>) &lt;&lt; <span class="string">&quot;The number of operand is less than two&quot;</span>;</span><br><span class="line">        std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt; input_node1 = op_stack.<span class="built_in">top</span>();</span><br><span class="line"></span><br><span class="line">        <span class="built_in">CHECK</span>(input_node1.<span class="built_in">size</span>() == batch_size)</span><br><span class="line">            &lt;&lt; <span class="string">&quot;The first operand doesn&#x27;t have appropriate number of tensors, &quot;</span></span><br><span class="line">              <span class="string">&quot;which need &quot;</span></span><br><span class="line">            &lt;&lt; batch_size;</span><br><span class="line">        op_stack.<span class="built_in">pop</span>();</span><br><span class="line"></span><br><span class="line">        std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt; input_node2 = op_stack.<span class="built_in">top</span>();</span><br><span class="line">        <span class="built_in">CHECK</span>(input_node2.<span class="built_in">size</span>() == batch_size)</span><br><span class="line">            &lt;&lt; <span class="string">&quot;The second operand doesn&#x27;t have appropriate number of tensors, &quot;</span></span><br><span class="line">              <span class="string">&quot;which need &quot;</span></span><br><span class="line">            &lt;&lt; batch_size;</span><br><span class="line">        op_stack.<span class="built_in">pop</span>();</span><br><span class="line"></span><br><span class="line">        std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt; <span class="built_in">output_token_nodes</span>(</span><br><span class="line">            batch_size);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; batch_size; ++i) &#123;</span><br><span class="line">          <span class="comment">// do execution</span></span><br><span class="line">          <span class="keyword">if</span> (op == <span class="built_in">int</span>(TokenType::TokenAdd)) &#123;</span><br><span class="line">            output_token_nodes.<span class="built_in">at</span>(i) =</span><br><span class="line">                <span class="built_in">TensorElementAdd</span>(input_node1.<span class="built_in">at</span>(i), input_node2.<span class="built_in">at</span>(i));</span><br><span class="line">          &#125; <span class="keyword">else</span> <span class="keyword">if</span> (op == <span class="built_in">int</span>(TokenType::TokenMul)) &#123;</span><br><span class="line">            output_token_nodes.<span class="built_in">at</span>(i) =</span><br><span class="line">                <span class="built_in">TensorElementMultiply</span>(input_node1.<span class="built_in">at</span>(i), input_node2.<span class="built_in">at</span>(i));</span><br><span class="line">          &#125; <span class="keyword">else</span> <span class="keyword">if</span> (op == <span class="built_in">int</span>(TokenType::TokenSin)) &#123;</span><br><span class="line">            output_token_nodes.<span class="built_in">at</span>(i) =</span><br><span class="line">                <span class="built_in">TensorElementSin</span>(input_node1.<span class="built_in">at</span>(i));</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown operator type: &quot;</span> &lt;&lt; op;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        op_stack.<span class="built_in">push</span>(output_token_nodes);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">CHECK</span>(op_stack.<span class="built_in">size</span>() == <span class="number">1</span>)</span><br><span class="line">      &lt;&lt; <span class="string">&quot;The expression has more than one output operand!&quot;</span>;</span><br><span class="line">  std::vector&lt;sftensor&gt; output_node = op_stack.<span class="built_in">top</span>();</span><br><span class="line">  op_stack.<span class="built_in">pop</span>();</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; batch_size; ++i) &#123;</span><br><span class="line">    <span class="built_in">CHECK</span>(outputs.<span class="built_in">at</span>(i) != <span class="literal">nullptr</span> &amp;&amp; !outputs.<span class="built_in">at</span>(i)-&gt;<span class="built_in">empty</span>());</span><br><span class="line">    <span class="built_in">CHECK</span>(outputs.<span class="built_in">at</span>(i)-&gt;<span class="built_in">shapes</span>() == output_node.<span class="built_in">at</span>(i)-&gt;<span class="built_in">shapes</span>());</span><br><span class="line">    outputs.<span class="built_in">at</span>(i) = output_node.<span class="built_in">at</span>(i);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> InferStatus::kInferSuccess;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/12/16/Nano-Web-Server/" rel="prev" title="Nano Web Server">
                  <i class="fa fa-chevron-left"></i> Nano Web Server
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">jarvis</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  





  





</body>
</html>
