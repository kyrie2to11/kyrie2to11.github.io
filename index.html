<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.2/css/all.min.css" integrity="sha256-xejo6yLi6vGtAjcMIsY8BHdKsLg7QynVlFMzdQgUuy8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"kyrie2to11.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.12.3","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="记录学习和生活，留下时光的痕迹">
<meta property="og:type" content="website">
<meta property="og:title" content="Jarvis&#39;s Blog">
<meta property="og:url" content="https://kyrie2to11.github.io/index.html">
<meta property="og:site_name" content="Jarvis&#39;s Blog">
<meta property="og:description" content="记录学习和生活，留下时光的痕迹">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="jarvis">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://kyrie2to11.github.io/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Jarvis's Blog</title>
  






  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Jarvis's Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">记录生活，沉淀自己</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>







</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">jarvis</p>
  <div class="site-description" itemprop="description">记录学习和生活，留下时光的痕迹</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">27</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://kyrie2to11.github.io/2024/12/24/Kuiper-Infer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="jarvis">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jarvis's Blog">
      <meta itemprop="description" content="记录学习和生活，留下时光的痕迹">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Jarvis's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/12/24/Kuiper-Infer/" class="post-title-link" itemprop="url">Kuiper Infer</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-12-24 21:06:56" itemprop="dateCreated datePublished" datetime="2024-12-24T21:06:56+08:00">2024-12-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-01-03 17:41:34" itemprop="dateModified" datetime="2025-01-03T17:41:34+08:00">2025-01-03</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <blockquote>
<p>github repo: <a target="_blank" rel="noopener" href="https://github.com/zjhellofss/kuiperdatawhale.git">https://github.com/zjhellofss/kuiperdatawhale.git</a></p>
</blockquote>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul>
<li><a href="#%E7%9B%AE%E5%BD%95">目录</a></li>
<li><a href="#tensor">Tensor</a></li>
<li><a href="#compute-graph">Compute Graph</a></li>
<li><a href="#kuiperinfer%E5%AF%B9%E8%AE%A1%E7%AE%97%E5%9B%BE%E7%9A%84%E5%B0%81%E8%A3%85">KuiperInfer对计算图的封装</a></li>
<li><a href="#%E6%9E%84%E5%BB%BA%E8%AE%A1%E7%AE%97%E5%9B%BE%E5%85%B3%E7%B3%BB%E5%92%8C%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F">构建计算图关系和执行顺序</a><ul>
<li><a href="#%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F">拓扑排序</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E7%9A%84%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%E8%AE%A1%E7%AE%97%E6%AD%A5%E9%AA%A4">基于深度优先的拓扑排序计算步骤</a></li>
</ul>
</li>
<li><a href="#operator--register-factory">Operator &amp; Register Factory</a><ul>
<li><a href="#layer-%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%AE%9A%E4%B9%89">Layer 类型的定义</a></li>
</ul>
</li>
<li><a href="#convolution--pooling-operator">Convolution &amp; Pooling Operator</a><ul>
<li><a href="#%E6%B1%A0%E5%8C%96%E7%AE%97%E5%AD%90%E7%9A%84%E5%AE%9A%E4%B9%89">池化算子的定义</a></li>
<li><a href="#%E5%8D%B7%E7%A7%AF%E7%AE%97%E5%AD%90%E7%9A%84%E5%AE%9A%E4%B9%89">卷积算子的定义</a></li>
</ul>
</li>
<li><a href="#expression-layer">Expression Layer</a><ul>
<li><a href="#%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84%E5%AE%9A%E4%B9%89">表达式的定义</a></li>
<li><a href="#%E8%AF%8D%E6%B3%95%E8%A7%A3%E6%9E%90">词法解析</a><ul>
<li><a href="#%E8%AF%8D%E6%B3%95%E7%9A%84%E5%AE%9A%E4%B9%89">词法的定义</a></li>
<li><a href="#%E8%AF%8D%E6%B3%95%E7%9A%84%E8%A7%A3%E6%9E%90">词法的解析</a><ul>
<li><a href="#%E5%88%A4%E6%96%AD%E5%8F%A5%E5%AD%90%E6%98%AF%E5%90%A6%E4%B8%BA%E7%A9%BA">判断句子是否为空</a></li>
<li><a href="#%E7%A7%BB%E9%99%A4%E5%8F%A5%E5%AD%90%E4%B8%AD%E7%9A%84%E7%A9%BA%E6%A0%BC">移除句子中的空格</a></li>
<li><a href="#%E9%80%90%E4%B8%AA%E8%A7%A3%E6%9E%90%E5%8F%A5%E5%AD%90%E7%9A%84%E5%AD%97%E7%AC%A6">逐个解析句子的字符</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E8%AF%AD%E6%B3%95%E8%A7%A3%E6%9E%90">语法解析</a><ul>
<li><a href="#%E8%AF%AD%E6%B3%95%E6%A0%91%E7%9A%84%E5%AE%9A%E4%B9%89">语法树的定义</a></li>
<li><a href="#%E9%80%92%E5%BD%92%E5%90%91%E4%B8%8B%E7%9A%84%E8%A7%A3%E6%9E%90">递归向下的解析</a></li>
</ul>
</li>
<li><a href="#%E5%AF%B9%E8%AF%AD%E6%B3%95%E6%A0%91%E7%9A%84%E8%BD%AC%E6%8D%A2">对语法树的转换</a><ul>
<li><a href="#%E9%80%86%E6%B3%A2%E5%85%B0%E5%BC%8F">逆波兰式</a></li>
</ul>
</li>
<li><a href="#%E8%BF%87%E7%A8%8B%E6%80%BB%E8%BF%B0">过程总述</a></li>
</ul>
</li>
<li><a href="#resnet--yolov5-infer">ResNet &amp; YOLOv5 Infer</a></li>
<li><a href="#homework">homework</a><ul>
<li><a href="#course1">course1</a></li>
<li><a href="#course2">course2</a></li>
<li><a href="#course3">course3</a></li>
<li><a href="#course4">course4</a></li>
<li><a href="#course5">course5</a></li>
<li><a href="#course6">course6</a></li>
<li><a href="#course7">course7</a></li>
</ul>
</li>
</ul>
<h2 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h2><ol>
<li><p>类设计</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Tensor</span>&lt;<span class="type">float</span>&gt;&#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">     <span class="built_in">Tensor</span>(<span class="type">const</span> std::vector&lt;<span class="type">uint32_t</span>&gt;&amp; shapes); <span class="comment">// 三维张量构造函数</span></span><br><span class="line">     <span class="function"><span class="type">uint32_t</span> <span class="title">rows</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">     <span class="function"><span class="type">uint32_t</span> <span class="title">cols</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">     <span class="function"><span class="type">uint32_t</span> <span class="title">channels</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">     <span class="function"><span class="type">uint32_t</span> <span class="title">size</span><span class="params">()</span> <span class="type">const</span></span>; <span class="comment">// 返回元素个数</span></span><br><span class="line">     <span class="function"><span class="type">const</span> std::vector&lt;<span class="type">uint32_t</span>&gt;&amp; <span class="title">raw_shapes</span><span class="params">()</span> <span class="type">const</span></span>; <span class="comment">// 张量实际大小</span></span><br><span class="line">     <span class="function"><span class="type">void</span> <span class="title">Fill</span><span class="params">(<span class="type">const</span> std::vector&lt;<span class="type">float</span>&gt;&amp; values, <span class="type">bool</span> row_major)</span></span>; <span class="comment">// 填充指定值</span></span><br><span class="line">     ···</span><br><span class="line">     ···</span><br><span class="line">     ···</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">     std::vector&lt;<span class="type">uint32_t</span>&gt; raw_shapes_;  <span class="comment">// 张量数据的实际尺寸大小</span></span><br><span class="line">     arma::fcube data_;                  <span class="comment">// 张量数据</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="Compute-Graph"><a href="#Compute-Graph" class="headerlink" title="Compute Graph"></a>Compute Graph</h2><ol>
<li><p>计算图相关概念</p>
<ul>
<li><code>Operator</code>: 深度学习计算图中的计算节点。</li>
<li><code>Layer</code>: <strong>计算节点中</strong>运算的具体执行者，<code>Layer</code>类先读取输入张量中的数据，然后对输入张量进行计算，得到的结果存放到计算节点的输出张量中，<strong>当然，不同的算子中<code>Layer</code>的计算过程会不一致</strong>。</li>
<li><code>Tensor</code>: 用于存放<strong>多维数据</strong>的数据结构，方便数据在计算节点之间传递，同时该结构也封装矩阵乘、点积等与矩阵相关的基本操作。</li>
<li><code>Graph</code>: 有多个<code>Operator</code>串联得到的有向无环图，规定了各个计算节点（<code>Operator</code>）执行的流程和顺序。</li>
</ul>
</li>
<li><p>PNNX 计算图优势</p>
<ul>
<li>使用模板匹配（<code>pattern matching</code>）的方法将匹配到的子图用对应等价的大算子替换掉，不会像模型导出 ONNX 算子一样细碎。</li>
<li>在<code>PyTorch</code>中编写的简单算术表达式在转换为<code>PNNX</code>后，会保留表达式的整体结构，而不会被拆分成许多小的加减乘除算子。</li>
<li><code>PNNX</code>项目中有大量图优化的技术，包括了算子融合，常量折叠和消除，公共表达式消除等技术。</li>
</ul>
</li>
<li><p>PNNX 计算图格式</p>
<ul>
<li><code>PNNX</code>由图结构(<code>Graph</code>), 运算符(<code>Operator</code>)和操作数(<code>Operand</code>)这三种结构组成的，设计非常简洁。</li>
<li><code>Graph</code>的核心作用是<strong>管理计算图中的运算符和操作数</strong>。下面将对这两个概念进行说明：<ol>
<li><code>Operator</code>类用来<strong>表示计算图中的运算符（算子）</strong>，比如一个模型中的<code>Convolution</code>, <code>Pooling</code>等算子；</li>
<li><code>Operand</code>类用来<strong>表示计算图中的操作数</strong>，即<strong>与一个运算符有关的输入和输出张量</strong>；</li>
<li><code>Graph</code>类的成员函数提供了方便的接口用来<strong>创建和访问操作符和操作数</strong>，以构建和遍历计算图。同时，它也是模型中<strong>运算符（算子）和操作数的集合</strong>。</li>
</ol>
</li>
</ul>
</li>
<li><p>PNNX 运算符结构</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Operator</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">   std::vector&lt;Operand*&gt; inputs; <span class="comment">// 输入</span></span><br><span class="line">   std::vector&lt;Operand*&gt; outputs; <span class="comment">// 输出</span></span><br><span class="line"></span><br><span class="line">   std::string type; <span class="comment">// 类型：conv/linear/pooling</span></span><br><span class="line">   std::string name; <span class="comment">// 名称</span></span><br><span class="line"></span><br><span class="line">   std::vector&lt;std::string&gt; inputnames; </span><br><span class="line">   std::map&lt;std::string, Parameter&gt; params; <span class="comment">// 参数：如 `stride`, `padding`, `kernel size` 等</span></span><br><span class="line">   std::map&lt;std::string, Attribute&gt; attrs; <span class="comment">// 权重属性</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>PNNX 操作数结构</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Operand</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">   <span class="function"><span class="type">void</span> <span class="title">remove_consumer</span><span class="params">(<span class="type">const</span> Operator* c)</span></span>;</span><br><span class="line">   Operator* producer;</span><br><span class="line">   std::vector&lt;Operator*&gt; consumers;</span><br><span class="line">   </span><br><span class="line">   <span class="type">int</span> type;</span><br><span class="line">   std::vector&lt;<span class="type">int</span>&gt; shape;</span><br><span class="line"></span><br><span class="line">   std::string name;</span><br><span class="line">   std::map&lt;std::string, Parameter&gt; params;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>操作数结构中的<code>producer</code>和<code>customers</code>, 分别表示<strong>产生这个操作数的算子</strong>和<strong>使用这个操作数的算子</strong>。<br>值得注意的是产生这个操作数的算子只能有一个，而使用这个操作数的算子可以有很多个。</p>
</li>
</ol>
<h2 id="KuiperInfer对计算图的封装"><a href="#KuiperInfer对计算图的封装" class="headerlink" title="KuiperInfer对计算图的封装"></a>KuiperInfer对计算图的封装</h2><ol>
<li>PNNX Operator -&gt; RuntimeOperator<img src="/2024/12/24/Kuiper-Infer/runtime_ir.png" class="" title="runtime_ir"></li>
</ol>
<h2 id="构建计算图关系和执行顺序"><a href="#构建计算图关系和执行顺序" class="headerlink" title="构建计算图关系和执行顺序"></a>构建计算图关系和执行顺序</h2><h3 id="拓扑排序"><a href="#拓扑排序" class="headerlink" title="拓扑排序"></a>拓扑排序</h3><p>对于一个有向无环图，拓扑排序总能够找到一个<strong>节点序列</strong>，在这个序列中，<strong>每个节点的前驱节点都能排在这个节点的前面</strong>。什么是前驱节点呢，也就是对于<strong>有向图中任意一条边的起点，可以认为它是终点节点的前驱节点。</strong></p>
<h3 id="基于深度优先的拓扑排序计算步骤"><a href="#基于深度优先的拓扑排序计算步骤" class="headerlink" title="基于深度优先的拓扑排序计算步骤"></a>基于深度优先的拓扑排序计算步骤</h3><p>有计算排序的函数为<code>ReverseTopo</code>. <code>ReverseTopo</code>有参数<code>current_op</code>.</p>
<ol>
<li>选定一个入度为零的节点(<code>current_op</code>)，入度为零指的是<strong>该节点没有前驱节点或所有前驱节点已经都被执行过</strong>，在选定的同时将该节点的已执行标记置为<code>True</code>，并将该节点传入到<code>ReverseTopo</code>函数中；</li>
<li>遍历1步骤中节点的后继节点(<code>current_op-&gt;output_operators</code>)；</li>
<li>如果1的某个后继节点没有被执行过(已执行标记为<code>False</code>)，则递归将<strong>该后继节点</strong>传入到<code>ReverseTopo</code>函数中；</li>
<li>第2步中的遍历结束后，将当前节点放入到执行队列(<code>topo_operators_</code>)中。</li>
</ol>
<p>当该函数结束后，对<strong>执行队列中的排序结果做逆序就得到了最终拓扑排序的结果</strong>，来看看具体的代码：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">RuntimeGraph::ReverseTopo</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::shared_ptr&lt;RuntimeOperator&gt;&amp; current_op)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">CHECK</span>(current_op != <span class="literal">nullptr</span>) &lt;&lt; <span class="string">&quot;current operator is nullptr&quot;</span>;</span><br><span class="line">  current_op-&gt;has_forward = <span class="literal">true</span>;</span><br><span class="line">  <span class="type">const</span> <span class="keyword">auto</span>&amp; next_ops = current_op-&gt;output_operators;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; [_, op] : next_ops) &#123;</span><br><span class="line">    <span class="keyword">if</span> (op != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!op-&gt;has_forward) &#123;</span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">ReverseTopo</span>(op);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; [_, op] : next_ops) &#123;</span><br><span class="line">    <span class="built_in">CHECK_EQ</span>(op-&gt;has_forward, <span class="literal">true</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">this</span>-&gt;topo_operators_.<span class="built_in">push_back</span>(current_op);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Operator-amp-Register-Factory"><a href="#Operator-amp-Register-Factory" class="headerlink" title="Operator &amp; Register Factory"></a>Operator &amp; Register Factory</h2><h3 id="Layer-类型的定义"><a href="#Layer-类型的定义" class="headerlink" title="Layer 类型的定义"></a>Layer 类型的定义</h3><ol>
<li><p>计算节点被称之为<code>RuntimeOperator</code>, 具体的结构定义如下的代码所示：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">RuntimeOperator</span> &#123;</span><br><span class="line"><span class="keyword">virtual</span> ~<span class="built_in">RuntimeOperator</span>();</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> has_forward = <span class="literal">false</span>;</span><br><span class="line">std::string name;      <span class="comment">/// 计算节点的名称</span></span><br><span class="line">std::string type;      <span class="comment">/// 计算节点的类型</span></span><br><span class="line">std::shared_ptr&lt;Layer&gt; layer;  <span class="comment">/// 节点对应的计算Layer</span></span><br><span class="line">   </span><br><span class="line">std::map&lt;std::string, std::shared_ptr&lt;RuntimeOperand&gt;&gt;</span><br><span class="line">      input_operands;  <span class="comment">/// 节点的输入操作数</span></span><br><span class="line">std::shared_ptr&lt;RuntimeOperand&gt; output_operands;  <span class="comment">/// 节点的输出操作数</span></span><br><span class="line">std::vector&lt;std::shared_ptr&lt;RuntimeOperand&gt;&gt;</span><br><span class="line">      input_operands_seq;  <span class="comment">/// 节点的输入操作数，顺序排列</span></span><br><span class="line">std::map&lt;std::string, std::shared_ptr&lt;RuntimeOperator&gt;&gt;</span><br><span class="line">      output_operators;  <span class="comment">/// 输出节点的名字和节点对应</span></span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在一个计算节点(<code>RuntimeOperator</code>)中，记录了与该节点相关的类型、名称，以及输入输出数等信息。其中最重要的是<code>layer</code>变量，它是具体计算的实施者。</p>
<p>通过访问<code>RuntimeOperator</code>的输入数(<code>input_operand</code>)，<code>layer</code>可以获取计算所需的输入张量数据，<strong>并根据<code>layer</code>各派生类别中定义的计算函数(<code>forward</code>)对输入张量数据进行计算</strong>。计算完成后，计算结果将存储在该节点的输出数(<code>output_operand</code>)中。</p>
</li>
<li><p>以下的代码位于<code>include/abstract/layer.hpp</code>中，<strong>它是所有算子的父类</strong>，如果要实现项目中其他的算子，都需要继承于该类作为派生类并重写其中的计算函数(<code>forward</code>)。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Layer</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="function"><span class="keyword">explicit</span> <span class="title">Layer</span><span class="params">(std::string layer_name)</span> : layer_name_(std::move(layer_name)) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">virtual</span> ~<span class="built_in">Layer</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Layer的执行函数</span></span><br><span class="line"><span class="comment">   * @param inputs 层的输入</span></span><br><span class="line"><span class="comment">   * @param outputs 层的输出</span></span><br><span class="line"><span class="comment">   * @return 执行的状态</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> InferStatus <span class="title">Forward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">const</span> std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt;&amp; inputs,</span></span></span><br><span class="line"><span class="params"><span class="function">      std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt;&amp; outputs)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Layer的执行函数</span></span><br><span class="line"><span class="comment">   * @param current_operator 当前的operator</span></span><br><span class="line"><span class="comment">   * @return 执行的状态</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> InferStatus <span class="title">Forward</span><span class="params">()</span></span>;</span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>以上的代码定义了<code>Layer</code>类的构造函数，它只需要一个<code>layer_name</code>变量来指定该算子的名称。重点关注带有参数的<code>Forward</code>方法，它是算子中定义的计算函数。</p>
<p>这个函数有两个参数，分别是<code>inputs</code>和<code>outputs</code>。它们是在计算过程中所需的输入和输出张量数组。<strong>每个算子的派生类都需要重写这个带参数的<code>Forward</code>方法，并在其中定义计算的具体逻辑。</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Layer</span> &#123;</span><br><span class="line">   ...</span><br><span class="line">   ...</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">std::weak_ptr&lt;RuntimeOperator&gt; runtime_operator_;</span><br><span class="line">std::string layer_name_;  <span class="comment">/// Layer的名称  </span></span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>在<code>Layer</code>类中有两个成员变量。一个是在构造函数中指定的算子名称 <code>layer_name</code>，另一个是与该算子关联的计算节点变量 <code>RuntimeOperator</code>。在之前回顾了 <code>RuntimeOperator</code> 的定义：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">RuntimeOperator</span> &#123;</span><br><span class="line">...</span><br><span class="line">std::shared_ptr&lt;Layer&gt; layer;  <span class="comment">/// 节点对应的计算Layer</span></span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">classDiagram</span><br><span class="line">      RuntimeOperator &lt;-- Layer</span><br><span class="line">      Layer &lt;-- RuntimeOperator </span><br><span class="line">      class RuntimeOperator&#123;</span><br><span class="line">         - Tensor Array inputs</span><br><span class="line">         - Tensor Array outputs</span><br><span class="line">         - Layer Reference layer</span><br><span class="line">      &#125;</span><br><span class="line">      class Layer&#123;</span><br><span class="line">      - RuntimeOperator Reference runtime_operator</span><br><span class="line">         + Forward(void) InferStatus</span><br><span class="line">      + Forward(inputs,outputs) InferStatus</span><br><span class="line">      &#125;</span><br><span class="line">      Layer &lt;|-- ReLULayer</span><br><span class="line">      Layer &lt;|-- ConvLayer</span><br><span class="line">      Layer &lt;|-- MaxPoolingLayer</span><br><span class="line">      class ReLULayer&#123;</span><br><span class="line">      + Forward(inputs,outputs) InferStatus</span><br><span class="line">      &#125;</span><br><span class="line">      class ConvLayer&#123;</span><br><span class="line">      + Forward(inputs,outputs) InferStatus</span><br><span class="line">      &#125;</span><br><span class="line">         class MaxPoolingLayer&#123;</span><br><span class="line">      + Forward(inputs,outputs) InferStatus</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure>

<p><code>RuntimeOperator</code>与该节点对应的 <code>Layer</code> 相关联，而 <code>Layer</code> 也关联了它所属的 <code>RuntimeOperator</code>，因此它们之间是双向关联的关系。</p>
<p><code>Layer</code> 类中不带参数的 <code>Forward</code> 方法。这个方法是所有算子的父类方法，<strong>它的作用是准备输入和输出数据，并使用这些数据调用每个派生类算子中各自实现的计算过程</strong>（上文提到的带参数的 <code>Forward</code> 函数）。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">InferStatus <span class="title">Layer::Forward</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="built_in">LOG_IF</span>(FATAL, <span class="keyword">this</span>-&gt;runtime_operator_.<span class="built_in">expired</span>())</span><br><span class="line">      &lt;&lt; <span class="string">&quot;Runtime operator is expired or nullptr&quot;</span>;</span><br><span class="line"><span class="comment">// 获取算子相关的计算节点</span></span><br><span class="line"><span class="type">const</span> <span class="keyword">auto</span>&amp; runtime_operator = <span class="keyword">this</span>-&gt;runtime_operator_.<span class="built_in">lock</span>();</span><br><span class="line"><span class="comment">// 准备节点layer计算所需要的输入</span></span><br><span class="line"><span class="type">const</span> std::vector&lt;std::shared_ptr&lt;RuntimeOperand&gt;&gt;&amp; input_operand_datas = runtime_operator-&gt;input_operands_seq;</span><br><span class="line"><span class="comment">// layer的输入</span></span><br><span class="line">std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt; layer_input_datas;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; input_operand_data : input_operand_datas) &#123;</span><br><span class="line">   <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; input_data : input_operand_data-&gt;datas) &#123;</span><br><span class="line">      layer_input_datas.<span class="built_in">push_back</span>(input_data);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在<code>Layer</code>类的不带参数的<code>Forward</code>方法中，首先获取与该<code>Layer</code>相对应的计算节点<code>RuntimeOperator</code>。它们之间是双向关联的关系，一个算子对应一个计算节点（<code>RuntimeOperator</code>），一个计算节点对应一个算子(<code>Layer</code>)。</p>
<p>从计算节点中得到<strong>该节点对应的输入数</strong><code>input_operand_datas</code>以及<strong>该输入数存储的张量数据</strong><code>layer_input_datas</code>. 随后，再从计算节点中取出对应的输出数<code>output_operand_datas</code>.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> std::shared_ptr&lt;RuntimeOperand&gt;&amp; output_operand_datas =</span><br><span class="line">      runtime_operator-&gt;output_operands;</span><br><span class="line">InferStatus status = runtime_operator-&gt;layer-&gt;<span class="built_in">Forward</span>(</span><br><span class="line">      layer_input_datas, output_operand_datas-&gt;datas);</span><br></pre></td></tr></table></figure>

<p>在以上的步骤中，从计算节点<code>RuntimeOperator</code>中获取了相关的输入数和输出数，随后再使用对应的输入和输出张量<strong>去调用子类算子各自实现的，带参数的<code>Forward</code>函数</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line"></span><br><span class="line">父类Layer中Foward不带参数的版本--准备输入输出--&gt; 各子类Layer中Foward带参数的版本;</span><br><span class="line">各子类Layer中Foward带参数的版本--&gt;Relu::Foward带参数版本</span><br><span class="line">各子类Layer中Foward带参数的版本--&gt;Conv::Foward带参数版本</span><br><span class="line">各子类Layer中Foward带参数的版本--&gt;MaxPool::Forward带参数版本</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="Convolution-amp-Pooling-Operator"><a href="#Convolution-amp-Pooling-Operator" class="headerlink" title="Convolution &amp; Pooling Operator"></a>Convolution &amp; Pooling Operator</h2><h3 id="池化算子的定义"><a href="#池化算子的定义" class="headerlink" title="池化算子的定义"></a>池化算子的定义</h3><p>池化算子常用于缓解深度神经网络对位置的过度敏感性。</p>
<p>池化算子会在固定形状的窗口（即池化窗口）内对输入数据的元素进行计算，计算结果可以是池化窗口内元素的最大值或平均值，这种运算被称为最大池化或平均池化。</p>
<img src="/2024/12/24/Kuiper-Infer/pooling.png" class="" title="pooling">

<p>对于带填充的池化算子，输出特征图的大小和输入特征图的大小之间有以下等式关系：<br>$$<br>output ,size&#x3D; floor(\frac{input,size+2\times padding-pooling,size}{stride}+1)<br>$$</p>
<h3 id="卷积算子的定义"><a href="#卷积算子的定义" class="headerlink" title="卷积算子的定义"></a>卷积算子的定义</h3><p>卷积是信号处理和图像处理中常用的运算操作之一。它通过将输入信号（如图像、音频等）与一个卷积核（也称为滤波器或权重）进行相乘和累加的过程，用于在深度神经网络中提取特定的特征。因此，可以说卷积是最常用的算子之一。</p>
<ul>
<li><p>卷积定义二维表示：</p>
<p>$$Y[i, j] &#x3D; \sum_{m} \sum_{n} H[m, n] \cdot X[i+m, j+n]$$</p>
</li>
</ul>
<p>其中，$X$表示输入矩阵，$H$表示卷积核，$Y$表示输出矩阵，$i$和$j$表示输出矩阵中的输出像素坐标，$m$和$n$表示卷积核中的坐标，$i+m$和$j+n$用于将卷积核和输入矩阵进行对齐，分别表示输入图像中的某个元素坐标。<strong>通过这两个偏移量，可以确定卷积核在输入矩阵中的位置，并将其与对应位置的像素值相乘，然后求和得到输出矩阵的每个元素 $Y[i,j]$。</strong></p>
<ul>
<li><p>二维卷积计算过程直观展示如下图，卷积核以滑动窗口的形式，从输入中划过，计算点积并求和，得到卷积后的输出存于<code>output</code>中。</p>
 <img src="/2024/12/24/Kuiper-Infer/single_channel_conv.png" class="" title="single channel conv">
</li>
<li><p>单通道可以直观地被拓展成多通道，只需对多个单通道的卷积结果求和即可（请注意，下图中的kernel属于同一个卷积核中的不同通道），此时需要注意的是输入的通道数与卷积核的通道数需要保持一致。</p>
<p>如下图所示，可以看到一个多通道的输入和一个多通道的卷积核进行卷积计算，最后得到了<strong>一个单通道的输出</strong><code>output</code>. <strong>输入张量的通道数需要和卷积核的通道数个数相同</strong>,这里都是2个通道</p>
<p>input第一个通道和kernel第一个通道 对应位置内求卷积</p>
<p>input第二个通道和kernel第二个通道对应位置内求卷积</p>
<p>两者相加，得到对应位置的输出</p>
 <img src="/2024/12/24/Kuiper-Infer/multi_channel_channel_conv.png" class="" title="multi channel conv">
</li>
<li><p>对于单通道输出，只需要一个卷积核就可以完成，<strong>如果想要使得输出为多通道，则需使用多个不同的卷积核，即卷积核个数对应输出通道个数</strong>。</p>
<p>如下图所示，可以看到，如果使用两个卷积核，最后会产生一个<strong>多通道的输出</strong><code>output</code>，它有两个通道，分别为<code>c1</code>和<code>c2</code>.</p>
<p>有一个输入，输入的通道数为2</p>
<p>取出input_channel &#x3D; 1的输入通道，它需要分别和卷积核1的通道1做卷积，和卷积核2的通道1做卷积，再把二者相加。</p>
<p>取出输入的第一个通道input c1</p>
<p>取出input_channel&#x3D;2，输入第二个通道，它需要和卷积核1的通道2做卷积，和卷积核2的通道2做卷积，再把二者相加。</p>
 <img src="/2024/12/24/Kuiper-Infer/multi_kernel_conv.png" class="" title="multi kernel conv">
</li>
<li><p>组卷积（<code>group conv</code>），顾名思义就是将卷积分组，即在深度上进行分组，假设group&#x3D;2，则表示将原有的输入数据分成2组，如上图图所示，原本一个卷积核管全部通道，当分组之后，一个卷积核只需要管$\frac{input,channel}{group} &#x3D; 2 &#x2F; 2  &#x3D; 1$个通道，即如下图所示。</p>
</li>
<li><p>分组卷积早在<code>AlexNet</code>便得到了应用，Alex认为组卷积能够增加 卷积核之间的对角相关性，并减少训练参数，不容易过拟合，达到类似正则的效果。从下图可以看出，如果对一个多通道的输入运用组卷积，最后得到了一个多通道的输出<code>output</code>, 它有两个通道，分别为<code>c1</code>和<code>c2</code>.</p>
 <img src="/2024/12/24/Kuiper-Infer/group_conv.png" class="" title="group conv"></li>
</ul>
<p>总结：以上是二维卷积的基本定义，二维卷积的直观解释。<strong>普通卷积核的通道数需要与输入数据的通道数保持一致，而卷积核的数量则代表了输出数据的通道数。分组卷积核的通道数为输入数据通道数&#x2F;分组数</strong>在卷积计算中，输入输出大小的维度有以下的对应关系：<br>$$<br>output, size &#x3D; floor(\frac{input,size+ 2\times padding-kernel ,size}{stride }+1)<br>$$</p>
<p>上图例子中：output size &#x3D; ((4+2*0-3)&#x2F;1+1)  &#x3D; 2</p>
<h2 id="Expression-Layer"><a href="#Expression-Layer" class="headerlink" title="Expression Layer"></a>Expression Layer</h2><h3 id="表达式的定义"><a href="#表达式的定义" class="headerlink" title="表达式的定义"></a>表达式的定义</h3><p><code>PNNX</code>中的表达式就是一个二元的计算过程，类似如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">output_mid = input1 + input2;</span><br><span class="line">output = output_mid * input3;</span><br></pre></td></tr></table></figure>

<p>在<code>PNNX</code>的表达式层（Expression Layer）中，提供了一种计算表达式，该表达式能够在一定程度上折叠计算过程并消除中间变量。例如，在残差结构中的add操作在<code>PNNX</code>中就是一个表达式层。</p>
<p>下面是<code>PNNX</code>中对上述过程的计算表达式表示，其中的<code>@0</code>和<code>@1</code>代表之前提到的计算数<code>RuntimeOperand</code>，用于表示计算表达式中的输入节点。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mul(@2, add(@0, @1));</span><br></pre></td></tr></table></figure>

<p>尽管这个抽象表达式看起来比较简单，但实际上可能存在更为复杂的情况，例如以下的例子。因此，在这种情况下，需要一个强大而可靠的表达式解析和语法树构建功能。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add(add(mul(@0, @1), mul(@2, add(add(add(@0, @2), @3), @4))), @5);</span><br></pre></td></tr></table></figure>

<h3 id="词法解析"><a href="#词法解析" class="headerlink" title="词法解析"></a>词法解析</h3><h4 id="词法的定义"><a href="#词法的定义" class="headerlink" title="词法的定义"></a>词法的定义</h4><p>词法解析的目的是将**add(@0, mul(@1, @2))**拆分为多个Token，拆分后的Token依次为：</p>
<ol>
<li>Identifier: <strong>add</strong></li>
<li>Left bracket: <strong>(</strong></li>
<li>Input number: <strong>@0</strong></li>
<li>Comma: <strong>,</strong></li>
<li>Identifier: <strong>mul</strong></li>
<li>Left bracket: <strong>(</strong></li>
<li>Input number: <strong>@1</strong></li>
<li>Comma: <strong>,</strong></li>
<li>Input number:  <strong>@2</strong></li>
<li>Right bracket: <strong>)</strong></li>
</ol>
<p><code>Token</code>的类型定义如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum class</span> <span class="title class_">TokenType</span> &#123;</span><br><span class="line">  TokenUnknown = <span class="number">-9</span>,</span><br><span class="line">  TokenInputNumber = <span class="number">-8</span>,</span><br><span class="line">  TokenComma = <span class="number">-7</span>,</span><br><span class="line">  TokenAdd = <span class="number">-6</span>,</span><br><span class="line">  TokenMul = <span class="number">-5</span>,</span><br><span class="line">  TokenLeftBracket = <span class="number">-4</span>,</span><br><span class="line">  TokenRightBracket = <span class="number">-3</span>,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>Token的定义如下，包括以下变量：</p>
<ol>
<li>Token类型，包括add（加法），mul（乘法），bracket（左右括号）等；</li>
<li>Token在原句子中的开始和结束位置，即<code>start_pos</code>和<code>end_pos</code>；</li>
</ol>
<p>对于表达式**add(@0, mul(@1, @2))**，可以将它切分为多个Token，其中Token(add)的<code>start_pos</code>为0，<code>end_pos</code>为3。Token(left bracket)的<code>start_pos</code>为3，<code>end_pos</code>为4。Token(@0)的<code>start_pos</code>为4，<code>end_pos</code>为5，以此类推。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 词语Token</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Token</span> &#123;</span><br><span class="line">    TokenType token_type = TokenType::TokenUnknown;</span><br><span class="line">    <span class="type">int32_t</span> start_pos = <span class="number">0</span>; <span class="comment">// 词语开始的位置</span></span><br><span class="line">    <span class="type">int32_t</span> end_pos = <span class="number">0</span>;   <span class="comment">// 词语结束的位置</span></span><br><span class="line">    <span class="built_in">Token</span>(TokenType token_type, <span class="type">int32_t</span> start_pos, <span class="type">int32_t</span> end_pos)</span><br><span class="line">        : <span class="built_in">token_type</span>(token_type), <span class="built_in">start_pos</span>(start_pos), <span class="built_in">end_pos</span>(end_pos) &#123;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>最后，在词法解析结束后，需要将这些 Token（词语）按照它们的出现顺序和层级关系组成一棵语法树。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 语法树的节点</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">TokenNode</span> &#123;</span><br><span class="line">    <span class="type">int32_t</span> num_index = <span class="number">-1</span>;</span><br><span class="line">    std::shared_ptr&lt;TokenNode&gt; left = <span class="literal">nullptr</span>;   <span class="comment">// 语法树的左节点</span></span><br><span class="line">    std::shared_ptr&lt;TokenNode&gt; right = <span class="literal">nullptr</span>;  <span class="comment">// 语法树的右节点</span></span><br><span class="line">    <span class="built_in">TokenNode</span>(<span class="type">int32_t</span> num_index, std::shared_ptr&lt;TokenNode&gt; left,</span><br><span class="line">              std::shared_ptr&lt;TokenNode&gt; right);</span><br><span class="line">    <span class="built_in">TokenNode</span>() = <span class="keyword">default</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="词法的解析"><a href="#词法的解析" class="headerlink" title="词法的解析"></a>词法的解析</h4><h5 id="判断句子是否为空"><a href="#判断句子是否为空" class="headerlink" title="判断句子是否为空"></a>判断句子是否为空</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">CHECK</span>(!statement_.<span class="built_in">empty</span>()) &lt;&lt; <span class="string">&quot;The input statement is empty!&quot;</span>;</span><br></pre></td></tr></table></figure>

<h5 id="移除句子中的空格"><a href="#移除句子中的空格" class="headerlink" title="移除句子中的空格"></a>移除句子中的空格</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">statement_.<span class="built_in">erase</span>(std::<span class="built_in">remove_if</span>(statement_.<span class="built_in">begin</span>(), statement_.<span class="built_in">end</span>(),</span><br><span class="line">                                [](<span class="type">char</span> c) &#123; <span class="keyword">return</span> std::<span class="built_in">isspace</span>(c); &#125;),</span><br><span class="line">                 statement_.<span class="built_in">end</span>());</span><br><span class="line"><span class="built_in">CHECK</span>(!statement_.<span class="built_in">empty</span>()) &lt;&lt; <span class="string">&quot;The input statement is empty!&quot;</span>;</span><br></pre></td></tr></table></figure>

<p>如果表达式层中有表达式为<code>add(@0,   @1)</code>，删除其中的空格后就会得到新的表达式<code>add(@0,@1)</code>。</p>
<h5 id="逐个解析句子的字符"><a href="#逐个解析句子的字符" class="headerlink" title="逐个解析句子的字符"></a>逐个解析句子的字符</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; statement_.<span class="built_in">size</span>();) &#123;</span><br><span class="line">    <span class="type">char</span> c = statement_.<span class="built_in">at</span>(i);</span><br><span class="line">    <span class="keyword">if</span> (c == <span class="string">&#x27;a&#x27;</span>) &#123;</span><br><span class="line">        <span class="built_in">CHECK</span>(i + <span class="number">1</span> &lt; statement_.<span class="built_in">size</span>() &amp;&amp; statement_.<span class="built_in">at</span>(i + <span class="number">1</span>) == <span class="string">&#x27;d&#x27;</span>)</span><br><span class="line">            &lt;&lt; <span class="string">&quot;Parse add token failed, illegal character: &quot;</span></span><br><span class="line">            &lt;&lt; statement_.<span class="built_in">at</span>(i + <span class="number">1</span>);</span><br><span class="line">        <span class="built_in">CHECK</span>(i + <span class="number">2</span> &lt; statement_.<span class="built_in">size</span>() &amp;&amp; statement_.<span class="built_in">at</span>(i + <span class="number">2</span>) == <span class="string">&#x27;d&#x27;</span>)</span><br><span class="line">            &lt;&lt; <span class="string">&quot;Parse add token failed, illegal character: &quot;</span></span><br><span class="line">            &lt;&lt; statement_.<span class="built_in">at</span>(i + <span class="number">2</span>);</span><br><span class="line">        <span class="function">Token <span class="title">token</span><span class="params">(TokenType::TokenAdd, i, i + <span class="number">3</span>)</span></span>;</span><br><span class="line">        tokens_.<span class="built_in">push_back</span>(token);</span><br><span class="line">        std::string token_operation =</span><br><span class="line">            std::<span class="built_in">string</span>(statement_.<span class="built_in">begin</span>() + i, statement_.<span class="built_in">begin</span>() + i + <span class="number">3</span>);</span><br><span class="line">        token_strs_.<span class="built_in">push_back</span>(token_operation);</span><br><span class="line">        i = i + <span class="number">3</span>;</span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假设字符 <code>c</code> 表示当前的字符。如果 <code>c</code> 等于字符 ‘a’，根据的词法规定，Token 中以 ‘a’ 开头的情况只有 add。因此，需要判断接下来的两个字符是否分别是 ‘d’ 和 ‘d’。如果不是，则报错。如果是的话，则初始化一个新的 Token，并保存其在表达式中的初始和结束位置。</p>
<p>举个例子，如果表达式中的单词以 ‘a’ 开头，那么它只能是 add，而不能是其他词汇表之外的单词，例如 <code>axc</code> 等情况。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">CHECK</span>(i + <span class="number">1</span> &lt; statement_.<span class="built_in">size</span>() &amp;&amp; statement_.<span class="built_in">at</span>(i + <span class="number">1</span>) == <span class="string">&#x27;d&#x27;</span>)</span><br><span class="line">    &lt;&lt; <span class="string">&quot;Parse add token failed, illegal character: &quot;</span></span><br><span class="line">    &lt;&lt; statement_.<span class="built_in">at</span>(i + <span class="number">1</span>);</span><br><span class="line"><span class="built_in">CHECK</span>(i + <span class="number">2</span> &lt; statement_.<span class="built_in">size</span>() &amp;&amp; statement_.<span class="built_in">at</span>(i + <span class="number">2</span>) == <span class="string">&#x27;d&#x27;</span>)</span><br><span class="line">    &lt;&lt; <span class="string">&quot;Parse add token failed, illegal character: &quot;</span></span><br><span class="line">    &lt;&lt; statement_.<span class="built_in">at</span>(i + <span class="number">2</span>);</span><br><span class="line"><span class="function">Token <span class="title">token</span><span class="params">(TokenType::TokenAdd, i, i + <span class="number">3</span>)</span></span>;</span><br><span class="line">tokens_.<span class="built_in">push_back</span>(token);</span><br><span class="line">std::string token_operation =</span><br><span class="line">    std::<span class="built_in">string</span>(statement_.<span class="built_in">begin</span>() + i, statement_.<span class="built_in">begin</span>() + i + <span class="number">3</span>);</span><br><span class="line">token_strs_.<span class="built_in">push_back</span>(token_operation);</span><br></pre></td></tr></table></figure>

<p>如果在第一行中，判断第二个字符是否为 ‘d’；若是，在第二行中，判断第三个字符是否也是 ‘d’。如果满足条件，将初始化一个 Token 实例，并保存该单词在句子中的起始位置和结束位置。</p>
<p>同样地，如果某个字符 <code>c</code> 是 ‘m’，需要判断接下来的字符是否是 ‘u’ 和 ‘l’。如果不满足条件，则说明的表达式中出现了词汇表之外的单词（因为词汇表只允许以 ‘m’ 开头的单词是 “mul”）。如果满足条件，同样会初始化一个 Token 实例，并保存该单词的起始和结束位置，以及 Token 的类型。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (c == <span class="string">&#x27;@&#x27;</span>) &#123;</span><br><span class="line">    <span class="built_in">CHECK</span>(i + <span class="number">1</span> &lt; statement_.<span class="built_in">size</span>() &amp;&amp; std::<span class="built_in">isdigit</span>(statement_.<span class="built_in">at</span>(i + <span class="number">1</span>)))</span><br><span class="line">        &lt;&lt; <span class="string">&quot;Parse number token failed, illegal character: &quot;</span> &lt;&lt; c;</span><br><span class="line">    <span class="type">int32_t</span> j = i + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (; j &lt; statement_.<span class="built_in">size</span>(); ++j) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!std::<span class="built_in">isdigit</span>(statement_.<span class="built_in">at</span>(j))) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">Token <span class="title">token</span><span class="params">(TokenType::TokenInputNumber, i, j)</span></span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(token.start_pos &lt; token.end_pos);</span><br><span class="line">    tokens_.<span class="built_in">push_back</span>(token);</span><br><span class="line">    std::string token_input_number = std::<span class="built_in">string</span>(statement_.<span class="built_in">begin</span>() + i, statement_.<span class="built_in">begin</span>() + j);</span><br><span class="line">    token_strs_.<span class="built_in">push_back</span>(token_input_number);</span><br><span class="line">    i = j;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果第一个字符是 ‘@’，需要读取 ‘@’ 后面的所有数字，例如对于@31231，需要读取@符号之后的所有数字。如果紧跟在 ‘@’ 后面的字符不是数字，则报错。如果是数字，则将这些数字全部读取并组成一个单词（Token）。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (c == <span class="string">&#x27;,&#x27;</span>) &#123;</span><br><span class="line">      Token <span class="built_in">token</span>(TokenType::TokenComma, i, i + <span class="number">1</span>);</span><br><span class="line">      tokens_.<span class="built_in">push_back</span>(token);</span><br><span class="line">      std::string token_comma =</span><br><span class="line">          std::<span class="built_in">string</span>(statement_.<span class="built_in">begin</span>() + i, statement_.<span class="built_in">begin</span>() + i + <span class="number">1</span>);</span><br><span class="line">      token_strs_.<span class="built_in">push_back</span>(token_comma);</span><br><span class="line">      i += <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果第一个字符是’,’逗号，那么直接读取这个字符作为一个新的Token。</p>
<p>最后，在正确解析和创建这些 Token 后，将它们放入名为 <code>tokens</code> 的数组中，以便进行后续处理。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokens_.<span class="built_in">push_back</span>(token);</span><br></pre></td></tr></table></figure>

<h3 id="语法解析"><a href="#语法解析" class="headerlink" title="语法解析"></a>语法解析</h3><h4 id="语法树的定义"><a href="#语法树的定义" class="headerlink" title="语法树的定义"></a>语法树的定义</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">TokenNode</span> &#123;</span><br><span class="line">    <span class="type">int32_t</span> num_index = <span class="number">-1</span>;</span><br><span class="line">    std::shared_ptr&lt;TokenNode&gt; left = <span class="literal">nullptr</span>;</span><br><span class="line">    std::shared_ptr&lt;TokenNode&gt; right = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="built_in">TokenNode</span>(<span class="type">int32_t</span> num_index, std::shared_ptr&lt;TokenNode&gt; left, std::shared_ptr&lt;TokenNode&gt; right);</span><br><span class="line">    <span class="built_in">TokenNode</span>() = <span class="keyword">default</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>在进行语法分析时，可以根据词法分析得到的 <code>token</code> 数组构建抽象语法树。抽象语法树是一个由二叉树组成的结构，每个节点都存储了操作符号或值，并通过左子节点和右子节点与其他节点连接。</p>
<p>对于表达式 “add (@0, @1)”，当 <code>num_index</code> 等于 1 时，表示计算数为 @0；当 <code>num_index</code> 等于 2 时，表示计算数为 @1。若 <code>num_index</code> 为负数，则说明当前节点是一个计算节点，如 “mul” 或 “add” 等。</p>
<p>以下是一个简单的示例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">   add</span><br><span class="line">  /   \</span><br><span class="line">@0     @1</span><br></pre></td></tr></table></figure>

<p>在这个示例中，根节点是 “add”，左子节点是 “@0”，右子节点是 “@1”。这个抽象语法树表示了一个将 “@0” 和 “@1” 进行相加的表达式。</p>
<p>通过将词法分析得到的 <code>token</code> 数组解析并构建抽象语法树，可以进一步对表达式进行语义分析和求值等操作。</p>
<h4 id="递归向下的解析"><a href="#递归向下的解析" class="headerlink" title="递归向下的解析"></a>递归向下的解析</h4><p>语法解析的过程是递归向下的,定义在<code>Generate_</code>函数中。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::shared_ptr&lt;TokenNode&gt; <span class="title">ExpressionParser::Generate_</span><span class="params">(<span class="type">int32_t</span> &amp;index)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>());</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> current_token = <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index);</span><br><span class="line">    <span class="built_in">CHECK</span>(current_token.token_type == TokenType::TokenInputNumber</span><br><span class="line">          || current_token.token_type == TokenType::TokenAdd || current_token.token_type == TokenType::TokenMul);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个函数处理的对象是词法解析的Token（单词）数组，因为<code>Generate_</code>是一个递归函数，所以<code>index</code>参数指向Token数组中的当前处理位置.</p>
<p><code>current_token</code>表示当前被处理的Token，它作为<strong>当前递归层</strong>的第一个Token，必须是以下类型之一。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">TokenInputNumber = <span class="number">0</span>,</span><br><span class="line">TokenAdd = <span class="number">2</span>,</span><br><span class="line">TokenMul = <span class="number">3</span>,</span><br></pre></td></tr></table></figure>

<p><strong>如果当前Token的类型是输入数字类型，那么会直接返回一个操作数Token作为叶子节点，不再进行下一层递归（如下）。</strong>例如，在表达式add(@0, @1)中的@0和@1被归类为输入数字类型的Token，在解析到这两个Token时会直接创建并返回语法树节点<code>TokenNode</code>。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (current_token.token_type == TokenType::TokenInputNumber) &#123;</span><br><span class="line">    <span class="type">uint32_t</span> start_pos = current_token.start_pos + <span class="number">1</span>;</span><br><span class="line">    <span class="type">uint32_t</span> end_pos = current_token.end_pos;</span><br><span class="line">    <span class="built_in">CHECK</span>(end_pos &gt; start_pos);</span><br><span class="line">    <span class="built_in">CHECK</span>(end_pos &lt;= <span class="keyword">this</span>-&gt;statement_.<span class="built_in">length</span>());</span><br><span class="line">    <span class="type">const</span> std::string &amp;str_number =</span><br><span class="line">        std::<span class="built_in">string</span>(<span class="keyword">this</span>-&gt;statement_.<span class="built_in">begin</span>() + start_pos, <span class="keyword">this</span>-&gt;statement_.<span class="built_in">begin</span>() + end_pos);</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">make_shared</span>&lt;TokenNode&gt;(std::<span class="built_in">stoi</span>(str_number), <span class="literal">nullptr</span>, <span class="literal">nullptr</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>如果当前Token的类型是mul或者add，需要进行下一层递归来构建对应的左子节点和右子节点。</strong></p>
<p>例如，在处理add(@1,@2)时，遇到add token之后，如下的第一行代码，需要做以下的两步：</p>
<ol>
<li>首先判断是否存在左括号（left bracket）</li>
<li>然后继续向下递归以获取@1，如下的第14行到17行代码，但由于@1代表的是数字类型，递归后立即返回，如以上代码块中第一行对数字类型Token的处理。</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (current_token.token_type == TokenType::TokenMul || current_token.token_type == TokenType::TokenAdd) &#123;</span><br><span class="line">    std::shared_ptr&lt;TokenNode&gt; current_node = std::<span class="built_in">make_shared</span>&lt;TokenNode&gt;();</span><br><span class="line">    current_node-&gt;num_index = -<span class="built_in">int</span>(current_token.token_type);</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>());</span><br><span class="line">    <span class="comment">// 判断add之后是否有( left bracket</span></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index).token_type == TokenType::TokenLeftBracket);</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>());</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> left_token = <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index);</span><br><span class="line">    <span class="comment">// 判断当前需要处理的left token是不是合法类型</span></span><br><span class="line">    <span class="keyword">if</span> (left_token.token_type == TokenType::TokenInputNumber</span><br><span class="line">        || left_token.token_type == TokenType::TokenAdd || left_token.token_type == TokenType::TokenMul) &#123;</span><br><span class="line">        <span class="comment">// (之后进行向下递归得到@0</span></span><br><span class="line">        current_node-&gt;left = <span class="built_in">Generate_</span>(index);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown token type: &quot;</span> &lt;&lt; <span class="built_in">int</span>(left_token.token_type);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在第17行当左子树递归构建完毕后，将它赋值到add节点的左子树上。对于表达式<code>add(@0, @1)</code>，将左子树连接到<code>current_node</code>的<code>left</code>指针中，随后开始构建右子树。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">graph TB;</span><br><span class="line">1((add))--&gt;2((ant 0))</span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">index += <span class="number">1</span>; </span><br><span class="line"><span class="comment">// 当前的index指向add(@1,@2)中的逗号</span></span><br><span class="line"><span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>());</span><br><span class="line"><span class="comment">// 判断是否是逗号</span></span><br><span class="line"><span class="built_in">CHECK</span>(<span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index).token_type == TokenType::TokenComma);</span><br><span class="line"></span><br><span class="line">index += <span class="number">1</span>;</span><br><span class="line"><span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>());</span><br><span class="line"><span class="comment">// current_node-&gt;right = Generate_(index);构建右子树</span></span><br><span class="line"><span class="type">const</span> <span class="keyword">auto</span> right_token = <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index);</span><br><span class="line"><span class="keyword">if</span> (right_token.token_type == TokenType::TokenInputNumber</span><br><span class="line">    || right_token.token_type == TokenType::TokenAdd || right_token.token_type == TokenType::TokenMul) &#123;</span><br><span class="line">  current_node-&gt;right = <span class="built_in">Generate_</span>(index);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown token type: &quot;</span> &lt;&lt; <span class="built_in">int</span>(left_token.token_type);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">index += <span class="number">1</span>;</span><br><span class="line"><span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>());</span><br><span class="line"><span class="built_in">CHECK</span>(<span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index).token_type == TokenType::TokenRightBracket);</span><br><span class="line"><span class="keyword">return</span> current_node;</span><br></pre></td></tr></table></figure>

<p>随后需要判断@0之后是否存在comma token，如上代码中的第五行。在构建右子树的过程中，对于表达式<code>add(@1,@2)</code>，当<code>index</code>指向逗号的位置时，首先需要判断是否存在逗号。接下来，开始构建右子树，在右子树的向下递归分析中，会得到<code>@2</code>作为一个叶子节点。</p>
<p>当右子树构建完成后，将该节点（即<code>Generate_</code>返回的<code>TokenNode</code>，此处为一个叶子节点，其数据为<code>@1</code>）放置于<code>current_node</code>的<code>right</code>指针中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">graph TB;</span><br><span class="line">1((add))--&gt;2((ant 0))</span><br><span class="line"></span><br><span class="line">1((add))--&gt;3((ant 1))</span><br></pre></td></tr></table></figure>

<h3 id="对语法树的转换"><a href="#对语法树的转换" class="headerlink" title="对语法树的转换"></a>对语法树的转换</h3><h4 id="逆波兰式"><a href="#逆波兰式" class="headerlink" title="逆波兰式"></a>逆波兰式</h4><p>来以一个简单的例子来说明，对于计算式<code>add(@0,@1)</code>，首先遇到的节点是<code>add</code>，但在遇到<code>add</code>时缺少进行计算所需的具体数据<code>@0</code>和<code>@1</code>。</p>
<p><strong>因此，需要进行逆波兰转换，将操作数放在前面，计算放在后面。</strong>该转换的实现非常简单，<strong>只需对原有的二叉树进行后续遍历即可：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">ReversePolish</span><span class="params">(<span class="type">const</span> std::shared_ptr&lt;TokenNode&gt; &amp;root_node,</span></span></span><br><span class="line"><span class="params"><span class="function">                   std::vector&lt;std::shared_ptr&lt;TokenNode&gt;&gt; &amp;reverse_polish)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (root_node != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="built_in">ReversePolish</span>(root_node-&gt;left, reverse_polish);</span><br><span class="line">        <span class="built_in">ReversePolish</span>(root_node-&gt;right, reverse_polish);</span><br><span class="line">        reverse_polish.<span class="built_in">push_back</span>(root_node);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>逆波兰式化后的表达如下：</p>
<p>对于 <code>add (@0,@1)</code>，逆波兰式为：<code>@0,@1,add</code></p>
<p>对于 <code>add(mul(@0,@1),@2)</code>，逆波兰式为：<code>@0,@1,mul,@2,add</code></p>
<p><strong>通过逆波兰转换，可以将原式转换为计算式的输入数放在前面，操作符号放在后面的形式。</strong>逆波兰式的特点是消除了括号的需求，使得计算顺序更加清晰和直观。</p>
<h3 id="过程总述"><a href="#过程总述" class="headerlink" title="过程总述"></a>过程总述</h3><p>经过这样的转换，可以确保在每次遇到计算节点时所需的操作数已经准备就绪。</p>
<ol>
<li>首先，传入一个表达式字符串，例如add(mul(@0,@1),@2)</li>
<li>接下来，对add(mul(@0,@1),@2)进行词法分析，将其拆分为多个tokens，在拆分过程中需要进行词法校验。</li>
<li>然后，根据已知的tokens数组，通过递归向下遍历进行语法分析，从而得到相应的计算二叉树。计算二叉树的各个节点可以是add、mul或者@0、@1等。</li>
<li>最后，对计算二叉树进行逆波兰变换，得到的逆波兰式如下：@0,@1,mul,@2,add。</li>
</ol>
<h2 id="ResNet-amp-YOLOv5-Infer"><a href="#ResNet-amp-YOLOv5-Infer" class="headerlink" title="ResNet &amp; YOLOv5 Infer"></a>ResNet &amp; YOLOv5 Infer</h2><p>TODO</p>
<h2 id="homework"><a href="#homework" class="headerlink" title="homework"></a>homework</h2><h3 id="course1"><a href="#course1" class="headerlink" title="course1"></a>course1</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// axby.cpp</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Axby</span><span class="params">(<span class="type">const</span> arma::fmat &amp;x, <span class="type">const</span> arma::fmat &amp;w, <span class="type">const</span> arma::fmat &amp;b,</span></span></span><br><span class="line"><span class="params"><span class="function">          arma::fmat &amp;y)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 把代码写这里 完成y = w * x + b的运算</span></span><br><span class="line">  y = w * x + b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">EPowerMinus</span><span class="params">(<span class="type">const</span> arma::fmat &amp;x, arma::fmat &amp;y)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 把代码写这里 完成y = e^&#123;-x&#125;的运算</span></span><br><span class="line">  <span class="function">arma::fmat <span class="title">eMat</span><span class="params">(x.n_rows, x.n_cols)</span></span>;</span><br><span class="line">  eMat.<span class="built_in">fill</span>(std::<span class="built_in">exp</span>(<span class="number">1.0</span>));</span><br><span class="line">  y = arma::<span class="built_in">pow</span>(eMat, -x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="course2"><a href="#course2" class="headerlink" title="course2"></a>course2</h3><ol>
<li>Tensor::Flatten</li>
<li>Tensor::Padding</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// tensor.cpp</span></span><br><span class="line"><span class="type">void</span> Tensor&lt;<span class="type">float</span>&gt;::<span class="built_in">Flatten</span>(<span class="type">bool</span> row_major) &#123;</span><br><span class="line">  <span class="type">const</span> std::vector&lt;<span class="type">uint32_t</span>&gt; flatten_size = &#123;<span class="keyword">this</span>-&gt;<span class="built_in">size</span>()&#125;;</span><br><span class="line">  <span class="keyword">this</span>-&gt;<span class="built_in">Reshape</span>(flatten_size, row_major);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> Tensor&lt;<span class="type">float</span>&gt;::<span class="built_in">Padding</span>(<span class="type">const</span> std::vector&lt;<span class="type">uint32_t</span>&gt;&amp; pads,</span><br><span class="line">                            <span class="type">float</span> padding_value) &#123;</span><br><span class="line">    <span class="built_in">CHECK</span>(!<span class="keyword">this</span>-&gt;data_.<span class="built_in">empty</span>());</span><br><span class="line">    <span class="built_in">CHECK_EQ</span>(pads.<span class="built_in">size</span>(), <span class="number">4</span>);</span><br><span class="line">    <span class="comment">// 四周填充的维度</span></span><br><span class="line">    <span class="type">uint32_t</span> pad_rows1 = pads.<span class="built_in">at</span>(<span class="number">0</span>);  <span class="comment">// up</span></span><br><span class="line">    <span class="type">uint32_t</span> pad_rows2 = pads.<span class="built_in">at</span>(<span class="number">1</span>);  <span class="comment">// bottom</span></span><br><span class="line">    <span class="type">uint32_t</span> pad_cols1 = pads.<span class="built_in">at</span>(<span class="number">2</span>);  <span class="comment">// left</span></span><br><span class="line">    <span class="type">uint32_t</span> pad_cols2 = pads.<span class="built_in">at</span>(<span class="number">3</span>);  <span class="comment">// right</span></span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> rows = <span class="keyword">this</span>-&gt;<span class="built_in">rows</span>();</span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> cols = <span class="keyword">this</span>-&gt;<span class="built_in">cols</span>();</span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> channels = <span class="keyword">this</span>-&gt;data_.n_slices;</span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> new_rows = rows + pad_rows1 + pad_rows2;</span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> new_cols = cols + pad_cols1 + pad_cols2;</span><br><span class="line"></span><br><span class="line">    arma::fcube new_data = arma::<span class="built_in">fcube</span>(new_rows, new_cols, channels);</span><br><span class="line">    new_data.<span class="built_in">fill</span>(padding_value);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 方式一：通过循环逐个赋值填充（记录开始时间，精确到纳秒）</span></span><br><span class="line">    <span class="keyword">auto</span> start_loop = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">uint32_t</span> c = <span class="number">0</span>; c &lt; channels; ++c) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; rows; ++i) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">uint32_t</span> j = <span class="number">0</span>; j &lt; cols; ++j) &#123;</span><br><span class="line">                new_data.<span class="built_in">at</span>(i + pad_rows1, j + pad_cols1, c) = <span class="keyword">this</span>-&gt;data_.<span class="built_in">at</span>(i, j, c);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">auto</span> end_loop = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">    <span class="keyword">auto</span> duration_loop = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::nanoseconds&gt;(end_loop - start_loop).<span class="built_in">count</span>();</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Time taken by loop-based padding (in nanoseconds): &quot;</span> &lt;&lt; duration_loop &lt;&lt; <span class="string">&quot; ns&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 重置new_data，重新填充初始值，为方式二做准备</span></span><br><span class="line">    new_data.<span class="built_in">fill</span>(padding_value);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 方式二：使用subcube赋值填充（记录开始时间，精确到纳秒）</span></span><br><span class="line">    <span class="keyword">auto</span> start_subcube = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">    new_data.<span class="built_in">subcube</span>(pad_rows1, pad_cols1, <span class="number">0</span>, new_rows - pad_rows2 - <span class="number">1</span>,</span><br><span class="line">                     new_cols - pad_cols2 - <span class="number">1</span>, channels - <span class="number">1</span>) = <span class="keyword">this</span>-&gt;data_;</span><br><span class="line">    <span class="keyword">auto</span> end_subcube = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">    <span class="keyword">auto</span> duration_subcube = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::nanoseconds&gt;(end_subcube - start_subcube).<span class="built_in">count</span>();</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Time taken by subcube-based padding (in nanoseconds): &quot;</span> &lt;&lt; duration_subcube &lt;&lt; <span class="string">&quot; ns&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">this</span>-&gt;data_ = std::<span class="built_in">move</span>(new_data);</span><br><span class="line">    <span class="keyword">this</span>-&gt;raw_shapes_ = std::vector&lt;<span class="type">uint32_t</span>&gt;&#123;channels, new_rows, new_cols&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="course3"><a href="#course3" class="headerlink" title="course3"></a>course3</h3><ol>
<li>RuntimeGraph::InitGraphParams</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// runtime_ir.cpp</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">RuntimeGraph::InitGraphParams</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">const</span> std::map&lt;std::string, pnnx::Parameter&gt; &amp;params,</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">const</span> std::shared_ptr&lt;RuntimeOperator&gt; &amp;runtime_operator)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span> &amp;[name, parameter]: params) &#123;</span><br><span class="line">      <span class="type">const</span> <span class="type">int</span> type = parameter.type;</span><br><span class="line">      <span class="keyword">switch</span> (type) &#123;</span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">int</span><span class="params">(RuntimeParameterType::kParameterUnknown)</span>: &#123;</span></span><br><span class="line">               RuntimeParameter *runtime_parameter = <span class="keyword">new</span> RuntimeParameter;</span><br><span class="line">               runtime_operator-&gt;params.<span class="built_in">insert</span>(&#123;name, runtime_parameter&#125;);</span><br><span class="line">               <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">int</span><span class="params">(RuntimeParameterType::kParameterBool)</span>: &#123;</span></span><br><span class="line">               RuntimeParameterBool *runtime_parameter = <span class="keyword">new</span> RuntimeParameterBool;</span><br><span class="line">               runtime_parameter-&gt;value = parameter.b;</span><br><span class="line">               runtime_operator-&gt;params.<span class="built_in">insert</span>(&#123;name, runtime_parameter&#125;);</span><br><span class="line">               <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">int</span><span class="params">(RuntimeParameterType::kParameterInt)</span>: &#123;</span></span><br><span class="line">               RuntimeParameterInt *runtime_parameter = <span class="keyword">new</span> RuntimeParameterInt;</span><br><span class="line">               runtime_parameter-&gt;value = parameter.i;</span><br><span class="line">               runtime_operator-&gt;params.<span class="built_in">insert</span>(&#123;name, runtime_parameter&#125;);</span><br><span class="line">               <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">int</span><span class="params">(RuntimeParameterType::kParameterFloat)</span>: &#123;</span></span><br><span class="line">               RuntimeParameterFloat *runtime_parameter = <span class="keyword">new</span> RuntimeParameterFloat;</span><br><span class="line">               runtime_parameter-&gt;value = parameter.f;</span><br><span class="line">               runtime_operator-&gt;params.<span class="built_in">insert</span>(&#123;name, runtime_parameter&#125;);</span><br><span class="line">               <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">int</span><span class="params">(RuntimeParameterType::kParameterString)</span>: &#123;</span></span><br><span class="line">               RuntimeParameterString *runtime_parameter = <span class="keyword">new</span> RuntimeParameterString;</span><br><span class="line">               runtime_parameter-&gt;value = parameter.s;</span><br><span class="line">               runtime_operator-&gt;params.<span class="built_in">insert</span>(&#123;name, runtime_parameter&#125;);</span><br><span class="line">               <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">int</span><span class="params">(RuntimeParameterType::kParameterIntArray)</span>: &#123;</span></span><br><span class="line">               RuntimeParameterIntArray *runtime_parameter =</span><br><span class="line">                        <span class="keyword">new</span> RuntimeParameterIntArray;</span><br><span class="line">               runtime_parameter-&gt;value = parameter.ai;</span><br><span class="line">               runtime_operator-&gt;params.<span class="built_in">insert</span>(&#123;name, runtime_parameter&#125;);</span><br><span class="line">               <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">int</span><span class="params">(RuntimeParameterType::kParameterFloatArray)</span>: &#123;</span></span><br><span class="line">               RuntimeParameterFloatArray *runtime_parameter =</span><br><span class="line">                        <span class="keyword">new</span> RuntimeParameterFloatArray;</span><br><span class="line">               runtime_parameter-&gt;value = parameter.af;</span><br><span class="line">               runtime_operator-&gt;params.<span class="built_in">insert</span>(&#123;name, runtime_parameter&#125;);</span><br><span class="line">               <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">int</span><span class="params">(RuntimeParameterType::kParameterStringArray)</span>: &#123;</span></span><br><span class="line">               RuntimeParameterStringArray *runtime_parameter =</span><br><span class="line">                        <span class="keyword">new</span> RuntimeParameterStringArray;</span><br><span class="line">               runtime_parameter-&gt;value = parameter.as;</span><br><span class="line">               runtime_operator-&gt;params.<span class="built_in">insert</span>(&#123;name, runtime_parameter&#125;);</span><br><span class="line">               <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">default</span>: &#123;</span><br><span class="line">               <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown parameter type: &quot;</span> &lt;&lt; type;</span><br><span class="line">            &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="course4"><a href="#course4" class="headerlink" title="course4"></a>course4</h3><ol>
<li>TopoSort</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// runtime_ir.hpp</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">KahnTopoSort</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// runtime_ir.cpp</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">RuntimeGraph::KahnTopoSort</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::unordered_map&lt;std::shared_ptr&lt;RuntimeOperator&gt;, <span class="type">int</span>&gt; in_degree;</span><br><span class="line">    std::queue&lt;std::shared_ptr&lt;RuntimeOperator&gt;&gt; zero_in_degree_queue;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算所有节点的入度</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; op : operators_) &#123;</span><br><span class="line">        in_degree[op] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; op : operators_) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; [_, next_op] : op-&gt;output_operators) &#123;</span><br><span class="line">            <span class="keyword">if</span> (next_op != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">                in_degree[next_op]++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 找到所有入度为0的节点</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; [op, degree] : in_degree) &#123;</span><br><span class="line">        <span class="keyword">if</span> (degree == <span class="number">0</span>) &#123;</span><br><span class="line">            zero_in_degree_queue.<span class="built_in">push</span>(op);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 处理队列中的节点</span></span><br><span class="line">    <span class="keyword">while</span> (!zero_in_degree_queue.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        <span class="keyword">auto</span> op = zero_in_degree_queue.<span class="built_in">front</span>();</span><br><span class="line">        zero_in_degree_queue.<span class="built_in">pop</span>();</span><br><span class="line">        topo_operators_.<span class="built_in">push_back</span>(op);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; [_, next_op] : op-&gt;output_operators) &#123;</span><br><span class="line">            <span class="keyword">if</span> (next_op != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">                in_degree[next_op]--;</span><br><span class="line">                <span class="keyword">if</span> (in_degree[next_op] == <span class="number">0</span>) &#123;</span><br><span class="line">                    zero_in_degree_queue.<span class="built_in">push</span>(next_op);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 检查是否存在环</span></span><br><span class="line">    <span class="keyword">if</span> (topo_operators_.<span class="built_in">size</span>() != operators_.<span class="built_in">size</span>()) &#123;</span><br><span class="line">        <span class="keyword">throw</span> std::<span class="built_in">runtime_error</span>(<span class="string">&quot;Graph has a cycle&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="course5"><a href="#course5" class="headerlink" title="course5"></a>course5</h3><ol>
<li>Sigmoid Layer</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// sigmoid.hpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> KUIPER_INFER_SOURCE_LAYER_BINOCULAR_SIGMOID_HPP_</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> KUIPER_INFER_SOURCE_LAYER_BINOCULAR_SIGMOID_HPP_</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;layer/abstract/non_param_layer.hpp&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> kuiper_infer &#123;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SigmoidLayer</span> : <span class="keyword">public</span> NonParamLayer &#123;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">SigmoidLayer</span>() : <span class="built_in">NonParamLayer</span>(<span class="string">&quot;Sigmoid&quot;</span>) &#123;&#125;</span><br><span class="line">        <span class="function">InferStatus <span class="title">Forward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">            <span class="type">const</span> std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt;&amp; inputs,</span></span></span><br><span class="line"><span class="params"><span class="function">            std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt;&amp; outputs)</span> <span class="keyword">override</span></span>;</span><br><span class="line">        <span class="function"><span class="type">static</span> ParseParameterAttrStatus <span class="title">GetInstance</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">            <span class="type">const</span> std::shared_ptr&lt;RuntimeOperator&gt;&amp; op,</span></span></span><br><span class="line"><span class="params"><span class="function">            std::shared_ptr&lt;Layer&gt;&amp; sigmoid_layer)</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line">&#125; <span class="comment">// namespace kuiper_infer</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span>  <span class="comment">// KUIPER_INFER_SOURCE_LAYER_BINOCULAR_SIGMOID_HPP_</span></span></span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// sigmoid.cpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;sigmoid.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;layer/abstract/layer_factory.hpp&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> kuiper_infer &#123;</span><br><span class="line"><span class="function">InferStatus <span class="title">SigmoidLayer::Forward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">   <span class="type">const</span> std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt; &amp;inputs,</span></span></span><br><span class="line"><span class="params"><span class="function">   std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt; &amp;outputs)</span> </span>&#123; </span><br><span class="line">  <span class="keyword">if</span> (inputs.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">    <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;The input tensor array in the relu layer is empty&quot;</span>;</span><br><span class="line">    <span class="keyword">return</span> InferStatus::kInferFailedInputEmpty;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (inputs.<span class="built_in">size</span>() != outputs.<span class="built_in">size</span>()) &#123;</span><br><span class="line">    <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;The input and output tensor array size of the relu layer do &quot;</span></span><br><span class="line">                  <span class="string">&quot;not match&quot;</span>;</span><br><span class="line">    <span class="keyword">return</span> InferStatus::kInferFailedInputOutSizeMatchError;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> batch_size = inputs.<span class="built_in">size</span>();</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; batch_size; ++i) &#123;</span><br><span class="line">    <span class="type">const</span> sftensor &amp;input_data = inputs.<span class="built_in">at</span>(i);</span><br><span class="line">    <span class="type">const</span> sftensor &amp;output_data = outputs.<span class="built_in">at</span>(i);</span><br><span class="line">    <span class="keyword">if</span> (input_data == <span class="literal">nullptr</span> || input_data-&gt;<span class="built_in">empty</span>()) &#123;</span><br><span class="line">      <span class="built_in">LOG</span>(ERROR)</span><br><span class="line">          &lt;&lt; <span class="string">&quot;The input tensor array in the relu layer has an empty tensor &quot;</span></span><br><span class="line">          &lt;&lt; i &lt;&lt; <span class="string">&quot; th&quot;</span>;</span><br><span class="line">      <span class="keyword">return</span> InferStatus::kInferFailedInputEmpty;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (output_data != <span class="literal">nullptr</span> &amp;&amp; !output_data-&gt;<span class="built_in">empty</span>()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (input_data-&gt;<span class="built_in">shapes</span>() != output_data-&gt;<span class="built_in">shapes</span>()) &#123;</span><br><span class="line">        <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;The input and output tensor shapes of the relu &quot;</span></span><br><span class="line">                      <span class="string">&quot;layer do not match &quot;</span></span><br><span class="line">                   &lt;&lt; i &lt;&lt; <span class="string">&quot; th&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> InferStatus::kInferFailedInputOutSizeMatchError;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; batch_size; ++i) &#123;</span><br><span class="line">    <span class="type">const</span> std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt; &amp;input = inputs.<span class="built_in">at</span>(i);</span><br><span class="line">    <span class="built_in">CHECK</span>(input == <span class="literal">nullptr</span> || !input-&gt;<span class="built_in">empty</span>())</span><br><span class="line">            &lt;&lt; <span class="string">&quot;The input tensor array in the relu layer has an empty tensor &quot;</span> &lt;&lt; i</span><br><span class="line">            &lt;&lt; <span class="string">&quot; th&quot;</span>;</span><br><span class="line"></span><br><span class="line">    std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt; output = outputs.<span class="built_in">at</span>(i);</span><br><span class="line">    <span class="keyword">if</span> (output == <span class="literal">nullptr</span> || output-&gt;<span class="built_in">empty</span>()) &#123;</span><br><span class="line">      <span class="built_in">DLOG</span>(ERROR)</span><br><span class="line">          &lt;&lt; <span class="string">&quot;The output tensor array in the relu layer has an empty tensor &quot;</span></span><br><span class="line">          &lt;&lt; i &lt;&lt; <span class="string">&quot; th&quot;</span>;</span><br><span class="line">      output = std::make_shared&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;(input-&gt;<span class="built_in">shapes</span>());</span><br><span class="line">      outputs.<span class="built_in">at</span>(i) = output;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">CHECK</span>(output-&gt;<span class="built_in">shapes</span>() == input-&gt;<span class="built_in">shapes</span>())</span><br><span class="line">            &lt;&lt; <span class="string">&quot;The input and output tensor shapes of the relu layer do not match &quot;</span></span><br><span class="line">            &lt;&lt; i &lt;&lt; <span class="string">&quot; th&quot;</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">uint32_t</span> j = <span class="number">0</span>; j &lt; input-&gt;<span class="built_in">size</span>(); ++j) &#123;</span><br><span class="line">      <span class="type">float</span> value = input-&gt;<span class="built_in">index</span>(j);</span><br><span class="line">      output-&gt;<span class="built_in">index</span>(j) = <span class="number">1.f</span> / (<span class="number">1.f</span> + <span class="built_in">expf</span>(-value));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> InferStatus::kInferSuccess;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">ParseParameterAttrStatus <span class="title">SigmoidLayer::GetInstance</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::shared_ptr&lt;RuntimeOperator&gt; &amp;op,</span></span></span><br><span class="line"><span class="params"><span class="function">    std::shared_ptr&lt;Layer&gt; &amp;sigmoid_layer)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">CHECK</span>(op != <span class="literal">nullptr</span>) &lt;&lt; <span class="string">&quot;Sigmod layer op is nullptr&quot;</span>;</span><br><span class="line">  sigmoid_layer = std::<span class="built_in">make_shared</span>&lt;SigmoidLayer&gt;();</span><br><span class="line">  <span class="keyword">return</span> ParseParameterAttrStatus::kParameterAttrParseSuccess;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">LayerRegistererWrapper <span class="title">kSigmoidGetInstance</span><span class="params">(<span class="string">&quot;nn.Sigmoid&quot;</span>, SigmoidLayer::GetInstance)</span></span>;</span><br><span class="line">&#125;  <span class="comment">// namespace kuiper_infer</span></span><br></pre></td></tr></table></figure>

<h3 id="course6"><a href="#course6" class="headerlink" title="course6"></a>course6</h3><ol>
<li>create_layer_group_convforward</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// test_conv.cpp</span></span><br><span class="line"><span class="built_in">TEST</span>(test_registry, create_layer_group_convforward) &#123;</span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> batch_size = <span class="number">1</span>;</span><br><span class="line">  <span class="function">std::vector&lt;sftensor&gt; <span class="title">inputs</span><span class="params">(batch_size)</span></span>;</span><br><span class="line">  <span class="function">std::vector&lt;sftensor&gt; <span class="title">outputs</span><span class="params">(batch_size)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> in_channel = <span class="number">2</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; batch_size; ++i) &#123;</span><br><span class="line">    sftensor input = std::<span class="built_in">make_shared</span>&lt;ftensor&gt;(in_channel, <span class="number">4</span>, <span class="number">4</span>);</span><br><span class="line">    input-&gt;<span class="built_in">data</span>().<span class="built_in">slice</span>(<span class="number">0</span>) = <span class="string">&quot;1,2,3,4;&quot;</span></span><br><span class="line">                             <span class="string">&quot;5,6,7,8;&quot;</span></span><br><span class="line">                             <span class="string">&quot;9,10,11,12;&quot;</span></span><br><span class="line">                             <span class="string">&quot;13,14,15,16;&quot;</span>;</span><br><span class="line"></span><br><span class="line">    input-&gt;<span class="built_in">data</span>().<span class="built_in">slice</span>(<span class="number">1</span>) = <span class="string">&quot;1,2,3,4;&quot;</span></span><br><span class="line">                             <span class="string">&quot;5,6,7,8;&quot;</span></span><br><span class="line">                             <span class="string">&quot;9,10,11,12;&quot;</span></span><br><span class="line">                             <span class="string">&quot;13,14,15,16;&quot;</span>;</span><br><span class="line">    inputs.<span class="built_in">at</span>(i) = input;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> kernel_h = <span class="number">3</span>;</span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> kernel_w = <span class="number">3</span>;</span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> stride_h = <span class="number">1</span>;</span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> stride_w = <span class="number">1</span>;</span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> kernel_count = <span class="number">2</span>;</span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> group = <span class="number">2</span>;</span><br><span class="line">  std::vector&lt;sftensor&gt; weights;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; kernel_count; ++i) &#123;</span><br><span class="line">    sftensor kernel = std::<span class="built_in">make_shared</span>&lt;ftensor&gt;(in_channel / group, kernel_h, kernel_w);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">uint32_t</span> j = <span class="number">0</span>; j &lt; (in_channel / group); ++j) &#123;</span><br><span class="line">      kernel-&gt;<span class="built_in">data</span>().<span class="built_in">slice</span>(j) = arma::<span class="built_in">fmat</span>(<span class="string">&quot;1,2,3;&quot;</span></span><br><span class="line">                                           <span class="string">&quot;3,2,1;&quot;</span></span><br><span class="line">                                           <span class="string">&quot;1,2,3;&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    weights.<span class="built_in">push_back</span>(kernel);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function">ConvolutionLayer <span class="title">conv_layer</span><span class="params">(kernel_count, in_channel, kernel_h, kernel_w, <span class="number">0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                              <span class="number">0</span>, stride_h, stride_w, group, <span class="literal">false</span>)</span></span>;</span><br><span class="line">  conv_layer.<span class="built_in">set_weights</span>(weights);</span><br><span class="line">  conv_layer.<span class="built_in">Forward</span>(inputs, outputs);</span><br><span class="line">  outputs.<span class="built_in">at</span>(<span class="number">0</span>)-&gt;<span class="built_in">Show</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="course7"><a href="#course7" class="headerlink" title="course7"></a>course7</h3><ol>
<li>词法和语法解析中支持sin(三角函数)操作</li>
<li>如果操作符是单输入数，例如问题1中的sin函数，的<code>Forward</code>函数应该做出什么改动能获得正确的计算结果。</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// tensor_utils.hpp</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * sin(@num)</span></span><br><span class="line"><span class="comment"> * @param tensor 输入张量</span></span><br><span class="line"><span class="comment"> * @return 张量 sin 的结果</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt; <span class="built_in">TensorElementSin</span>(</span><br><span class="line">    <span class="type">const</span> std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&amp; tensor);</span><br><span class="line"></span><br><span class="line"><span class="comment">// tensor_utils.cpp</span></span><br><span class="line">std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt; <span class="built_in">TensorElementSin</span>(</span><br><span class="line">            <span class="type">const</span> std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&amp; tensor) &#123;</span><br><span class="line">    <span class="built_in">CHECK</span>(tensor != <span class="literal">nullptr</span>);</span><br><span class="line"></span><br><span class="line">    sftensor output_tensor = <span class="built_in">TensorCreate</span>(tensor-&gt;<span class="built_in">shapes</span>());</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span>&amp; input_data = tensor-&gt;<span class="built_in">data</span>();</span><br><span class="line">    <span class="keyword">auto</span>&amp; output_data = output_tensor-&gt;<span class="built_in">data</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; input_data.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">        output_data[i] = std::<span class="built_in">sin</span>(input_data[i]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output_tensor;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// parse_expression.cpp</span></span><br><span class="line"><span class="function">std::shared_ptr&lt;TokenNode&gt; <span class="title">ExpressionParser::Generate_</span><span class="params">(<span class="type">int32_t</span> &amp;index)</span> </span>&#123; <span class="comment">// recursive generate</span></span><br><span class="line">  <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>());</span><br><span class="line">  <span class="type">const</span> <span class="keyword">auto</span> current_token = <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index);</span><br><span class="line">  <span class="built_in">CHECK</span>(current_token.token_type == TokenType::TokenInputNumber ||</span><br><span class="line">      current_token.token_type == TokenType::TokenAdd ||</span><br><span class="line">      current_token.token_type == TokenType::TokenMul ||</span><br><span class="line">      current_token.token_type == TokenType::TokenSin);</span><br><span class="line">  <span class="keyword">if</span> (current_token.token_type == TokenType::TokenInputNumber) &#123;</span><br><span class="line">    <span class="type">uint32_t</span> start_pos = current_token.start_pos + <span class="number">1</span>;</span><br><span class="line">    <span class="type">uint32_t</span> end_pos = current_token.end_pos;</span><br><span class="line">    <span class="built_in">CHECK</span>(end_pos &gt; start_pos || end_pos &lt;= <span class="keyword">this</span>-&gt;statement_.<span class="built_in">length</span>())</span><br><span class="line">            &lt;&lt; <span class="string">&quot;Current token has a wrong length&quot;</span>;</span><br><span class="line">    <span class="type">const</span> std::string &amp;str_number =</span><br><span class="line">        std::<span class="built_in">string</span>(<span class="keyword">this</span>-&gt;statement_.<span class="built_in">begin</span>() + start_pos,</span><br><span class="line">                    <span class="keyword">this</span>-&gt;statement_.<span class="built_in">begin</span>() + end_pos);</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">make_shared</span>&lt;TokenNode&gt;(std::<span class="built_in">stoi</span>(str_number), <span class="literal">nullptr</span>, <span class="literal">nullptr</span>);</span><br><span class="line"></span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (current_token.token_type == TokenType::TokenMul ||</span><br><span class="line">      current_token.token_type == TokenType::TokenAdd) &#123;</span><br><span class="line">    std::shared_ptr&lt;TokenNode&gt; current_node = std::<span class="built_in">make_shared</span>&lt;TokenNode&gt;();</span><br><span class="line">    current_node-&gt;num_index = <span class="built_in">int</span>(current_token.token_type);</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>()) &lt;&lt; <span class="string">&quot;Missing left bracket!&quot;</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index).token_type == TokenType::TokenLeftBracket);</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>()) &lt;&lt; <span class="string">&quot;Missing correspond left token!&quot;</span>;</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> left_token = <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (left_token.token_type == TokenType::TokenInputNumber ||</span><br><span class="line">        left_token.token_type == TokenType::TokenAdd ||</span><br><span class="line">        left_token.token_type == TokenType::TokenMul ||</span><br><span class="line">        left_token.token_type == TokenType::TokenSin) &#123;</span><br><span class="line">      current_node-&gt;left = <span class="built_in">Generate_</span>(index);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown token type: &quot;</span> &lt;&lt; <span class="built_in">int</span>(left_token.token_type);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>()) &lt;&lt; <span class="string">&quot;Missing comma!&quot;</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index).token_type == TokenType::TokenComma);</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>()) &lt;&lt; <span class="string">&quot;Missing correspond right token!&quot;</span>;</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> right_token = <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index);</span><br><span class="line">    <span class="keyword">if</span> (right_token.token_type == TokenType::TokenInputNumber ||</span><br><span class="line">        right_token.token_type == TokenType::TokenAdd ||</span><br><span class="line">        right_token.token_type == TokenType::TokenMul ||</span><br><span class="line">        right_token.token_type == TokenType::TokenSin) &#123;</span><br><span class="line">      current_node-&gt;right = <span class="built_in">Generate_</span>(index);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown token type: &quot;</span> &lt;&lt; <span class="built_in">int</span>(right_token.token_type);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>()) &lt;&lt; <span class="string">&quot;Missing right bracket!&quot;</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index).token_type == TokenType::TokenRightBracket);</span><br><span class="line">    <span class="keyword">return</span> current_node;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (current_token.token_type == TokenType::TokenSin)&#123;</span><br><span class="line">    std::shared_ptr&lt;TokenNode&gt; current_node = std::<span class="built_in">make_shared</span>&lt;TokenNode&gt;();</span><br><span class="line">    current_node-&gt;num_index = <span class="built_in">int</span>(current_token.token_type);</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>()) &lt;&lt; <span class="string">&quot;Missing left bracket!&quot;</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index).token_type == TokenType::TokenLeftBracket);</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> cur_token = <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index);</span><br><span class="line">    <span class="keyword">if</span> (cur_token.token_type == TokenType::TokenInputNumber ||</span><br><span class="line">        cur_token.token_type == TokenType::TokenAdd ||</span><br><span class="line">        cur_token.token_type == TokenType::TokenMul ||</span><br><span class="line">        cur_token.token_type == TokenType::TokenSin) &#123;</span><br><span class="line">      current_node-&gt;left = <span class="built_in">Generate_</span>(index);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown token type: &quot;</span> &lt;&lt; <span class="built_in">int</span>(cur_token.token_type);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    index += <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(index &lt; <span class="keyword">this</span>-&gt;tokens_.<span class="built_in">size</span>()) &lt;&lt; <span class="string">&quot;Missing right bracket!&quot;</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="keyword">this</span>-&gt;tokens_.<span class="built_in">at</span>(index).token_type == TokenType::TokenRightBracket);</span><br><span class="line">    <span class="keyword">return</span> current_node;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown token type: &quot;</span> &lt;&lt; <span class="built_in">int</span>(current_token.token_type);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// expression.cpp</span></span><br><span class="line"><span class="function">InferStatus <span class="title">ExpressionLayer::Forward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt;&amp; inputs,</span></span></span><br><span class="line"><span class="params"><span class="function">    std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt;&amp; outputs)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (inputs.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">    <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;The input tensor array in the expression layer is empty&quot;</span>;</span><br><span class="line">    <span class="keyword">return</span> InferStatus::kInferFailedInputEmpty;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (outputs.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">    <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;The output tensor array in the expression layer is empty&quot;</span>;</span><br><span class="line">    <span class="keyword">return</span> InferStatus::kInferFailedOutputEmpty;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="keyword">this</span>-&gt;parser_ != <span class="literal">nullptr</span>)</span><br><span class="line">      &lt;&lt; <span class="string">&quot;The parser in the expression layer is null!&quot;</span>;</span><br><span class="line">  <span class="keyword">this</span>-&gt;parser_-&gt;<span class="built_in">Tokenizer</span>(<span class="literal">false</span>);</span><br><span class="line">  <span class="type">const</span> <span class="keyword">auto</span>&amp; expressions = <span class="keyword">this</span>-&gt;parser_-&gt;<span class="built_in">tokens</span>();</span><br><span class="line">  <span class="built_in">CHECK</span>(!expressions.<span class="built_in">empty</span>())</span><br><span class="line">      &lt;&lt; <span class="string">&quot;The expression parser failed to parse &quot;</span> &lt;&lt; statement_;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; inputs.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">    <span class="type">const</span> sftensor&amp; input_data = inputs.<span class="built_in">at</span>(i);</span><br><span class="line">    <span class="keyword">if</span> (input_data == <span class="literal">nullptr</span> || input_data-&gt;<span class="built_in">empty</span>()) &#123;</span><br><span class="line">      <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;The input tensor array in the expression layer has an &quot;</span></span><br><span class="line">                    <span class="string">&quot;empty tensor &quot;</span></span><br><span class="line">                 &lt;&lt; i &lt;&lt; <span class="string">&quot;th&quot;</span>;</span><br><span class="line">      <span class="keyword">return</span> InferStatus::kInferFailedInputEmpty;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> batch_size = outputs.<span class="built_in">size</span>();</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; batch_size; ++i) &#123;</span><br><span class="line">    <span class="keyword">if</span> (outputs.<span class="built_in">at</span>(i) == <span class="literal">nullptr</span> || outputs.<span class="built_in">at</span>(i)-&gt;<span class="built_in">empty</span>()) &#123;</span><br><span class="line">      <span class="built_in">DLOG</span>(ERROR) &lt;&lt; <span class="string">&quot;The output tensor array in the expression layer has an &quot;</span></span><br><span class="line">                     <span class="string">&quot;empty tensor &quot;</span></span><br><span class="line">                  &lt;&lt; i &lt;&lt; <span class="string">&quot;th&quot;</span>;</span><br><span class="line">      <span class="keyword">return</span> InferStatus::kInferFailedOutputEmpty;</span><br><span class="line">    &#125;</span><br><span class="line">    outputs.<span class="built_in">at</span>(i)-&gt;<span class="built_in">Fill</span>(<span class="number">0.f</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  std::stack&lt;std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt;&gt; op_stack;</span><br><span class="line">  <span class="type">const</span> std::vector&lt;std::shared_ptr&lt;TokenNode&gt;&gt;&amp; token_nodes =</span><br><span class="line">      <span class="keyword">this</span>-&gt;parser_-&gt;<span class="built_in">Generate</span>();</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; token_node : token_nodes) &#123;</span><br><span class="line">    <span class="keyword">if</span> (token_node-&gt;num_index &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// process operator</span></span><br><span class="line">      <span class="type">uint32_t</span> start_pos = token_node-&gt;num_index * batch_size;</span><br><span class="line">      std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt; input_token_nodes;</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; batch_size; ++i) &#123;</span><br><span class="line">        <span class="built_in">CHECK</span>(i + start_pos &lt; inputs.<span class="built_in">size</span>())</span><br><span class="line">            &lt;&lt; <span class="string">&quot;The &quot;</span> &lt;&lt; i</span><br><span class="line">            &lt;&lt; <span class="string">&quot;th operand doesn&#x27;t have appropriate number of tensors&quot;</span>;</span><br><span class="line">        <span class="comment">// fixme 这里的张量拷贝是否有必要</span></span><br><span class="line">        input_token_nodes.<span class="built_in">push_back</span>(inputs.<span class="built_in">at</span>(i + start_pos));</span><br><span class="line">      &#125;</span><br><span class="line">      op_stack.<span class="built_in">push</span>(input_token_nodes);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// process operation</span></span><br><span class="line">      <span class="type">const</span> <span class="type">int32_t</span> op = token_node-&gt;num_index;</span><br><span class="line">      <span class="keyword">if</span> (op != <span class="built_in">int</span>(TokenType::TokenAdd) &amp;&amp; op != <span class="built_in">int</span>(TokenType::TokenMul) &amp;&amp; op != <span class="built_in">int</span>(TokenType::TokenSin)) &#123;</span><br><span class="line">        <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown operator type: &quot;</span> &lt;&lt; op;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (op == <span class="built_in">int</span>(TokenType::TokenSin)) &#123;</span><br><span class="line">          <span class="built_in">CHECK</span>(op_stack.<span class="built_in">size</span>() &gt;= <span class="number">1</span>) &lt;&lt; <span class="string">&quot;The number of operand is less than one for sin operation&quot;</span>;</span><br><span class="line">          std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt; input_node = op_stack.<span class="built_in">top</span>();</span><br><span class="line">          <span class="built_in">CHECK</span>(input_node.<span class="built_in">size</span>() == batch_size)</span><br><span class="line">                          &lt;&lt; <span class="string">&quot;The operand doesn&#x27;t have appropriate number of tensors, &quot;</span></span><br><span class="line">                             <span class="string">&quot;which need &quot;</span></span><br><span class="line">                          &lt;&lt; batch_size;</span><br><span class="line">          op_stack.<span class="built_in">pop</span>();</span><br><span class="line">          std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt; <span class="built_in">output_token_nodes</span>(batch_size);</span><br><span class="line">          <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; batch_size; ++i) &#123;</span><br><span class="line">              <span class="comment">// do execution</span></span><br><span class="line">              output_token_nodes.<span class="built_in">at</span>(i) = <span class="built_in">TensorElementSin</span>(input_node.<span class="built_in">at</span>(i)); <span class="comment">// Modified</span></span><br><span class="line">          &#125;</span><br><span class="line">          op_stack.<span class="built_in">push</span>(output_token_nodes);</span><br><span class="line">          <span class="keyword">continue</span>; <span class="comment">/// 跳过循环的其余部分进行sin操作</span></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">CHECK</span>(op_stack.<span class="built_in">size</span>() &gt;= <span class="number">2</span>) &lt;&lt; <span class="string">&quot;The number of operand is less than two&quot;</span>;</span><br><span class="line">        std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt; input_node1 = op_stack.<span class="built_in">top</span>();</span><br><span class="line"></span><br><span class="line">        <span class="built_in">CHECK</span>(input_node1.<span class="built_in">size</span>() == batch_size)</span><br><span class="line">            &lt;&lt; <span class="string">&quot;The first operand doesn&#x27;t have appropriate number of tensors, &quot;</span></span><br><span class="line">              <span class="string">&quot;which need &quot;</span></span><br><span class="line">            &lt;&lt; batch_size;</span><br><span class="line">        op_stack.<span class="built_in">pop</span>();</span><br><span class="line"></span><br><span class="line">        std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt; input_node2 = op_stack.<span class="built_in">top</span>();</span><br><span class="line">        <span class="built_in">CHECK</span>(input_node2.<span class="built_in">size</span>() == batch_size)</span><br><span class="line">            &lt;&lt; <span class="string">&quot;The second operand doesn&#x27;t have appropriate number of tensors, &quot;</span></span><br><span class="line">              <span class="string">&quot;which need &quot;</span></span><br><span class="line">            &lt;&lt; batch_size;</span><br><span class="line">        op_stack.<span class="built_in">pop</span>();</span><br><span class="line"></span><br><span class="line">        std::vector&lt;std::shared_ptr&lt;Tensor&lt;<span class="type">float</span>&gt;&gt;&gt; <span class="built_in">output_token_nodes</span>(</span><br><span class="line">            batch_size);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; batch_size; ++i) &#123;</span><br><span class="line">          <span class="comment">// do execution</span></span><br><span class="line">          <span class="keyword">if</span> (op == <span class="built_in">int</span>(TokenType::TokenAdd)) &#123;</span><br><span class="line">            output_token_nodes.<span class="built_in">at</span>(i) =</span><br><span class="line">                <span class="built_in">TensorElementAdd</span>(input_node1.<span class="built_in">at</span>(i), input_node2.<span class="built_in">at</span>(i));</span><br><span class="line">          &#125; <span class="keyword">else</span> <span class="keyword">if</span> (op == <span class="built_in">int</span>(TokenType::TokenMul)) &#123;</span><br><span class="line">            output_token_nodes.<span class="built_in">at</span>(i) =</span><br><span class="line">                <span class="built_in">TensorElementMultiply</span>(input_node1.<span class="built_in">at</span>(i), input_node2.<span class="built_in">at</span>(i));</span><br><span class="line">          &#125; <span class="keyword">else</span> <span class="keyword">if</span> (op == <span class="built_in">int</span>(TokenType::TokenSin)) &#123;</span><br><span class="line">            output_token_nodes.<span class="built_in">at</span>(i) =</span><br><span class="line">                <span class="built_in">TensorElementSin</span>(input_node1.<span class="built_in">at</span>(i));</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown operator type: &quot;</span> &lt;&lt; op;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        op_stack.<span class="built_in">push</span>(output_token_nodes);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">CHECK</span>(op_stack.<span class="built_in">size</span>() == <span class="number">1</span>)</span><br><span class="line">      &lt;&lt; <span class="string">&quot;The expression has more than one output operand!&quot;</span>;</span><br><span class="line">  std::vector&lt;sftensor&gt; output_node = op_stack.<span class="built_in">top</span>();</span><br><span class="line">  op_stack.<span class="built_in">pop</span>();</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; batch_size; ++i) &#123;</span><br><span class="line">    <span class="built_in">CHECK</span>(outputs.<span class="built_in">at</span>(i) != <span class="literal">nullptr</span> &amp;&amp; !outputs.<span class="built_in">at</span>(i)-&gt;<span class="built_in">empty</span>());</span><br><span class="line">    <span class="built_in">CHECK</span>(outputs.<span class="built_in">at</span>(i)-&gt;<span class="built_in">shapes</span>() == output_node.<span class="built_in">at</span>(i)-&gt;<span class="built_in">shapes</span>());</span><br><span class="line">    outputs.<span class="built_in">at</span>(i) = output_node.<span class="built_in">at</span>(i);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> InferStatus::kInferSuccess;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://kyrie2to11.github.io/2024/12/16/Nano-Web-Server/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="jarvis">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jarvis's Blog">
      <meta itemprop="description" content="记录学习和生活，留下时光的痕迹">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Jarvis's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/12/16/Nano-Web-Server/" class="post-title-link" itemprop="url">Nano Web Server</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-12-16 11:09:06" itemprop="dateCreated datePublished" datetime="2024-12-16T11:09:06+08:00">2024-12-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-24 23:49:36" itemprop="dateModified" datetime="2024-12-24T23:49:36+08:00">2024-12-24</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><h3 id="服务器框架"><a href="#服务器框架" class="headerlink" title="服务器框架"></a>服务器框架</h3><img src="/2024/12/16/Nano-Web-Server/basic_frame.png" class="" title="basic frame">
<p>服务器基本框架：I&#x2F;O 单元 + 逻辑单元 + 网络存储单元 （各个单元间通信方式：请求队列）</p>
<h3 id="四种-I-x2F-O-模型"><a href="#四种-I-x2F-O-模型" class="headerlink" title="四种 I&#x2F;O 模型"></a>四种 I&#x2F;O 模型</h3><img src="/2024/12/16/Nano-Web-Server/IO_compare.png" class="" title="I&#x2F;O model">
<p>基础概念：</p>
<ol>
<li>同步 I&#x2F;O：用户代码自行执行 I&#x2F;O 操作（数据从内核缓冲区读入用户缓冲区或从用户缓冲区写入内核缓冲区），<strong>同步 I&#x2F;O 内核向应用程序通知的是就绪事件</strong></li>
<li>异步 I&#x2F;O: 数据在内核缓冲区和用户缓冲区之间的移动是由内核在“后台”完成的，<strong>异步 I&#x2F;O 内核向应用程序通知的是完成事件</strong></li>
<li>阻塞 I&#x2F;O：阻塞的文件描述符，针对阻塞 I&#x2F;O 执行的系统调用可能因为无法立即完成而被操作系统挂起，直到等待的事件发生为止</li>
<li>非阻塞 I&#x2F;O：非阻塞的文件描述符，针对非阻塞 I&#x2F;O 执行的系统调用总是立即返回，而不管事件是否已经发生</li>
</ol>
<h3 id="两种事件处理模式"><a href="#两种事件处理模式" class="headerlink" title="两种事件处理模式"></a>两种事件处理模式</h3><p>服务器程序通常需要处理三类事件： I&#x2F;O 事件、信号及定时事件</p>
<ol>
<li><p><strong>reactor 模式</strong>：主线程(I&#x2F;O处理单元)只负责监听文件描述符上是否有事件发生，有的话立即通知工作线程(逻辑单元)，读写数据、接受新连接及处理客户请求均在工作线程中完成。通常由<strong>同步 I&#x2F;O</strong>实现。</p>
<img src="/2024/12/16/Nano-Web-Server/reactor.png" class="" title="reactor">
</li>
<li><p><strong>proactor模式</strong>：主线程和内核负责处理读写数据、接受新连接等I&#x2F;O操作，工作线程仅负责业务逻辑，如处理客户请求。通常由<strong>异步 I&#x2F;O</strong>实现。</p>
<img src="/2024/12/16/Nano-Web-Server/proactor.png" class="" title="reactor"></li>
</ol>
<h3 id="两种并发模式"><a href="#两种并发模式" class="headerlink" title="两种并发模式"></a>两种并发模式</h3><ol>
<li>半同步&#x2F;半异步模式<ol>
<li>并发模式中的同步和异步：同步指的是程序完全按照代码序列的顺序执行，异步指的是程序的执行需要由系统事件驱动</li>
<li>I&#x2F;O 模型中的同步和异步区分的是内核向应用程序通知的是何种 I&#x2F;O 事件（就绪事件 or 完成事件），以及由谁完成 I&#x2F;O 读写（应用程序 or 内核）</li>
<li>半同步&#x2F;半异步模式中，同步线程用于处理客户逻辑，异步线程用于处理 I&#x2F;O 事件</li>
<li>服务器程序中，综合考虑两种事件处理模式和几种 I&#x2F;O 模型，则半同步&#x2F;半异步模式存在多种变体。其中有一种变体称为半同步&#x2F;半反应堆模式：异步线程只有一个，由主线程充当。同步线程（工作线程）处理客户逻辑。工作模式是 Reactor 模式<img src="/2024/12/16/Nano-Web-Server/half_sync_half_reactive.png" class="" title="half-sync&#x2F;half-reactor"></li>
</ol>
</li>
<li>领导者&#x2F;追随者模式</li>
</ol>
<h2 id="项目特性"><a href="#项目特性" class="headerlink" title="项目特性"></a>项目特性</h2><ol>
<li>利用 epoll 与线程池实现 Reactor 高并发模型</li>
<li>利用状态机与正则实现 HTTP 请求报文解析和 HTTP 响应生成，可处理 GET 和 POST 请求</li>
<li>用 vector 容器封装 char,实现一个可自动扩容的缓冲区</li>
<li>基于 epoll_wait 实现定时功能，关闭超时的非活动连接，并用小根堆作为容器管理定时器</li>
<li>利用单例模式实现了一个简单的线程池，减少了线程创建与销毁的开销</li>
<li>利用单例模式实现 MySQL 数据库连接池，减少数据库连接建立与关闭的开销，实现了用户注册登录功能</li>
<li>利用单例模式与阻塞队列实现异步日志系统，记录服务器运行状态</li>
<li>能够处理前端发送的<code>multi/form-data</code>类型的 POST 请求，实现了文件上传功能</li>
<li>通过 jsoncpp 生成 json 数据，向前端发送文件列表，实现文件展示与下载</li>
</ol>
<h2 id="Workflow"><a href="#Workflow" class="headerlink" title="Workflow"></a>Workflow</h2><ol>
<li><p>git push</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加子模块</span></span><br><span class="line">git submodule add https://github.com/open-source-parsers/jsoncpp.git jsoncpp</span><br><span class="line"></span><br><span class="line">git add .</span><br><span class="line">git commit -m <span class="string">&quot;message&quot;</span></span><br><span class="line">git push origin main</span><br></pre></td></tr></table></figure>
</li>
<li><p>git clone &amp; install</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/kyrie2to11/NanoServer.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 jsoncpp</span></span><br><span class="line">git submodule update --init --recursive</span><br><span class="line"><span class="built_in">cd</span> jsoncpp</span><br><span class="line">cmake -S . -B build</span><br><span class="line"><span class="built_in">cd</span> build &amp;&amp; make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br><span class="line"><span class="comment"># jsoncpp</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="variable">$LD_LIBRARY_PATH</span>:/usr/local/lib</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成 NanoServer 可执行文件 </span></span><br><span class="line"><span class="built_in">cd</span> NanoServer</span><br><span class="line">make</span><br></pre></td></tr></table></figure>
</li>
<li><p>mysql config</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 报错：ERROR 2002 (HY000): Can&#x27;t connect to local MySQL server through socket &#x27;/var/run/mysqld/mysqld.sock&#x27; (2)</span></span><br><span class="line"><span class="comment"># mysql 服务重启即可</span></span><br><span class="line">service mysql restart</span><br><span class="line"></span><br><span class="line"><span class="comment"># mysql 服务关闭</span></span><br><span class="line">service mysql stop</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建数据库</span></span><br><span class="line"><span class="keyword">create</span> database webdb;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建user表</span></span><br><span class="line">USE webdb;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="keyword">user</span>(</span><br><span class="line">   username <span class="type">char</span>(<span class="number">50</span>) <span class="keyword">NULL</span>,</span><br><span class="line">   passwd <span class="type">char</span>(<span class="number">50</span>) <span class="keyword">NULL</span></span><br><span class="line">)ENGINE<span class="operator">=</span>InnoDB;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 添加数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">user</span>(username, passwd) <span class="keyword">VALUES</span>(<span class="string">&#x27;username&#x27;</span>, <span class="string">&#x27;password&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- webdb是数据库名，user是表名，需要在main函数中传入</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>start server</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tmux</span><br><span class="line"><span class="built_in">cd</span> NanoServer</span><br><span class="line">./bin/server</span><br><span class="line"></span><br><span class="line">ctrl + b + d <span class="comment"># detach session</span></span><br><span class="line">tmux attach-session -t 0 <span class="comment"># attach session</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 默认访问端口： 1316 可在 main.cpp 更改</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="Bug"><a href="#Bug" class="headerlink" title="Bug"></a>Bug</h2><ol>
<li><p>运行一段时间后 buffer 报错，暂不清楚原因</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(base) jarvis@zephyrus:~/Projects/webserver/NanoServer$ ./bin/server </span><br><span class="line">server: ../src/buffer/buffer.cpp:21: void Buffer::Retrieve(size_t): Assertion <span class="string">&#x27;len &lt;= ReadableBytes()&#x27;</span> failed.</span><br><span class="line">Aborted (core dumped)</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h2><ol>
<li>Linux高性能服务器编程，游双著</li>
<li><a target="_blank" rel="noopener" href="https://github.com/markparticle/WebServer">markparticle&#x2F;WebServer</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/Sakura1221/SimpleWebServer.git">Sakura1221&#x2F;SimpleWebServer</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/wustghj/SimpleServer.git">wustghj&#x2F;SimpleServer</a></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://kyrie2to11.github.io/2024/12/03/SQL-Pool-Project/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="jarvis">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jarvis's Blog">
      <meta itemprop="description" content="记录学习和生活，留下时光的痕迹">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Jarvis's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/12/03/SQL-Pool-Project/" class="post-title-link" itemprop="url">SQL Pool Project</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-12-03 14:49:09" itemprop="dateCreated datePublished" datetime="2024-12-03T14:49:09+08:00">2024-12-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-05 15:12:00" itemprop="dateModified" datetime="2024-12-05T15:12:00+08:00">2024-12-05</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="SQL-Pool-Project-背景"><a href="#SQL-Pool-Project-背景" class="headerlink" title="SQL Pool Project 背景"></a>SQL Pool Project 背景</h2><ul>
<li>为了提高 MySQL 数据库的访存瓶颈，在大量 SQL connection 并发的情况下，重复的<strong>TCP三次握手 -&gt; MySQL Server 连接认证 -&gt; MySQL Server 关闭连接回收资源 -&gt; TCP 四次挥手</strong>消耗大量时间，增加连接池可以减少此部分耗时</li>
</ul>
<h2 id="技术点"><a href="#技术点" class="headerlink" title="技术点"></a>技术点</h2><ol>
<li>MySQL 数据库编程</li>
<li>单例模式</li>
<li>queue 队列容器</li>
<li>c++11 多线程编程、线程互斥、线程同步通信和 unique_lock<ol>
<li>进程与线程的区别和举例<ul>
<li>资源占用<ol>
<li>进程是资源分配的基本单位。每个进程有独立的地址空间、代码段、数据段、堆和栈。如打开一个文本编辑器和浏览器，这是两个不同的进程，资源独立</li>
<li>线程是进程内的执行单元，共享所属进程的资源。如一个文本编辑器进程中，可能有一个线程负责接收用户键盘输入，另一个线程负责后台保存文档。这些线程共享文本编辑器进程的代码段、数据段等。</li>
</ol>
</li>
<li>调度开销<ol>
<li>进程切换开销大，线程切换开销较小</li>
</ol>
</li>
</ul>
</li>
<li>进程通信方式<ul>
<li>管道(Pipe): 半双工通信（同一时刻单向信息流动），用于具有亲缘关系的进程通信</li>
<li>消息队列(Message Queue): 相较管道克服了管道只能在具有亲缘关系的进程间通信的限制</li>
<li>共享内存(Shared Memory)</li>
<li>信号量(Semaphore): 相较线程通信条件变量区别在于有状态，实际上是一个计数器，可正可负，用于标识共享资源的数目或阻塞的进程数目</li>
</ul>
</li>
<li>线程通信方式<ul>
<li>互斥锁(Mutex)</li>
<li>条件变量(Condition_Variable): 无状态</li>
</ul>
</li>
<li>条件变量搭配 uniqe_lock 而不能搭配 lock_guard 原因：<ul>
<li>Condition_Variable cv.wait(mtx) 在等待信号量通知时会先把锁释放掉，unique_lock 允许灵活的释放和获取锁。而 lock_guard 是 RAII 类型的模板类，lock_guard 对象在创建时获取互斥量的锁，析构时自动释放锁，不提供手动解锁接口</li>
</ul>
</li>
</ol>
</li>
<li>基于 CAS 的原子整形: (Compare and Switch) CAS</li>
<li>智能指针 shared_ptr</li>
<li>lambda 表达式</li>
<li>生产者-消费者线程模型</li>
</ol>
<h2 id="功能点"><a href="#功能点" class="headerlink" title="功能点"></a>功能点</h2><ol>
<li>connection_pool: 单例模式</li>
<li>get_connection: 从 connection_pool 获取连接，需要处理获取连接超时的情况</li>
<li>空闲连接维护在一个线程安全的 connection_queue 中</li>
<li>如果 connection_queue 为空，需要动态创建 connection,上限 maxSize</li>
<li>connection_queue 中空闲时长超过 maxIdleTime 的需要被释放掉，只保留初始 initSize 个 connection 即可</li>
</ol>
<h2 id="压力测试"><a href="#压力测试" class="headerlink" title="压力测试"></a>压力测试</h2><hr>
<table>
<thead>
<tr>
<th>数据量</th>
<th>不用 SQL Pool</th>
<th>使用 SQL Pool</th>
</tr>
</thead>
<tbody><tr>
<td>1000</td>
<td>单线程：50768ms</td>
<td>单线程：10407.6ms 四线程：1980.9ms</td>
</tr>
<tr>
<td>5000</td>
<td>单线程：244466ms</td>
<td>单线程：21791.8ms 四线程：7504.81ms</td>
</tr>
<tr>
<td>10000</td>
<td>单线程：493808ms</td>
<td>单线程：37665.3ms 四线程：14478.5ms</td>
</tr>
</tbody></table>
<hr>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://kyrie2to11.github.io/2024/08/17/aliyun-github-blog-config/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="jarvis">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jarvis's Blog">
      <meta itemprop="description" content="记录学习和生活，留下时光的痕迹">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Jarvis's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/17/aliyun-github-blog-config/" class="post-title-link" itemprop="url">Hexo Blog Updates to Aliyun and Github Page</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-08-17 11:59:05 / 修改时间：20:19:38" itemprop="dateCreated datePublished" datetime="2024-08-17T11:59:05+08:00">2024-08-17</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="aliyun-服务器配置"><a href="#aliyun-服务器配置" class="headerlink" title="aliyun 服务器配置"></a>aliyun 服务器配置</h2><h3 id="ubuntu-系统更新"><a href="#ubuntu-系统更新" class="headerlink" title="ubuntu 系统更新"></a>ubuntu 系统更新</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt upgrade</span><br></pre></td></tr></table></figure>

<h3 id="创建新用户"><a href="#创建新用户" class="headerlink" title="创建新用户"></a>创建新用户</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">adduser jarvis <span class="comment"># jarvis 为用户名</span></span><br><span class="line"><span class="built_in">chmod</span> 740 /etc/sudoers</span><br><span class="line">vim /etc/sudoers</span><br></pre></td></tr></table></figure>

<p>找到如下 <code>root ALL=(ALL:ALL) ALL</code> 后，在其下面添加一行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jarvis ALL=(ALL:ALL) ALL</span><br></pre></td></tr></table></figure>

<h3 id="切换到新用户目录下"><a href="#切换到新用户目录下" class="headerlink" title="切换到新用户目录下"></a>切换到新用户目录下</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">su jarvis</span><br><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install vim git htop screenfetch curl wget <span class="comment"># 安装常用软件</span></span><br></pre></td></tr></table></figure>

<h3 id="配置-ssh"><a href="#配置-ssh" class="headerlink" title="配置 ssh"></a>配置 ssh</h3><p>在服务器用户目录下创建 <code>~/.ssh</code> 和 <code>authorized_keys</code> 文件，赋予权限</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> ~/.ssh</span><br><span class="line">vim ~/.ssh/authorized_keys </span><br><span class="line"><span class="built_in">chmod</span> 600 ~/.ssh/authorized_keys </span><br><span class="line"><span class="built_in">chmod</span> 700 ~/.ssh/</span><br></pre></td></tr></table></figure>

<p>然后切回本机，将 <code>~/.ssh/id_rsa.pub</code> 公钥复制到远程服务器的 <code>~/.ssh/authorized_keys</code>里面；本地测试，验证 ssh 无密码登录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -v jarvis@SERVER_IP <span class="comment"># -v 参数显示详细信息 verbose</span></span><br></pre></td></tr></table></figure>

<h3 id="配置-git"><a href="#配置-git" class="headerlink" title="配置 git"></a>配置 git</h3><p>创建工作目录 blog,初始化 Git 裸库 blog.git,创建 hook 文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line"><span class="built_in">mkdir</span> blog</span><br><span class="line"><span class="built_in">mkdir</span> repos</span><br><span class="line"><span class="built_in">cd</span> repos</span><br><span class="line">git init --bare blog.git</span><br><span class="line">vim blog.git/hooks/post-receive  <span class="comment"># 创建 hook 文件</span></span><br></pre></td></tr></table></figure>

<p>编辑 hook 内容</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#！/bin/sh</span></span><br><span class="line">git --work-tree=/home/jarvis/blog --git-dir=/home/jarvis/repos/blog.git checkout -f</span><br></pre></td></tr></table></figure>

<p>添加运行权限</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +x blog.git/hooks/post-receive</span><br></pre></td></tr></table></figure>

<h3 id="配置-nginx"><a href="#配置-nginx" class="headerlink" title="配置 nginx"></a>配置 nginx</h3><p>安装 nginx 并修改对应配置文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install</span><br><span class="line">sudo vim /etc/nginx/sites-available/default</span><br></pre></td></tr></table></figure>

<p>找到</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># include snippets/snakeoil.conf;</span></span><br><span class="line"></span><br><span class="line">root /var/www/html; </span><br></pre></td></tr></table></figure>

<p>替换为</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># include snippets/snakeoil.conf;</span></span><br><span class="line"></span><br><span class="line">root /home/jarvis/blog;</span><br></pre></td></tr></table></figure>

<p>此刻直接访问云服务器的公网 IP 会显示 nginx 欢迎界面。</p>
<h2 id="本地-hexo-config-yml-文件配置"><a href="#本地-hexo-config-yml-文件配置" class="headerlink" title="本地 hexo _config.yml 文件配置"></a>本地 hexo _config.yml 文件配置</h2><p>配置如下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Deployment</span></span><br><span class="line"><span class="comment">## Docs: https://hexo.io/docs/one-command-deployment</span></span><br><span class="line">deploy:</span><br><span class="line">    <span class="built_in">type</span>: git</span><br><span class="line">    repo: </span><br><span class="line">      github: git@github.com:kyrie2to11/kyrie2to11.github.io.git </span><br><span class="line">      aliyun: jarvis@aliyun_server_ip:/home/jarvis/blog/blog.git</span><br><span class="line">    branch: master</span><br></pre></td></tr></table></figure>

<h2 id="用-aliyun-ip-访问博客报错-404-处理"><a href="#用-aliyun-ip-访问博客报错-404-处理" class="headerlink" title="用 aliyun ip 访问博客报错 404 处理"></a>用 aliyun ip 访问博客报错 <code>404</code> 处理</h2><p>部署完毕，访问 SERVER IP 出现 404 报错, 查看 log,显示没有访问 <code>/home/jarvis/blog</code> 的权限</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vim /var/log/nginx/error.log</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出如下</span></span><br><span class="line">2024/08/17 19:44:42 [crit] 9007<span class="comment">#9007: *14 stat() &quot;/home/jarvis/blog/&quot; failed (13: Permission denied), client: 114.97.236.162, server: _, request: &quot;GET / HTTP/1.1&quot;, host: &quot;47.100.101.82&quot;</span></span><br><span class="line">2024/08/17 19:44:42 [crit] 9007<span class="comment">#9007: *14 stat() &quot;/home/jarvis/blog/&quot; failed (13: Permission denied), client: 114.97.236.162, server: _, request: &quot;GET / HTTP/1.1&quot;, host: &quot;47.100.101.82&quot;</span></span><br><span class="line">2024/08/17 19:44:43 [crit] 9007<span class="comment">#9007: *14 stat() &quot;/home/jarvis/blog/&quot; failed (13: Permission denied), client: 114.97.236.162, server: _, request: &quot;GET / HTTP/1.1&quot;, host: &quot;47.100.101.82&quot;</span></span><br><span class="line">2024/08/17 19:44:43 [crit] 9007<span class="comment">#9007: *14 stat() &quot;/home/jarvis/blog/&quot; failed (13: Permission denied), client: 114.97.236.162, server: _, request: &quot;GET / HTTP/1.1&quot;, host: &quot;47.100.101.82&quot;</span></span><br></pre></td></tr></table></figure>

<p>查看 nginx 所有进程，找到 nginx worker process 为 <code>www-data</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ps aux | grep nginx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出如下</span></span><br><span class="line">nginx: master process /usr/sbin/nginx -g daemon on; master_process on;</span><br><span class="line">www-data   12637  0.0  0.3  55992  6488 ?        S    19:51   0:00 nginx: worker process</span><br><span class="line">www-data   12638  0.0  0.3  55992  5656 ?        S    19:51   0:00 nginx: worker process</span><br><span class="line">root       13217  0.0  0.1   6612  2444 pts/5    S+   20:01   0:00 grep --color=auto nginx</span><br></pre></td></tr></table></figure>

<p>参照<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/25774999/nginx-stat-failed-13-permission-denied">如下链接</a>赋予 nginx worker process: <code>www-data</code> 访问博客路径 <code>root /home/jarvis/blog</code> 的权限</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gpasswd -a www-data jarvis</span><br><span class="line"><span class="built_in">chmod</span> g+x /home  &amp;&amp; <span class="built_in">chmod</span> g+x /home/jarvis &amp;&amp; <span class="built_in">chmod</span> g+x /home/jarvis/blog</span><br><span class="line">nginx -s reload <span class="comment"># 重启 nginx</span></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://kyrie2to11.github.io/2023/11/18/QuantLLM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="jarvis">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jarvis's Blog">
      <meta itemprop="description" content="记录学习和生活，留下时光的痕迹">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Jarvis's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/11/18/QuantLLM/" class="post-title-link" itemprop="url">QuantLLM</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-11-18 15:25:11" itemprop="dateCreated datePublished" datetime="2023-11-18T15:25:11+08:00">2023-11-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-02 15:21:10" itemprop="dateModified" datetime="2024-12-02T15:21:10+08:00">2024-12-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Quantization-of-LLM"><a href="#Quantization-of-LLM" class="headerlink" title="Quantization of LLM"></a>Quantization of LLM</h2><h3 id="LLM-Quantization-Survey"><a href="#LLM-Quantization-Survey" class="headerlink" title="LLM Quantization Survey"></a><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2308.07633">LLM Quantization Survey</a></h3><h3 id="Awesome-LLM-Quantization-Repository"><a href="#Awesome-LLM-Quantization-Repository" class="headerlink" title="Awesome LLM Quantization Repository"></a><a target="_blank" rel="noopener" href="https://github.com/HuangOwen/Awesome-LLM-Compression#quantization">Awesome LLM Quantization Repository</a></h3><h3 id="LLM-Quantization-Papers"><a href="#LLM-Quantization-Papers" class="headerlink" title="LLM Quantization Papers"></a>LLM Quantization Papers</h3><h4 id="Quantization-Aware-Training-QAT"><a href="#Quantization-Aware-Training-QAT" class="headerlink" title="Quantization-Aware Training(QAT)"></a>Quantization-Aware Training(QAT)</h4><ol>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.17888">LLM-QAT (from META)</a><ul>
<li>Motivation:<ol>
<li>Lacking training data</li>
<li>Training LLMs involves instruction tuning, reinforcement learning and etc, which are difficult to replicate during QAT</li>
</ol>
</li>
<li>Method:  <ol>
<li>Data-free quantization-aware training (QAT) which produces QAT data using next token data generation <code>-&gt;</code> Select appropriate fine-tuning dataset    <style>.fistybmurpvn{}</style></li>
<li>Per-channel weight quantization and per-token activation quantization (symmetric MinMax quantization), per-token quantization for KV cache <code>-&gt;</code> Identify suitable quantizer    <style>.lljkqduuvfkp{}</style></li>
<li>Cross-entropy based loss <code>-&gt;</code> Knowledge distillation from full precision model    <style>.swpxrptlfssz{}</style></li>
</ol>
</li>
<li>Result:<ol>
<li>Empirical recommendations:<ul>
<li>8-bit quantization should be preferred over smaller full precision models, and PTQ methods are sufficient for this case</li>
<li>4-bit models quantized using LLM-QAT should be preferred over 8-bit models of similar size <code>-&gt;</code> 4-bit LLM-QAT models towards the best efficiency-accuracy tradeoff</li>
</ul>
</li>
<li>Partial results:    <style>.nujoobuokiay{}</style></li>
</ol>
</li>
<li>Limitation:<ol>
<li>4-bit quantization does not have hardware support out-of-the-box <code>-&gt;</code> no hardware implementation</li>
<li>Method works well for 4-bit weights, 4-bit KV cache and 8-bit activations <code>-&gt;</code> Insufficient for 4-bit activation quantization</li>
</ol>
</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.14152">PEQA (from NAVER)</a><ul>
<li>Motivation:<ol>
<li>Bridging the gap between parameter-efficient fine-tuning(PEFT e.g. LoRA, Prefix Tuning) and Quantization <code>-&gt;</code> combine PEFT with quantized LLMs</li>
</ol>
</li>
<li>Method:<ol>
<li>Overall pipeline    <style>.mtosgvjhxiir{}</style></li>
<li>Solely updating quantization scales while freezing the integer quantization values of pre-trained weights  <style>.zssgtvvmmbvm{}</style></li>
</ol>
</li>
<li>Result:<ol>
<li>Memory footprint, inference latency performance  <style>.armndmsoehpu{}</style>  
  <style>.zimksjpbnmkc{}</style></li>
<li>Common-sense reasoning and in-context learning performance    <style>.vygoqrojaadh{}</style></li>
<li>Massive Multitask Language Understanding (MMLU) benchmark performance    <style>.euqzgcwdlfmf{}</style></li>
</ol>
</li>
<li>Limitation:<ol>
<li>low-bit weight-only quantization in a linear asymmetric per-channel context <code>-&gt;</code> Lacking weight-activation quantization part</li>
</ol>
</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.14314">QLoRA (from University of Washington’s UW NLP group)</a><ul>
<li>Motivation:<ol>
<li>Reduce memory footprint of parameter-efficient fine-tuning(PEFT) stage</li>
</ol>
</li>
<li>Method:<ol>
<li>Overall pipeline    <style>.mogrwscogfyi{}</style></li>
<li>QLoRA    <style>.savquwmmquky{}</style>
<ul>
<li>4-bit NormalFloat Quantization <code>-&gt;</code> better quantization data type for normally distributed data compared with 4-bit Integers and 4-bit Floats (See the paper for details)</li>
<li>Double Quantization <code>-&gt;</code> combined with NF4 to reduce the memory footprint of quantization constants i.e. weights (See the paper for details)</li>
</ul>
</li>
<li>Paged Optimizers <code>-&gt;</code> manage memory spikes i.e. manage the memory swap between CPU and GPU</li>
</ol>
</li>
<li>Result:<ol>
<li>MMLU test accuracy    <style>.pjpkirxbpbjc{}</style></li>
<li>Memory footprint <code>-&gt;</code> enables the finetuning of 33B parameter models on a single consumer GPU and 65B parameter models on a single professional GPU, even 7B parameter models on mobile phones(e.g. iPhone 12 Plus)  <style>.fgomfftirvdy{}</style></li>
</ol>
</li>
<li>Limitation:<ol>
<li>Can’t establish that QLoRA can match full 16-bit finetuning performance at 33B and 65B scales…</li>
<li>Did not evaluate different bit-precisions e.g.3-bit base models, or different adapter methods</li>
</ol>
</li>
</ul>
</li>
</ol>
<h4 id="Post-Training-Quantization-PTQ"><a href="#Post-Training-Quantization-PTQ" class="headerlink" title="Post-Training Quantization(PTQ)"></a>Post-Training Quantization(PTQ)</h4><h5 id="Weight-Quantization"><a href="#Weight-Quantization" class="headerlink" title="Weight Quantization"></a>Weight Quantization</h5><ol>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2206.09557">LUT-GEMM</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2208.07339">LLM.int8()</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2210.17323">GPTQ</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2306.00978">AWQ</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2306.02272">OWQ</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2306.03078">SpQR</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2306.07629">SqueezeLLM</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2307.13304">QuIP</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.05516">SignRound</a></li>
</ol>
<h5 id="Weight-and-Activation-Quantization"><a href="#Weight-and-Activation-Quantization" class="headerlink" title="Weight and Activation Quantization"></a>Weight and Activation Quantization</h5><ol>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2206.01861">ZeroQuant</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2211.10438">SmoothQuant</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2304.01089">RPTQ</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2304.07493">OliVe</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.08302">ZeroQuant-V2</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2304.09145">OutlierSuppression+</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.12356">MoFQ</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2307.09782">ZeroQuant-FP</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2308.15987">FPTQ</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.01885">QuantEase</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.02784">NormTweaking</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2308.13137">OmniQuant</a></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://kyrie2to11.github.io/2023/10/19/ZMO-interview/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="jarvis">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jarvis's Blog">
      <meta itemprop="description" content="记录学习和生活，留下时光的痕迹">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Jarvis's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/19/ZMO-interview/" class="post-title-link" itemprop="url">Interview</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-10-19 14:39:35" itemprop="dateCreated datePublished" datetime="2023-10-19T14:39:35+08:00">2023-10-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-02 11:53:24" itemprop="dateModified" datetime="2024-12-02T11:53:24+08:00">2024-12-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="2023-10-19-ZMO-Round-2"><a href="#2023-10-19-ZMO-Round-2" class="headerlink" title="2023.10.19 ZMO Round 2"></a>2023.10.19 ZMO Round 2</h2><h3 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h3><ol>
<li>产品 background remover&#x2F; AI designer &#x2F; text or image to image &#x2F; magic remover 这几个都是用什么模型做的</li>
<li>想了解下用卡的规模，对比下学校的集群 A40 A800</li>
<li>有无stable diffusion做移动端部署的需求和规划（参考：<a target="_blank" rel="noopener" href="https://www.qualcomm.com/news/onq/2023/02/worlds-first-on-device-demonstration-of-stable-diffusion-on-android?spm=a2c6h.12873639.article-detail.11.379f1ba9d19yg7%EF%BC%89">https://www.qualcomm.com/news/onq/2023/02/worlds-first-on-device-demonstration-of-stable-diffusion-on-android?spm=a2c6h.12873639.article-detail.11.379f1ba9d19yg7）</a></li>
<li>日常工作中模型训练以及针对实际应用场景优化这部分，对于日常工作占大头吗 还是说集中在看论文找idea这种</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://kyrie2to11.github.io/2023/10/15/Work-Log-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="jarvis">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jarvis's Blog">
      <meta itemprop="description" content="记录学习和生活，留下时光的痕迹">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Jarvis's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/15/Work-Log-1/" class="post-title-link" itemprop="url">Quantization of SR Methods Work Log</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-10-15 16:16:29" itemprop="dateCreated datePublished" datetime="2023-10-15T16:16:29+08:00">2023-10-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-02 15:23:21" itemprop="dateModified" datetime="2024-12-02T15:23:21+08:00">2024-12-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Time-2023-10-09-2023-11-10"><a href="#Time-2023-10-09-2023-11-10" class="headerlink" title="Time:2023.10.09-2023.11.10"></a>Time:2023.10.09-2023.11.10</h2><h2 id="Paper-Reading"><a href="#Paper-Reading" class="headerlink" title="Paper Reading"></a>Paper Reading</h2><ol>
<li>VRT: A Video Restoration Transformer (arXiv 2022)-&gt; <code>VRT</code><ul>
<li>feature: parallel computation + long-range dependency modelling + mutual attention for frame alignment</li>
</ul>
</li>
<li>BasicVSR++: Improving Video Super-Resolution with Enhanced Propagation and Alignment (CVPR 2022) -&gt; <code>BasicVSR++</code></li>
<li>Learning Trajectory-Aware Transformer for Video Super-Resolution (CVPR 2022) -&gt; <code>TTVSR</code></li>
<li>An Implicit Alignment for Video Super-Resolution (CVPR2023) -&gt; <code>IA-RT/IA-CNN</code></li>
<li>Rethinking Alignment in Video Super-Resolution Transformers (NIPS2022) -&gt; <code>PSRT</code></li>
<li>ResQ: Residual Quantization for Video Perception (ICCV 2023) -&gt; <code>ResQ</code><ul>
<li>motivation: residuals exhibit a significantly lower variance than the frame activations, and can be quantized with lower error.</li>
<li>verified tasks: Human Pose Estimation&#x2F;Semantic Segmentation</li>
<li>limitations:<ul>
<li>requires the propagation of representations to future timesteps, leading to a memory overhead potentially impacting latency -&gt; 对VSR任务影响小,例如BasicVSR++ 本身就是基于帧间传播的,且目前VSR对latency要求不高</li>
<li>implementing location-specific quantized operations is not trivial and requires specialized hardware or gather-scatter implementations of convolutions -&gt; 实际部署困难问题 特定区域的量化选择 涉及稀疏处理的调度问题</li>
<li>ResQ is able to reduce the amortized cost of video processing, yet the peak BOPs is not reduced</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h2><ol>
<li><p><code>BasicVSR++</code> + <code>Paddleslim</code> 量化看结果 -&gt; false</p>
</li>
<li><p>openmmlab 的 <code>mmagic</code> project 内置的 <code>BasicVSR++</code> + <code>mmrazor</code> project 进行量化 -&gt; false</p>
</li>
<li><p><code>BasicVSR++</code> + <code>Dipoorlet</code> PTQ -&gt; false: ValueError: cannot reshape array of size 3628800 into shape (0,0,3,180,320) dipoorlet可能不支持动态输入</p>
</li>
<li><p><code>BasicVSR++</code> + <code>MQBench</code> PTQ -&gt; pending</p>
<ol>
<li>使用<code>mmedit</code>构建的<code>BasicVSR++</code>在<code>symbolic traces</code>时会出现报错<code>TypeError: &#39;BasicVSR&#39; object is not subscriptable</code>, 故尝试直接通过模型的<code>archetecture</code>和<code>checkpoint</code>构建模型 -&gt; suspend (必要性不强，工作量不小~)</li>
<li>torch fx <code>if</code> symbolic trace fause: <code>torch.fx.proxy.TraceError: symbolically traced variables cannot be used as inputs to control flow</code></li>
</ol>
</li>
<li><p><code>BasicVSR++</code> + <code>PPL Quantization Tool(PPQ)</code> PTQ -&gt; inprogress</p>
</li>
<li></li>
</ol>
<h2 id="Issue-Log"><a href="#Issue-Log" class="headerlink" title="Issue Log"></a>Issue Log</h2><ol>
<li><p>command: <code>whereis</code> vs <code>which</code></p>
<ol>
<li>用途：<code>whereis</code> 用于查找可执行文件、源代码文件和帮助文档等。<br>  输出：它返回指定命令的可执行文件路径、man页面（帮助文档）路径以及源代码路径（如果可用）。<br>  限制：通常，whereis 不搜索PATH环境变量中指定的所有目录，而是搜索标准的系统目录。因此，它可能无法找到用户自定义安装的命令。</li>
<li>用途：<code>which</code>用于查找可执行命令的位置，通常用于查找命令是否在系统PATH中，并返回找到的第一个匹配的命令。<br>  输出：它会搜索PATH环境变量中指定的目录以查找命令。<br>  注意：which 仅返回第一个匹配的命令的路径，因此如果有多个同名命令，它只会返回一个。</li>
</ol>
</li>
<li><p>environment setup</p>
<ol>
<li>NvidiaDriver&#x2F;CUDA&#x2F;CUDNN installation<ul>
<li>note: 传统上，安装 NVIDIA Driver 和 CUDA Toolkit 的步骤是分开的，但实际上现在可以直接安装 CUDA Toolkit，系统将自动安装与其版本匹配的 NVIDIA Driver。</li>
</ul>
</li>
<li>Pull docker image: torch 1.13.1<ul>
<li>command: <code>docker pull cnstark/pytorch:1.13.1-py3.9.16-cuda11.7.1-ubuntu20.04</code></li>
</ul>
</li>
<li>Dipoorlet dependency:<ul>
<li>CUDA Toolkit  &#x3D;&#x3D; 11.8</li>
<li>CUDNN &#x3D;&#x3D; 8.7.0</li>
<li>onnxruntime-gpu &#x3D;&#x3D; 1.16.0</li>
<li>python &#x3D;&#x3D; 3.8.10</li>
<li>torch &#x3D;&#x3D; 2.0.0</li>
</ul>
</li>
<li>Ubuntu kenerl unroll (回滚)<ul>
<li><code>sudo dpkg --get-selections | grep linux-image</code>  查看系统已经安装的kernel</li>
<li><code>sudo apt-get remove linux-image-x.x.x-xx-generic</code> 卸载目前的kernel</li>
<li><code>sudo update-grub</code> 更新开机引导程序 ps: GRUB（GRand Unified Bootloader）是一个用于管理计算机开机引导过程的引导加载程序,支持引导多操作系统 windows&#x2F;linux发行版&#x2F;BSD</li>
<li><code>sudo reboot</code> 重启系统</li>
<li><code>uname -r</code> 查看当前kernel是否已经完成回滚</li>
<li><code>sudo apt-mark hold/unhold linux-image-5.4.0-xx-generic</code> 设置 hold 参数保持当前kernel不更新, 设置 unhold 解除更新限制</li>
</ul>
</li>
</ol>
</li>
<li><p>command: <code>pip install -U package</code> 命令中的 <code>-U</code> 参数表示升级(update)已安装的 Python package到最新版本。</p>
</li>
<li><p>confusion: PTQ static vs dynamic</p>
<ol>
<li>PTQ static<ul>
<li>使用校准数据集离线计算缩放因子(Scale)和零点(Zero Point)</li>
<li>所有激活(Activation)都使用相同的缩放因子和零点</li>
</ul>
</li>
<li>PTQ dynamic<ul>
<li>缩放因子(Scale)和零点(Zero Point)是在推理时计算的，并且特定用于每次的激活(Activation)</li>
<li>因此它们更准确，但引入了额外的计算开销</li>
</ul>
</li>
</ol>
</li>
<li><p>confusion: BI degradation vs BD degradation</p>
<ol>
<li>BI -&gt; bicubic-down,降质过程仅包含双三次下采样</li>
<li>BD -&gt; blur-down,通过高斯模糊下采样</li>
</ol>
</li>
<li><p>confusion: argparse library</p>
<ol>
<li>basic: <code>parser = argparse.ArgumetParser(description, epilog)</code> -&gt; 创建 ArgumentParser 对象，其中 description 是一个简要的程序描述，epilog 是一个在帮助信息的结尾显示的额外文本</li>
<li>basic: <code>add_argument(name or flags, ...)</code> -&gt; 添加命令行参数(<code>xxx</code>: positional argument or <code>--xxx</code>: option that takes a value)。name or flags 参数可以是单个选项（例如 ‘-f’），也可以是多个选项（例如 ‘-f’, ‘–file’）。你可以使用许多其他关键字参数来配置参数的行为，如 type、default、help 等,示例如下<ul>
<li>整数类型参数: <code>parser.add_argument(&#39;--count&#39;, type=int, help=&#39;An integer value&#39;)</code></li>
<li>浮点类型参数: <code>parser.add_argument(&#39;--rate&#39;, type=float, help=&#39;A floating-point value&#39;)</code></li>
<li>字符串类型参数: <code>parser.add_argument(&#39;--name&#39;, type=str, help=&#39;A string value&#39;)</code></li>
<li>布尔类型参数: <code>parser.add_argument(&#39;--verbose&#39;, action=&#39;store_true&#39;, help=&#39;Enable verbose mode&#39;)</code></li>
<li>文件路径参数: <code>parser.add_argument(&#39;--file&#39;, type=argparse.FileType(&#39;r&#39;), help=&#39;A file path&#39;)</code></li>
<li>目录路径参数: <code>parser.add_argument(&#39;--directory&#39;, type=str, help=&#39;A directory path&#39;)</code></li>
<li><strong>note:</strong> 很奇怪的点在于关键字参数<code>--xx_x</code>中使用<code>_</code>传入参数时会出现<code>error: unrecognized arguments: --xx_x</code>,故用<code>-</code>代替</li>
</ul>
</li>
<li>basic: <code>parse_args()</code>: 解析命令行参数，并返回一个包含所有参数值的命名空间对象</li>
<li>extension: <code>add_subparsers()</code> -&gt; 添加子命令解析器，允许你为你的程序创建子命令（类似于 git 命令的子命令，如 git clone、git commit 等）</li>
<li>extension: <code>set_defaults()</code> -&gt; 为参数设置默认值</li>
<li>extension: <code>add_argument_group()</code> -&gt; 将参数分组到一个组中，用于更好地组织帮助信息</li>
<li>extension: <code>format_help()</code> -&gt; 生成帮助信息</li>
<li>extension: <code>error(msg)</code> -&gt; 在参数解析过程中发生错误时触发错误消息</li>
</ol>
</li>
<li><p>confusion: <code>&#123;:08d&#125;.png</code> 字符串格式化模板</p>
<ol>
<li><code>&#123;&#125;</code>: 这是一个占位符，用于表示将要插入的值。在这个模板中，{} 用来表示一个整数</li>
<li><code>:08d</code>: 这是格式说明符，指定了如何格式化这个整数。其中：<ul>
<li><code>0</code> 表示要用零来填充空白位置</li>
<li><code>8</code> 表示总共要占用 8 个字符的宽度，包括填充的零和数字本身</li>
<li><code>d</code> 表示要格式化的值是一个十进制整数</li>
</ul>
</li>
</ol>
</li>
<li><p>confusion: function <code>os.path.splitext()</code></p>
<ol>
<li>input: 文件路径（或文件名）</li>
<li>return: 一个包含两个部分的元组tuple i.e. (文件名, 文件扩展名)</li>
</ol>
</li>
<li><p>confusion: print(model) 实现</p>
<ol>
<li>print(model)  # 当你使用 print 函数来打印一个对象时，它会尝试调用该对象的 <code>__str__()</code> 或 <code>__repr__()</code> 方法来获取一个可打印的字符串表示<ul>
<li><code>model.__repr__</code> 输出model的属性<code>__repr__</code>  i.e. 方法的名称  -&gt; <code>&lt;bound method Module.__repr__ of xxx&gt;</code></li>
<li><code>model.__repr__()</code> 输出model的method<code>__repr__()</code> i.e. 方法的调用 的结果 -&gt; <code>xxx</code></li>
<li><strong>note:</strong> 属性是对象的数据成员，而方法是对象上的函数成员，用于定义对象的行为。实际上，方法是对象上的可调用属性</li>
</ul>
</li>
</ol>
</li>
<li><p>confusion: <code>glob.glob(os.path.join(img_dir, &#39;*&#39;))</code></p>
<ol>
<li><code>import os</code> 后 <code>os.path.join(img_dir, &#39;*&#39;)</code> 返回值 <code>&#39;img_dir/*&#39;</code>类型为 <code>str</code> -&gt; <code>type(os.path.join(img_dir, &#39;*&#39;)) == &lt;class &#39;str&#39;&gt;</code></li>
<li><code>import glob</code> 后 <code>glob.glob(os.path.join(img_dir, &#39;*&#39;))</code> 返回值为指定路径下的文件列表 -&gt; <code>type(glob.glob(os.path.join(img_dir, &#39;*&#39;))) == &lt;class &#39;list&#39;&gt;</code></li>
</ol>
</li>
<li><p>confusion: <code>img_dir_split = re.split(r&#39;[\\/]&#39;, img_dir)</code> 这行代码使用正则表达式来分割文件路径</p>
<ol>
<li>具体来讲首先<code>import re # re(regular expression) 是 python 中的正则表达式模块</code> , r’[\&#x2F;]’ 表示一个正则表达式的字符集, 它匹配一个正斜杠 &#x2F; 或反斜杠 \ 中的任何一个字符, ‘\‘ 用于转义字符。这在处理文件路径时很有用，因为不同的操作系统使用不同的路径分隔符，有些使用正斜杠 &#x2F;，而有些使用反斜杠 \。使用 [\&#x2F;] 可以在跨平台的情况下匹配路径中的分隔符，而不必担心操作系统差异</li>
<li><code>img_dir_split = re.split(r&#39;[\\/]&#39;, img_dir)</code>  它会将指定的文件路径 img_dir 按照正斜杠 &#x2F; 或反斜杠 \ 进行分割，并将分割的部分存储在一个列表中。返回值为由文件路径名各部分(str)组成的list -&gt; 例如  img_dir_split &#x3D;&#x3D; [‘data’, ‘demo_000’]</li>
</ol>
</li>
<li><p>confusion: <code>img_dir_split[:-1]</code></p>
<ol>
<li>img_dir_split[:-1] 是 Python 中的列表切片（slicing）操作，它用于获取列表 img_dir_split 中的一部分元素</li>
<li>具体来说，[:-1] 表示切片从列表的开头到倒数第二个元素（不包括倒数第一个元素）。这个操作会返回一个新的列表，包含了 img_dir_split 中从第一个元素到倒数第二个元素（不包括倒数第一个元素）的所有元素</li>
</ol>
</li>
<li><p>confusion: <code>lq_folder = reduce(os.path.join, img_dir_split[:-1])</code></p>
<ol>
<li><code>from functools import reduce</code> 导入包<code>reduce</code>，它用于将一个二元函数应用于可迭代的元素，从左到右依次累积结果</li>
<li>上述代码的目的是将 img_dir_split 列表切片后的元素 i.e. <code>img_dir_split[:-1]</code>通过操作系统路径连接起来，然后返回连接后的结果。</li>
</ol>
</li>
<li><p>confusion: <code>assert isinstance(transforms, Sequence)</code></p>
<ol>
<li><code>from collections.abc import Sequence</code> <code>Sequence</code>是在Python中的抽象基类，用于定义一组通用的接口和方法，而不是具体的实现。<code>Sequence</code>它表示序列类型，如列表、元组、字符串等。</li>
<li><code>assert isinstance(transforms, Sequence)</code>这种检查可以用于确保transforms具有序列类型的行为，以便在代码中安全地使用类似列表或元组的操作。</li>
</ol>
</li>
<li><p>confusion: <code>@PIPELINES.register_module()</code></p>
<ol>
<li><code>from ..registry import PIPELINES</code>: 从相对于当前模块的上一级目录中的 registry 模块中导入名为 PIPELINES 的对象</li>
<li><code>@PIPELINES.register_module()</code>的作用是将被装饰的函数或类注册到名为 PIPELINES 的模块或类的注册表中。这通常在Python中用于实现插件或扩展性架构，以便在运行时动态添加和管理功能。</li>
</ol>
</li>
<li><p>confusion: <code>dict</code>类实例化后的对象<code>object</code>如何访问</p>
<ol>
<li>在Python中，字典的键和值是通过方括号<code>[]</code>来访问的(如<code>data[&quot;meta&quot;]</code>, data为dict类的实例, <code>meta</code> 是其中一个key)，而不是通过点.来访问</li>
<li>在Python中，可以使用点号 <code>.</code>来访问以下类型的成员或属性<ul>
<li>类的成员(类变量和类方法): <code>MyClass.my_class_variable 或 MyClass.my_class_method()</code></li>
<li>实例对象的属性和方法: <code>my_object.my_instance_variable 或 my_object.my_instance_method()</code></li>
<li>模块的函数和变量：<code>math.sqrt()</code></li>
<li>实例化后的内置类：<code>my_string.upper()</code>，其中 <code>upper()</code> 是字符串(str)对象的一个方法</li>
</ul>
</li>
</ol>
</li>
<li><p>confusion: python func <code>range()</code> 生成有序的整数序列</p>
<ol>
<li><code>range(stop)</code>: start（可选）：序列的起始值，默认为 0</li>
<li><code>range(start, stop)</code>: stop（必需）：序列的结束值，但不包括该值。range() 会生成从 start 到 stop-1 的整数序列</li>
<li><code>range(start, stop, step)</code>: step（可选）：可选参数，控制序列中的值之间的步长，默认为 1, e.g. <code>list(range(0, 21, 5)) == [0, 5, 10, 15, 20]</code></li>
</ol>
</li>
<li><p>confusion: python slicing operation</p>
<ol>
<li>假设data为一维list或str, <code>data[start:end]</code> 选取范围 start -&gt; end-1, step &#x3D;&#x3D; 1; 若start未指定，则默认为0; 若end未指定，则默认选取到最后一个元素(包含最后一个元素)</li>
<li>假设data为多维NumPy array, <code>data[:, start:end:step]</code> 选取 dim&#x3D;&#x3D;0 所有元素, 选取 dim&#x3D;&#x3D;1 的 start -&gt; end-1, step&#x3D;&#x3D;step的元素</li>
<li>假设data为一维list或str, <code>data[-5:]</code> 选取从倒数第5个元素直至末尾最后一个元素,最后一个元素index为-1</li>
</ol>
</li>
<li><p>command: <code>find . -name &quot;*.tar&quot; | while read NAME ; do mkdir -p &quot;$&#123;NAME%.tar&#125;&quot;; tar -xvf &quot;$&#123;NAME&#125;&quot; -C &quot;$&#123;NAME%.tar&#125;&quot;; rm -f &quot;$&#123;NAME&#125;&quot;; done</code> recursively unzip files</p>
<ol>
<li><code>find . -name &quot;*.tar&quot;</code>: 这部分使用 <code>find</code> 命令来在当前目录及其子目录中查找文件名匹配 <code>*.tar</code> 的文件</li>
<li><code>|</code>: 这是管道符号，它将 <code>find</code> 命令的输出（即找到的所有 <code>.tar</code>文件的路径列表）传递给管道符号右侧的命令</li>
<li><code>while read NAME</code>: 这部分创建一个 <code>while</code> 循环，它将逐行读取管道传入的文件路径，并将每行内容赋值给 <code>NAME</code> 变量</li>
<li><code>do</code>: 这标志着 <code>while</code> 循环的开始</li>
<li><code>mkdir -p &quot;$&#123;NAME%.tar&#125;&quot;</code>: 这是在循环中的第一个命令。它使用 <code>mkdir</code> 命令创建目录，并且 <code>-p</code> no error if existing, make parent directories as needed. <code>$&#123;NAME%.tar&#125;</code> 是一种变量扩展，它会从 <code>NAME</code> 变量的值中删除 <code>.tar</code>扩展名，然后创建一个对应的目录</li>
<li><code>tar -xvf &quot;$&#123;NAME&#125;&quot; -C &quot;$&#123;NAME%.tar&#125;&quot;</code>: 这是在循环中的第二个命令。它使用 <code>tar</code> 命令来解压缩 <code>NAME</code>变量中指定的 <code>.tar</code>文件，并将解压后的文件放入对应的目录 <code>$&#123;NAME%.tar&#125;</code>, note: 参数说明 <code>-C, --directory=DIR   change to directory DIR</code> 用于指定解压缩操作的目标目录</li>
<li><code>rm -f &quot;$&#123;NAME&#125;&quot;</code>: 这是在循环中的第三个命令。它使用 <code>rm</code> 命令删除原始的 <code>.tar</code> 文件。<code>-f</code> 选项表示不会询问确认</li>
<li><code>done</code>: 这标志着 <code>while</code> 循环的结束</li>
</ol>
</li>
<li><p>command: <code>python -c &quot;Python code to execute&quot;</code></p>
<ol>
<li><code>-c</code> 参数是 <code>Python</code> 解释器的一个命令行选项，它允许你在命令行中执行一段 <code>Python</code> 代码，而不必编写一个独立的 <code>Python</code> 脚本文件。</li>
</ol>
</li>
<li><p>confusion: <code>dict(xx=yy) 和 dict = &#123;&#39;xx&#39;: yy&#125;</code>异同</p>
<ol>
<li><code>dict(xx=yy)</code> 和 <code>dict = &#123;&#39;xx&#39;: yy&#125;</code> 构造出来的字典在本质上是相同的</li>
<li><code>dict(xx=yy)</code> 的语法是一种关键字参数的方式，其中 <code>xx</code> 是键，<code>yy</code> 是值。这种方式适用于在函数调用中将多个键值对传递给函数，而不需要明确创建字典对象</li>
<li><code>dict = &#123;&#39;xx&#39;: yy&#125;</code> 是显式创建一个字典的方式，其中 <code>&#39;xx&#39;</code> 是键，<code>yy</code> 是值。这种方式更适用于创建独立的字典对象，以便在程序中进行操作和访问</li>
</ol>
</li>
<li><p>confusion: <code>from easydict import EasyDict</code> 作用: 可以像访问属性一样访问字典的值<code>value</code>, 而不必使用<code>my_dict[&#39;key&#39;]</code></p>
</li>
<li><p>confusion: <code>apt</code> 和 <code>dpkg</code></p>
<ol>
<li>dpkg 和 apt 是在 Debian 及其衍生发行版（如 Ubuntu）中用于软件包管理的两个重要工具，它们之间存在密切的关系，但有不同的职责。<ul>
<li>dpkg(Debian Package): dpkg 是底层的软件包管理工具，用于安装、卸载和管理 Debian 系统上的软件包。它直接处理软件包的安装和卸载，以及配置文件的处理。dpkg 可以从本地 .deb 文件安装软件包，也可以从软件源下载并安装软件包。</li>
<li>apt(Advanced Package Tool): apt 是一个高级的软件包管理工具，建立在 dpkg 之上，提供更高级的功能。apt 可以自动解决软件包之间的依赖关系，并处理升级、安装、卸载等操作。它使用软件源（repositories）来获取软件包信息，并允许用户方便地搜索、安装和更新软件。</li>
<li>简而言之，dpkg 是更基础的工具，直接负责软件包的安装和卸载，而 apt 提供了更高级、用户友好的接口，使软件包管理更加方便，它处理了更多的任务，包括依赖解决、更新软件源、搜索软件包等。</li>
</ul>
</li>
</ol>
</li>
<li><p>confusion: <code>SIMD</code> <code>MIMD</code> <code>SIMT</code></p>
<ol>
<li><code>SIMD</code>: SIMD 是指单指令流多数据流（Single Instruction, Multiple Data）的计算模式。在计算机体系结构中，SIMD 是一种并行计算的方式，它允许同时对多个数据执行相同的操作，以提高并行计算的效率。</li>
<li><code>SIMT</code>: 类似于 SIMD，SIMT 是 NVIDIA GPU 中一种并行计算模式，它允许执行单一指令在多个线程上。</li>
<li><code>MIMD</code>: MIMD（Multiple Instruction, Multiple Data）： 在 MIMD 模式中，多个处理单元同时执行不同的指令，处理不同的数据。每个处理单元都有自己的指令流和数据流，可以独立运行。MIMD 适用于处理多个独立的任务，每个任务可能需要不同的指令序列。</li>
</ol>
</li>
<li><p>confusion: <code>GCC编译器</code> <code>Make</code> <code>CMake</code> <code>Makefile</code> <code>CMakeLists.txt</code> 区别</p>
<ul>
<li>GCC 编译器：<ol>
<li>作用： 将高级语言源代码编译成机器码或可执行文件。</li>
<li>使用场景： 用于直接编译源代码，生成可执行文件。</li>
</ol>
</li>
<li>Make：<ol>
<li>作用： 构建工具，根据 Makefile 中定义的规则和依赖关系来管理和调度项目(调用GCC编译器)的构建过程。</li>
<li>使用场景： 用于自动化构建过程，确保只有发生更改的文件被重新编译。</li>
</ol>
</li>
<li>Makefile：<ol>
<li>作用： 文本文件，包含项目的构建规则、依赖关系和编译动作。</li>
<li>使用场景： Make 工具根据 Makefile 中的规则来判断哪些文件需要重新构建，然后调用适当的编译器。</li>
</ol>
</li>
<li>CMake：<ol>
<li>作用： 生成用于不同构建系统的构建配置文件，如 Makefile。</li>
<li>使用场景： 提供跨平台的构建配置，允许开发者在不同的构建系统上使用相同的配置。</li>
<li>makefile在一些简单的工程完全可以人工手下，但是当工程非常大的时候，手写makefile也是非常麻烦的，如果换了个平台makefile又要重新修改。这时候就出现了Cmake这个工具，cmake就可以更加简单的生成makefile文件给上面那个make用。当然cmake还有其他功能，就是可以跨平台生成对应平台能用的makefile，你不用再自己去修改了</li>
</ol>
</li>
<li>CMakeLists.txt：<ol>
<li>作用： 文本文件，包含 CMake 的配置和项目信息。</li>
<li>使用场景： CMake 使用 CMakeLists.txt 来生成项目的构建配置文件，其中定义了项目的结构、依赖关系和编译选项。</li>
<li>cmake根据什么生成makefile呢？它又要根据一个叫CMakeLists.txt文件（学名：组态档）去生成makefile。 CMakeLists.txt文件谁写啊？亲，是你自己手写的。</li>
</ol>
</li>
<li>总结：<br>GCC 编译器是用于将源代码编译为机器码的工具。<br>Make 是一个构建工具，使用 Makefile 来自动管理项目的构建过程。<br>CMake 是一个用于生成跨平台构建配置的工具，可以生成 Makefile 或其他构建系统的配置文件。<br>Makefile 包含构建项目所需的规则和命令，由 Make 工具读取执行。<br>CMakeLists.txt 包含项目的配置信息和结构，由 CMake 解析生成构建配置。</li>
</ul>
</li>
<li><p>confusion: ssh 添加 public_key 至目标远程主机实现无需密码登录</p>
<ul>
<li>本地host <code>ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com</code><ol>
<li>-t rsa: 指定密钥类型为 RSA。</li>
<li>-b 4096: 指定密钥的位数，4096 位是一种常见的安全选择。</li>
<li>-C “<a href="mailto:&#121;&#111;&#x75;&#114;&#x5f;&#x65;&#x6d;&#97;&#x69;&#x6c;&#x40;&#101;&#120;&#97;&#x6d;&#112;&#x6c;&#x65;&#46;&#99;&#x6f;&#x6d;">&#121;&#111;&#x75;&#114;&#x5f;&#x65;&#x6d;&#97;&#x69;&#x6c;&#x40;&#101;&#120;&#97;&#x6d;&#112;&#x6c;&#x65;&#46;&#99;&#x6f;&#x6d;</a>“: 在生成的密钥中添加注释，通常使用你的电子邮件地址。</li>
</ol>
</li>
<li>将生成的ssh public key (id_rsa.pub) 复制到远程target 的 <code>~/.ssh/authorized_keys</code> (如果没有则自建此文件)中即可</li>
</ul>
</li>
<li><p>confusion: <code>chmod mode file</code> 中的 mode 含义 -&gt; 用每个分组读写操作权限用3bit表示， 从左到右依次是 <code>rwx</code></p>
<ul>
<li>示例： <code>drwxr--r--</code> : d 代表 directory 目录， 所有者(user)拥有权限 read write 没有 execute,用数字表示为 <code>6 = 4 + 2 + 0</code> ,群组(group)和其他(others)只有权限 read, 数字表示为 <code>4 = 4 + 0 + 0</code>, 综上此文件的 mode 为 <code>644</code></li>
</ul>
</li>
<li><p>confusion: ubuntu 除用 <code>ifconfig</code> 查看本机ip之外，还可以用 <code>ip addr</code> (较新的ubuntu默认安装了 <code>ip</code> 命令), 一般前者失效时后者有效，不用再安装 <code>net-tools</code> 包</p>
</li>
<li><p>confusion: <code>register_buffer()</code></p>
<ul>
<li><code>register_buffer</code> 是 PyTorch 中 nn.Module 类提供的一个方法，用于注册一个缓冲张量。这个缓冲张量不会被视为模型的参数，但会被包含在模型的状态中，并在模型的 <code>state_dict</code> 中保存。这通常用于存储不需要优化的固定参数，比如在模型中使用的常数或预先计算好的张量。</li>
</ul>
</li>
<li><p>confusion: Slurm（Simple Linux Utility for Resource Management）作业调度系统</p>
</li>
<li><p>confusion: github 克隆别人的仓库，修改更新后如何推送到自己的 github 账户下</p>
<ul>
<li><p>新建 github 上我的空repo, 可以不需要 readme.md 和 license, 因为克隆别人仓库一般都有</p>
</li>
<li><p>clone github 上他人仓库，重命名仓库文件夹名称使之与github上我的repo同名</p>
</li>
<li><p>git remote 设定远端repo是我的github新建的repo <code>git remote set-url origin https://github.com/kyrie2to11/gptq_test.git</code></p>
</li>
<li><p>修改本地仓库文件后，推送到远端github repo  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git status <span class="comment"># 查看本地仓库哪些文件被修改了</span></span><br><span class="line">git add . <span class="comment"># 把修改的文件放入staging area,准备commit</span></span><br><span class="line">git commit -m <span class="string">&quot;commit remark message&quot;</span> <span class="comment"># 本地仓库正式commit更改</span></span><br><span class="line">git push origin main <span class="comment"># 将本地修改同步到github repo</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>confusion: 更改ubuntu root密码 <code>sudo passwd</code> 或者 <code>sudo passwd root</code></p>
</li>
<li><p>confusion: python 切片 slicing 语法 <code>[start:stop:step]</code>  </p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">start：起始位置的索引。</span><br><span class="line">stop：终止位置的索引（不包含在切片内）。</span><br><span class="line">step：步长，表示每次移动的距离。</span><br></pre></td></tr></table></figure>

<p>如果不指定这些值，默认值为：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">start 默认为第一个元素（索引 0）。</span><br><span class="line">stop 默认为最后一个元素的下一个位置（即列表的长度）。</span><br><span class="line">step 默认为 1。</span><br></pre></td></tr></table></figure>

<p>当你使用 [::-1] 时，两个冒号 : 表示没有指定 start 和 stop，因此默认取整个序列。而 -1 作为步长表示从最后一个元素开始，以步长为 1 的方向逐步向前取值，实现反向取值。</p>
</li>
<li><p><code>results_list = self.get_bboxes(*outs, img_metas=img_metas, rescale=rescale)</code> 中 <code>*outs</code>的作用</p>
<ul>
<li>在这个上下文中，*outs 是一种使用在函数调用中的语法，它表示将一个可迭代对象（比如列表或元组）中的元素分别传递给函数作为独立的参数。这个语法称为“拆包”（unpacking）。</li>
<li>具体到你的代码中，outs 可能是一个包含多个元素的可迭代对象（比如元组），而 self.get_bboxes 函数的参数需要这些元素作为独立的参数传递进去。使用 *outs 就能够方便地将 outs 中的元素拆包传递给函数。</li>
<li>这种方式在函数参数数量不确定，或者希望通过一个可迭代对象传递参数时非常有用。在这里，*outs 将 outs 中的内容展开，作为 self.get_bboxes 函数的独立参数传递给函数。</li>
</ul>
</li>
</ol>
<h2 id="Metrics（Full-Reference）"><a href="#Metrics（Full-Reference）" class="headerlink" title="Metrics（Full-Reference）"></a>Metrics（Full-Reference）</h2><ol>
<li>Peak Signal to Noise Ratio (PSNR)</li>
<li>Structural SIMilarity (SSIM)</li>
</ol>
<h2 id="Milestone"><a href="#Milestone" class="headerlink" title="Milestone"></a>Milestone</h2><table>
<thead>
<tr>
<th>Model</th>
<th>Description</th>
<th>Dataset</th>
<th>Val PSNR</th>
<th>Val SSIM</th>
<th>Params</th>
<th>Runtime on oneplus7T [ms]</th>
<th>FLOPs [G]</th>
</tr>
</thead>
<tbody><tr>
<td>VapSR_4_1</td>
<td>Functional VapSR_4 with pixel norm realized by layer normalization, VAB activation: RELU, Attention using Partial conv</td>
<td>REDS</td>
<td>27.790268</td>
<td>0.77721727</td>
<td>59,468</td>
<td>654.0 (INT8_CPU)</td>
<td>7.462</td>
</tr>
<tr>
<td>SWAT_0</td>
<td>Sliding Window, VAB Attention, Partial Conv, Channel Shuffle(mix_ratio&#x3D;4)</td>
<td>REDS</td>
<td>27.842232</td>
<td>0.77754354</td>
<td>50,624</td>
<td>271.0   (FP16_CPU)</td>
<td>5.803</td>
</tr>
</tbody></table>
<hr>
<p><em>AI benchmark setting for Runtime test:</em>  </p>
<ul>
<li>Input Values range(min,max): 0,255  </li>
<li>Inference Mode: INT8&#x2F;FP16  </li>
<li>Acceleration: CPU&#x2F;TFLite GPU Delegate</li>
</ul>
<h2 id="Benchmark"><a href="#Benchmark" class="headerlink" title="Benchmark"></a>Benchmark</h2><table>
<thead>
<tr>
<th>Rank</th>
<th>Model</th>
<th>Source</th>
<th>Dataset</th>
<th>Test PSNR</th>
<th>Test SSIM</th>
<th>Params</th>
<th>Runtime on oneplus7T [ms]</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>Diggers</td>
<td>Real-Time Video Super-Resolution based on Bidirectional RNNs(2021 SOTA)</td>
<td>REDS(train_videos: 240, test_videos: 30)</td>
<td>27.98</td>
<td>-</td>
<td>39,640</td>
<td>-</td>
</tr>
<tr>
<td>2</td>
<td>VSR_12</td>
<td>Ours</td>
<td>REDS(train_videos: 240, test_videos: 30)</td>
<td>27.981062</td>
<td>0.7824855</td>
<td>57,696</td>
<td>62.8</td>
</tr>
</tbody></table>
<h2 id="PaperWriting"><a href="#PaperWriting" class="headerlink" title="PaperWriting"></a>PaperWriting</h2><h2 id="No-1"><a href="#No-1" class="headerlink" title="No.1"></a>No.1</h2><ol>
<li>BSConvU as shallow feature extraction</li>
</ol>
<h2 id="PaperReference"><a href="#PaperReference" class="headerlink" title="PaperReference"></a>PaperReference</h2><ol>
<li>Rethinking Alignment in Video Super-Resolution Transformers(NIPS 2022) -&gt; VIT 视频超分(VSR)中帧&#x2F;特征对齐不是必要操作</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://kyrie2to11.github.io/2023/09/13/Competition-0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="jarvis">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jarvis's Blog">
      <meta itemprop="description" content="记录学习和生活，留下时光的痕迹">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Jarvis's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/09/13/Competition-0/" class="post-title-link" itemprop="url">Single Image Depth Estimation</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-13 21:10:10" itemprop="dateCreated datePublished" datetime="2023-09-13T21:10:10+08:00">2023-09-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-02 11:46:21" itemprop="dateModified" datetime="2024-12-02T11:46:21+08:00">2024-12-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Time-2023-09-13-2023-10-05"><a href="#Time-2023-09-13-2023-10-05" class="headerlink" title="Time: 2023.09.13-2023.10.05"></a>Time: 2023.09.13-2023.10.05</h2><h2 id="Paper-Reading"><a href="#Paper-Reading" class="headerlink" title="Paper Reading"></a>Paper Reading</h2><h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><ol>
<li>HR-WSI: Structure-Guided Ranking Loss for Single Image Depth Prediction</li>
<li>Holopix50k: A Large-Scale In-the-wild Stereo Image Dataset</li>
<li>DiverseDepth: Affine-invariant Depth Prediction Using Diverse Data</li>
<li>ReDWeb V1: Monocular Relative Depth Perception with Web Stereo Data Supervision</li>
<li>The Replica Dataset: A Digital Replica of Indoor Spaces</li>
<li>Taskonomy: Disentangling Task Transfer Learning</li>
</ol>
<h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h3><ul>
<li><p>authority recommend</p>
<ol>
<li>ZoeDepth: Zero-shot Transfer by Combining Relative and Metric Depth (arXiv 2023.02)</li>
<li>Vision Transformers for Dense Prediction (ICCV 2021)</li>
<li>Learning to Recover 3D Scene Shape from a Single Image (CVPR 2021)</li>
</ol>
</li>
<li><p>lightweight SIDE research</p>
<ol>
<li>Deep Neighbor Layer Aggregation for Lightweight Self-Supervised Monocular Depth Estimation (arXiv 2023.09)<ul>
<li><strong>fully convolutional depth estimation network</strong> using <strong>contextual feature fusion</strong></li>
<li>use <strong>high-resolution and low-resolution features</strong> to reserve information on small targets and fast-moving objects <strong>instead of long-range fusion</strong></li>
<li>employing lightweight <strong>channel attention</strong> based on convolution in the <strong>decoder stage</strong></li>
</ul>
</li>
<li>RT-MonoDepth: Real-time Monocular Depth Estimation on Embedded Systems (arXiv 2023.08)<ul>
<li>Fast inference based on convolution: RT-MonoDepth and RT-MonoDepthS, runs at 18.4&amp;30.5 FPS on NVIDIA Jetson Nano and 253.0&amp;364.1 FPS on NVIDIA Jetson AGX Orin on a single RGB image of resolution 640×192, and achieve relative stateof-the-art accuracy on the KITTI dataset.</li>
<li>Encoder (downsample inputs): 4-layer pyramid convolution encoder, removing the normalization layer, standard convolutions instead of depth-wise separable convolution.</li>
<li>Decoder (upsample and fuse): upsampling -&gt; 3 × 3 depth-wise separable convolution followed by nearest-neighbor interpolation with a scale factor of 2; fusion -&gt; mixed use of element-wise addition and concatenate; prediction -&gt; convs + activating functions: leakyReLU, sigmoid.</li>
</ul>
</li>
<li>Lightweight Monocular Depth Estimation via Token-Sharing Transformer (2023 IEEE International Conference on Robotics and Automation (ICRA), CCF-B)<ul>
<li>Token-Sharing Transformer (TST): On the NYU Depth v2 dataset, TST can deliver depth maps up to 63.4 FPS in NVIDIA Jetson nano and 142.6 FPS in NVIDIA Jetson TX2.</li>
<li>Design concept: hierarchy-focused architecture (gradually reduces the resolutions of tokens) + <strong>bottleneck-focused architecture</strong> (bottleneck-focused architecture reduces the resolution through CNN and applies self-attention only in low-resolution tokens)</li>
</ul>
</li>
<li>Lite-Mono: A Lightweight CNN and Transformer Architecture for Self-Supervised Monocular Depth Estimation (CVPR 2023)<ul>
<li>efficient combination of CNNs and Transformers: Consecutive Dilated Convolutions (CDC) module -&gt; shallow CNNs with dilated convolution to enhance local features; Local-Global Features Interaction (LGFI) module -&gt; cross-covariance attention to compute the attention along the feature channels.</li>
</ul>
</li>
<li>Boosting LightWeight Depth Estimation via Knowledge Distillation (International Conference on Knowledge Science, Engineering and Management, KSEM 2023, CCF-C)<ul>
<li>lightweight network (MobileNet-v2 Encoder, Channel-wise attention) + <strong>Promoting KD with Auxiliary Data</strong></li>
</ul>
</li>
<li>Lightweight Monocular Depth Estimation with an Edge Guided Network (2022 17th International Conference on Control, Automation, Robotics and Vision, ICARCV, CORE Computer Science Conference Rankings: A)<ul>
<li>Preliminary: edge information are important cues for convolutional neural networks (CNNs) to estimate depth.</li>
<li>Encoder-Decoder Architecture:<ol>
<li>Multi-scale Feature Extractor -&gt; MobileNetV2 as the backbone</li>
<li>Edge Guidance Branch -&gt; <strong>guiding depth estimation</strong></li>
<li>Transformer-Based Feature Aggregation Module</li>
</ol>
</li>
</ul>
</li>
<li>Lightweight Monocular Depth Estimation through Guided Decoding (2022 International Conference on Robotics and Automation (ICRA), CCF-B)<ul>
<li>lightweight encoder-decoder architecture for embedded platforms + <strong>Guided Upsampling Block</strong></li>
<li>inference:<ol>
<li>NYU Depth V2: 35.1 fps on the NVIDIA Jetson Nano and up to 144.5 fps on the NVIDIA Xavier NX</li>
<li>KITTI: 23.7 fps on the Jetson Nano and 102.9 fps on the Xavier NX</li>
</ol>
</li>
</ul>
</li>
<li>MobileXNet: An Efficient Convolutional Neural Network for Monocular Depth Estimation (IEEE Transactions on Intelligent Transportation Systems, 2022, CCF-B)<ul>
<li>Encoder-Decoder style CNN architecture: Conv, DWConv, DilatedConv, Bilinear Upsampling</li>
<li>To penalize the errors around edges -&gt; hybrid loss: the regular L1 loss + the image gradient-based L1 loss</li>
</ul>
</li>
</ol>
</li>
<li><p>others</p>
<ol>
<li>DiffusionDepth: Diffusion Denoising Approach for Monocular Depth Estimation (arXiv 2023.08)<ul>
<li>Paradigm innovation: regression or classification -&gt; denoising diffusion</li>
</ul>
</li>
<li>Edge-guided occlusion fading reduction for a light-weighted self-supervised monocular depth estimation (arXiv 2019.11)<ul>
<li>Atrous Spatial Pyramid Pooling (ASPP) -&gt; (Dilated&#x2F;Atrous Convolution) reduce the computational costs</li>
<li>Edge-Guided post-processing -&gt; reduce the occlusion fading</li>
</ul>
</li>
</ol>
</li>
</ul>
<h2 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h2><ol>
<li><p><strong>相对误差（Relative Error，REL）</strong>：</p>
<ul>
<li>相对误差用于度量模型估计的深度值与真实深度值之间的相对差异。</li>
<li>公式：$REL &#x3D; \frac{|D_{\text{est}} - D_{\text{gt}}|}{D_{\text{gt}}}$</li>
</ul>
</li>
<li><p><strong>均方根误差（Root Mean Square Error，RMSE）</strong>：</p>
<ul>
<li>均方根误差衡量模型估计值与真实值之间的绝对差异，通过平方差的平均值再开平方根得到。</li>
<li>公式：$RMSE &#x3D; \sqrt{\frac{1}{N} \sum (D_{\text{est}} - D_{\text{gt}})^2}$</li>
</ul>
</li>
<li><p><strong>平均绝对误差（Mean Absolute Error，MAE）</strong>：</p>
<ul>
<li>平均绝对误差度量估计深度值与真实深度值之间的平均绝对差异。</li>
<li>公式：$MAE &#x3D; \frac{1}{N} \sum |D_{\text{est}} - D_{\text{gt}}|$</li>
</ul>
</li>
<li><p><strong>对数均方根误差（Log Root Mean Square Error，Log-RMSE）</strong>：</p>
<ul>
<li>对数均方根误差在对数尺度上度量估计深度值与真实深度值之间的均方根差异。</li>
<li>公式：$Log-RMSE &#x3D; \sqrt{\frac{1}{N} \sum (\log(D_{\text{est}} + \epsilon) - \log(D_{\text{gt}} + \epsilon))^2}$</li>
<li>这里的$\epsilon$是一个小的常数，通常用于避免对数中的除零错误。</li>
</ul>
</li>
</ol>
<h2 id="Milestones"><a href="#Milestones" class="headerlink" title="Milestones"></a>Milestones</h2>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://kyrie2to11.github.io/2023/07/12/Git-Commands/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="jarvis">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jarvis's Blog">
      <meta itemprop="description" content="记录学习和生活，留下时光的痕迹">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Jarvis's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/07/12/Git-Commands/" class="post-title-link" itemprop="url">Git Commands</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-07-12 14:33:49" itemprop="dateCreated datePublished" datetime="2023-07-12T14:33:49+08:00">2023-07-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-01-03 13:48:29" itemprop="dateModified" datetime="2024-01-03T13:48:29+08:00">2024-01-03</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <table>
<thead>
<tr>
<th>Operation</th>
<th>Commander</th>
</tr>
</thead>
<tbody><tr>
<td>初始化本地仓库</td>
<td><code>git init</code></td>
</tr>
<tr>
<td>添加文件到Git暂存区</td>
<td><code>git add &lt;文件名&gt;</code> 或 <code>git add .</code></td>
</tr>
<tr>
<td>提交暂存区的文件到本地仓库</td>
<td><code>git commit -m &quot;提交消息&quot;</code></td>
</tr>
<tr>
<td>关联本地仓库与远程仓库</td>
<td><code>git remote add origin &lt;远程仓库URL&gt;</code></td>
</tr>
<tr>
<td>推送本地仓库的代码到远程仓库</td>
<td><code>git push origin &lt;分支名&gt;</code></td>
</tr>
<tr>
<td>克隆远程仓库到本地</td>
<td><code>git clone &lt;远程仓库URL&gt;</code></td>
</tr>
<tr>
<td>拉取远程仓库的更新到本地</td>
<td><code>git pull origin &lt;分支名&gt;</code></td>
</tr>
<tr>
<td>创建一个新的分支</td>
<td><code>git branch &lt;分支名&gt;</code></td>
</tr>
<tr>
<td>切换到指定分支</td>
<td><code>git checkout &lt;分支名&gt;</code></td>
</tr>
<tr>
<td>查看当前分支</td>
<td><code>git branch</code></td>
</tr>
<tr>
<td>查看仓库的状态</td>
<td><code>git status</code></td>
</tr>
<tr>
<td>创建并切换到一个新的分支</td>
<td><code>git checkout -b &lt;分支名&gt;</code></td>
</tr>
<tr>
<td>合并指定分支到当前分支</td>
<td><code>git merge &lt;分支名&gt;</code></td>
</tr>
<tr>
<td>查看提交历史记录</td>
<td><code>git log</code></td>
</tr>
<tr>
<td>撤销工作目录中的修改</td>
<td><code>git restore &lt;文件名&gt;</code></td>
</tr>
<tr>
<td>创建标签并附上注释</td>
<td><code>git tag -a &lt;标签名&gt; -m &quot;标签注释&quot;</code></td>
</tr>
<tr>
<td>查看标签列表</td>
<td><code>git tag</code></td>
</tr>
<tr>
<td>切换到指定标签</td>
<td><code>git checkout &lt;标签名&gt;</code></td>
</tr>
<tr>
<td>同步远程仓库的分支列表</td>
<td><code>git remote update origin --prune</code></td>
</tr>
<tr>
<td>查看远程仓库列表</td>
<td><code>git remote -v</code></td>
</tr>
<tr>
<td>从本地仓库中删除指定分支</td>
<td><code>git branch -d &lt;分支名&gt;</code></td>
</tr>
<tr>
<td>从远程仓库中删除指定分支</td>
<td><code>git push origin --delete &lt;分支名&gt;</code></td>
</tr>
<tr>
<td>撤销上一次提交</td>
<td><code>git revert HEAD</code></td>
</tr>
<tr>
<td>撤销上一次提交并丢弃相关的修改</td>
<td><code>git reset HEAD~</code> 或 <code>git reset &lt;提交ID&gt;</code></td>
</tr>
<tr>
<td>撤销上一次提交并保留相关的修改</td>
<td><code>git reset HEAD~ --soft</code> 或 <code>git reset &lt;提交ID&gt; --soft</code></td>
</tr>
<tr>
<td>解决合并冲突后，继续合并操作</td>
<td><code>git merge --continue</code></td>
</tr>
<tr>
<td>取消合并操作</td>
<td><code>git merge --abort</code></td>
</tr>
<tr>
<td>生成 SSH 密钥</td>
<td><code>ssh-keygen -t rsa -b 4096 -C &quot;你的邮箱地址&quot;</code></td>
</tr>
<tr>
<td>查看公钥内容</td>
<td><code>cat ~/.ssh/id_rsa.pub</code></td>
</tr>
<tr>
<td>添加 SSH 密钥至 GitHub</td>
<td><code>github GUI operation</code></td>
</tr>
</tbody></table>
<p><em>More info:</em> <a target="_blank" rel="noopener" href="https://www.runoob.com/git/git-tutorial.html">https://www.runoob.com/git/git-tutorial.html</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://kyrie2to11.github.io/2023/07/07/Work-Log-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="jarvis">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jarvis's Blog">
      <meta itemprop="description" content="记录学习和生活，留下时光的痕迹">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Jarvis's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/07/07/Work-Log-2/" class="post-title-link" itemprop="url">Video Super-Resolution Quantization Work Log</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-07-07 14:31:56" itemprop="dateCreated datePublished" datetime="2023-07-07T14:31:56+08:00">2023-07-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-12-02 12:02:41" itemprop="dateModified" datetime="2024-12-02T12:02:41+08:00">2024-12-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Video-Super-Resolution-Quantization-Time-2023-07-07-2023-08-07"><a href="#Video-Super-Resolution-Quantization-Time-2023-07-07-2023-08-07" class="headerlink" title="Video Super-Resolution Quantization (Time:2023.07.07-2023.08.07)"></a>Video Super-Resolution Quantization (Time:2023.07.07-2023.08.07)</h2><h2 id="Paper-Reading"><a href="#Paper-Reading" class="headerlink" title="Paper Reading"></a>Paper Reading</h2><ol>
<li>Dynamic Network Quantization for Efficient Video Inference <strong>(ICCV2021)</strong><ul>
<li><strong>Feat</strong>: selects optimal precision for each frame conditioned on the input for efficient video recognition</li>
</ul>
</li>
<li>ResQ: Residual Quantization for Video Perception <strong>(ICCV2023)</strong><ul>
<li><strong>Feat</strong>: difference in network activations between two neighboring frames, exhibit properties that make them highly quantizable</li>
</ul>
</li>
<li>QuantSR: Accurate Low-bit Quantization for Efficient Image Super-Resolution <strong>(NIPS2023)</strong><ul>
<li>To overcome the representation homogeneity caused by quantization in the network, we introduce the Redistribution-driven Learnable Quantizer (RLQ). This is accomplished through an inference-agnostic efficient redistribution design, which adds additional information in both forward and backward passes to improve the representation ability of quantized networks. (为了克服网络中量化造成的表示同质性，我们引入了重分布驱动的可学习量化器 (RLQ)。这是通过与推理无关的高效重分布设计实现的，它在前向和后向传递中添加了额外信息，以提高量化网络的表示能力。)</li>
<li>Furthermore, to achieve flexible inference and break the upper limit of accuracy, we propose the Depth-dynamic Quantized Architecture (DQA). Our DQA allows for the trade-off between efficiency and accuracy during inference through weight sharing.(此外，为了实现灵活的推理并突破准确率的上限，我们提出了深度动态量化架构（DQA）。我们的DQA通过权重共享，实现了推理过程中效率和准确率之间的平衡。)</li>
</ul>
</li>
<li>Knowledge Distillation for Optical Flow-Based Video Superresolution <strong>(JCSE2023)</strong><ul>
<li><strong>Feat</strong>: Video super-resolution; Optical flow; Knowledge distillation;</li>
</ul>
</li>
<li>EDVR: Video Restoration with Enhanced Deformable Convolutional Networks <strong>(NTIRE2019)</strong></li>
<li>leverage temporal redundancies to accelerate video processing<ol>
<li>Towards High Performance Video Object Detection for Mobiles <strong>(MSRA_arxiv2018)</strong></li>
<li>Temporally Distributed Networks for Fast Video Semantic Segmentation <strong>(CVPR2020)</strong><ul>
<li><strong>Feat</strong>: 在连续帧上用前层网络获取浅层特征，通过 attention 将当前帧前的浅层特征传播到当前帧来近似得到在当前帧上使用深层网络获取深层特征的效果。在分割任务上简单高效</li>
</ul>
</li>
<li>Mobile Video Object Detection with Temporally-Aware Feature Maps <strong>(CVPR2018)</strong><ul>
<li><strong>Feat</strong>: 来自之前帧的 hidden state 当作 temperal information 增强当前帧的目标检测效果</li>
</ul>
</li>
<li>Low-Latency Video Semantic Segmentation <strong>(CVPR2018)</strong><ul>
<li><strong>Feat</strong>: 视频语义分割 当前帧处理受之前帧中间特征影响，判断是否为关键帧，关键帧用高计算强度的模块处理</li>
</ul>
</li>
</ol>
</li>
</ol>
<h2 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h2><ol>
<li>需要搞清楚 basicvsr++ 模型接受的输入是怎样的，模型的大致处理过程是怎样的? input example: torch.Size([1, 141, 3, 240, 320]) -&gt; finish</li>
<li>需要搞清楚 test 加载数据计算指标的 pipeline? 成功, test 结果如下： -&gt; finish<ol>
<li>orig: <code>07/11 20:25:27 - mmengine - INFO - Iter(test) [4/4]    REDS4-BIx4-RGB/PSNR: 32.3965  REDS4-BIx4-RGB/SSIM: 0.9075  data_time: 13.1019  time: 57.3645</code></li>
<li>curret_best: <code>07/12 17:36:58 - mmengine - INFO - Iter(test) [4/4]    REDS4-BIx4-RGB/PSNR: 25.3909  REDS4-BIx4-RGB/SSIM: 0.6822  data_time: 12.9891  time: 64.2525</code></li>
<li>current_now: <code>07/12 22:35:48 - mmengine - INFO - Iter(test) [4/4]    REDS4-BIx4-RGB/PSNR: 25.3899  REDS4-BIx4-RGB/SSIM: 0.6821  data_time: 13.4293  time: 71.2697</code></li>
<li>current_all:<ol>
<li><code>REDS4-BIx4-RGB/PSNR: 25.3908  REDS4-BIx4-RGB/SSIM: 0.6821</code></li>
<li><code>Vimeo-90K-T-BDx4-Y/PSNR: 29.6901  Vimeo-90K-T-BDx4-Y/SSIM: 0.8333  Vimeo-90K-T-BIx4-Y/PSNR: 30.3137  Vimeo-90K-T-BIx4-Y/SSIM: 0.8437</code></li>
<li><code>UDM10-BDx4-Y/PSNR: 30.7291  UDM10-BDx4-Y/SSIM: 0.8677</code></li>
<li><code>VID4-BDx4-Y/PSNR: 22.9580  VID4-BDx4-Y/SSIM: 0.5820  VID4-BIx4-Y/PSNR: 23.2985  VID4-BIx4-Y/SSIM: 0.5998</code></li>
</ol>
</li>
</ol>
</li>
<li>如何降低量化时间，提升量化后效果？ -&gt; cease<ol>
<li>current: the calibration time is 16175.18998336792 s 约 4.5 h) 暂时无解</li>
</ol>
</li>
<li>EDVR 在 REDS 上测试? -&gt; cease<ol>
<li>orig_0: <code>07/16 16:04:32 - mmengine - INFO - Iter(test) [400/400]    REDS4-BIx4-RGB/PSNR: 24.7137  SSIM: 0.6305  data_time: 0.1508  time: 0.5635</code></li>
<li>orig_1: <code>07/16 16:15:56 - mmengine - INFO - Iter(test) [400/400]    REDS4-BIx4-RGB/PSNR: 23.5544  SSIM: 0.6249  data_time: 0.1505  time: 0.5589</code></li>
<li>orig_2: <code>07/16 18:42:34 - mmengine - INFO - Iter(test) [400/400]    REDS4-BIx4-RGB/PSNR: 23.8858  REDS4-BIx4-RGB/SSIM: 0.6057  data_time: 0.1552  time: 0.5929</code></li>
</ol>
</li>
<li>转向在 VSR 小模型上测试量化算法的效果 -&gt; cease<ol>
<li>小的视频超分模型几乎都有各自的特点：有用剪枝的 有突出功耗低的 有用重参数化技巧的 种种已有特点不适合再叠加量化算法</li>
</ol>
</li>
<li>转向在 SISR 模型上测试量化算法的效果 -&gt; cease</li>
<li>尝试其它轻量化技巧，聚焦移动设备应用<ol>
<li>结构重参数</li>
</ol>
</li>
</ol>
<h2 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h2><ol>
<li>PSNR</li>
<li>SSIM</li>
<li>Memory</li>
<li>Latency</li>
</ol>
<h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><h3 id="Milestone-0"><a href="#Milestone-0" class="headerlink" title="Milestone_0"></a>Milestone_0</h3><table>
<thead>
<tr>
<th>Rank</th>
<th>Model</th>
<th>Source</th>
<th>Dataset</th>
<th>PSNR</th>
<th>SSIM</th>
<th>Memory</th>
<th>Latency</th>
</tr>
</thead>
</table>
<h3 id="Milestone-1"><a href="#Milestone-1" class="headerlink" title="Milestone_1"></a>Milestone_1</h3><h2 id="PaperWriting"><a href="#PaperWriting" class="headerlink" title="PaperWriting"></a>PaperWriting</h2><h3 id="No-1"><a href="#No-1" class="headerlink" title="No.1"></a>No.1</h3><h2 id="PaperReference"><a href="#PaperReference" class="headerlink" title="PaperReference"></a>PaperReference</h2>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">jarvis</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  





  





</body>
</html>
